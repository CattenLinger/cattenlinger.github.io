{"meta":{"title":"CattenLinger's Blog","subtitle":"（´・ω・｀） Would you want some coding kitten ?","description":"CattenLinger's blog.","author":"Catten Linger","url":"https://cattenlinger.github.io","root":"/"},"pages":[{"title":"","date":"2024-09-30T12:28:22.397Z","updated":"2024-09-30T12:28:22.397Z","comments":true,"path":"404.html","permalink":"https://cattenlinger.github.io/404.html","excerpt":"","text":"404 Sorry Maybe the page was deleted or the location is worng."},{"title":"","date":"2024-09-30T12:28:22.429Z","updated":"2024-09-30T12:28:22.429Z","comments":true,"path":"about/index.html","permalink":"https://cattenlinger.github.io/about/index.html","excerpt":"","text":"下面写关于自己的内容"},{"title":"","date":"2024-09-30T12:28:22.429Z","updated":"2024-09-30T12:28:22.429Z","comments":true,"path":"all_articles/index.html","permalink":"https://cattenlinger.github.io/all_articles/index.html","excerpt":"","text":""},{"title":"所有分类","date":"2024-09-30T12:28:22.429Z","updated":"2024-09-30T12:28:22.429Z","comments":true,"path":"categories/index.html","permalink":"https://cattenlinger.github.io/categories/index.html","excerpt":"","text":""},{"title":"友情链接","date":"2024-09-30T12:28:22.430Z","updated":"2024-09-30T12:28:22.430Z","comments":true,"path":"friends/index.html","permalink":"https://cattenlinger.github.io/friends/index.html","excerpt":"这里写友链上方的内容。","text":"这里写友链上方的内容。 这里可以写友链页面下方的文字备注，例如自己的友链规范、示例等。"},{"title":"所有标签","date":"2020-07-13T00:25:42.000Z","updated":"2024-09-30T12:28:22.440Z","comments":true,"path":"tags/index.html","permalink":"https://cattenlinger.github.io/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"搭建 busuanzi 后端 (Self-Hosting)","slug":"搭建-busuanzi-后端-Self-Hosting","date":"2025-03-22T13:56:16.000Z","updated":"2025-03-24T00:41:22.225Z","comments":true,"path":"2025/03/22/08eb7ea4f0be.html","link":"","permalink":"https://cattenlinger.github.io/2025/03/22/08eb7ea4f0be.html","excerpt":"","text":"因为 GitHub Pages 用 busuanzi 一直都有点小问题，这些年总有点毛病，所以总是想着能不能自己部署一个后端。 最近找到了 busuanzi 的后端：soxft&#x2F;busuanzi，很开心啊终于有人做了，也找到了，决定部署一个。 原来的数据我也不打算保留了，主要觉得麻烦。 基于 docker compose 的部署很简单，写好 compose 文件就好了。 12345678services: busuanzi: image: &quot;xcsoft/busuanzi:latest&quot; container_name: busuanzi network_mode: host env_file: .env volumes: - &#x27;./data/busuanzi_config.yaml:/app/config.yaml&#x27; 我个人喜欢仅将 docker 作为应用运行容器，不喜欢隔离网络。这个 busuanzi 后端默认监听 0.0.0.0:8080，需要修改一下。 通过观察代码仓库里的配置文件，发现了它的配置可以全部通过环境变量覆盖，很方便。 1234567891011121314151617181920212223242526# 来自 https://github.com/soxft/busuanzi/blob/main/config.yamlWeb: Address: 0.0.0.0:8080 # 监听地址 Cors: &quot;https://xsot.cn,https://google.com&quot; # 跨域访问 Debug: false # 是否开启debug模式 Log: false # 是否开启日志Redis: Address: redis:6379 # redis地址 Password: Database: 0 TLS: false # 是否使用TLS连接redis Prefix: bsz # redis前缀 MaxIdle: 25 # 最大空闲连接数 MaxActive: 100 # 最大连接数 MinIdle: 25 # 最小空闲连接数 MaxRetries: 3 # 最大重试次数Bsz: Expire: 0 # 统计数据过期时间 单位秒, 请输入整数 (无任何访问, 超过这个时间后, 统计数据将被清空, 0为不过期) Secret: &quot;bsz&quot; # JWT签名密钥 // 请设置为任意长度的随机值 Encrypt: &quot;MD516&quot; # 加密算法 (MD516 / MD532) 老版本请使用 MD532 PathStyle: true # 路径样式 (false: url&amp;path, true: path) 老版本请使用 false, true 更便于数据迁移# TIPS, 所有 config 内的设置, 均可使用 环境变量 覆盖# Ex BSZ_SECRET=123 将覆盖 config.yaml 中的 Bsz.Secret 所以我就直接创建了一个 .env 文件，将环境变量都塞进去了。比起作者给出的默认配置，我还多出了一个 WEB_ADDRESS 来修改监听地址 1234567891011121314151617181920212223242526# 是否开启日志WEB_LOG=true# 是否开启debug模式WEB_DEBUG=false# 跨域访问WEB_CORS=&quot;https://cattenlinger.github.io&quot;# 统计数据过期时间 单位秒, 请输入整数 (无任何访问, 超过这个时间后, 统计数据将被清空, 0为不过期)BSZ_EXPIRE=0# 签名密钥 // 请设置为任意长度的随机值BSZ_SECRET=&quot;&quot;# 填写你的 API 地址API_SERVER=&quot;&quot;# redis 地址REDIS_ADDRESS=127.0.0.1:6379# Web 监听WEB_ADDRESS: 127.0.0.1:8082BSZ_PATHSTYLE=trueBSZ_ENCRYPT=MD516 最后在 _config.volantis.yml 改一下 busuanzi 的地址 12analytics: busuanzi: https://busuanzi.infra.shinonometn.com/js 但是，Volantis 5.8 的 busianzi，统计显示的 HTML 元素的 ID 前缀是 busuanzi_value，我搜索了一下对应的 ejs 模板然后手动将值全部改掉，显示才正常。","categories":[{"name":"Self-Hosting","slug":"Self-Hosting","permalink":"https://cattenlinger.github.io/categories/Self-Hosting/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://cattenlinger.github.io/tags/Linux/"},{"name":"Docker","slug":"Docker","permalink":"https://cattenlinger.github.io/tags/Docker/"}]},{"title":"为二级域名配置 NS 来解析三级域名（Subzone）","slug":"为二级域名配置-NS-来解析三级域名（Subzone）","date":"2025-03-18T15:12:01.000Z","updated":"2025-03-24T00:41:42.315Z","comments":true,"path":"2025/03/18/8332b566727f.html","link":"","permalink":"https://cattenlinger.github.io/2025/03/18/8332b566727f.html","excerpt":"","text":"当租到一个一级域名（例如 example.com）之后，就可以在托管商提供的界面，配置二级域名来设置对应的解析记录。 但这种配置方式，在域名多了之后就很不方便了，特别是当需要开始为域名配置三级域名的时候，问题就开始多样化起来： 例如 area-name-01.oss.example.com 这种一般是 Object Storage Server 的域名解析，数量多了起来一般是用自动化，再使用面板很明显不合适。 再例如 project.page.example.com 这种类似 GitHub Page 的用法，虽然可以通过 *.page.example.com 的方式搞定，但有些 NS 服务方为了防滥用，禁用了通配解析，这下就很尴尬了。 还有一些基建设施，hostname.infra.example.com 这种，即便接受频繁上去界面修改 zone file，面对着大量的记录的时候，就很不实际。 所以就想到，有没有一种方法，让某个二级域名的解析，从托管方转移到我自己搭建的域名解析服务上。根据 DNS 的递归查询机制的特性来说，这当然是可行的，可应该要怎么实现呢？ 上网搜了一下好像并没有多少资料，不知道是不是我的搜索姿势不是很对。但还是想办法通过 LLM 搜索找到一点资料：https://serverfault.com/questions/530415/what-is-dns-delegation Phind 给我生成了个很简短的答案，大概意思就是，设置一个 Glue record，另起一个询问之后，才明白这其实是标准的 DNS Delegation。一级域名是顶级域名的 subzone，二级域名是一级域名的 subzone。按照 subzone（子域）的概念来理解就方便了。 很绕口，但说这么多其实操作就是这样，以 subzone.example.com 为例： 新建一个 A record 或者 AAAA record，指向 DNS 服务器软件的地址，这种域名一般开头加 ns1, ns2 这样的名字（ns1.subzone.example.com） 新建一个 NS record subzone.example.com，NS 需要是个 server name，填解析服务器的 A 记录名称（ns1.subzone.example.com） 在 ns1.subzone.example.com 对应的服务器上，配置好 zone file 解析（不同的软件有不同的做法，但 zone file 格式是通用的） 12345678910111213141516$ORIGIN subzone.example.com.$TTL 3600subzone.example.com. IN SOA ns1.subzone.example.com. ( 2025031002 ;serial 7200 ;refresh 3600 ;retry 1209600 ;expire 3600 ) ;minimumsubzone.example.com. IN NS ns1.subzone.example.com.subzone.example.com. 3600 IN A 192.168.0.1subzone.example.com. 3600 IN A 192.168.0.2 ;可以搞多个www.subzone.example.com. 3600 IN A 192.168.0.2 然后，测试一下解析 www.subzone.example.com ，成功的话就会发现权威解析来自于自己的服务器，查询返回的地址是 192.168.0.2 了。 这里需要注意： 本质上是域名解析服务们做了这个递归查询过程，从 . 开始到 com. 到 example.com. 到 subzone.example.com. ，所以用途不管是否是解析内网地址，DNS 服务器都需要正常被外网访问。因为 DNS 查询不分服务器和客户端，“执行递归查询的实际机器”是个未定义角色，任何方都可能是解析者。 以上仅适用于本文讨论的，在国际互联网上注册过的二级域名下的三级域名的 DNS 代理性解析，如果是从根开始就独立解析，那么服务器就当然是可以全内网了。 Zone File 里，域名（也就是所谓的 host name，主机名）都需要写上根的名字.，平常各种面板和界面为了方便都将它简化掉了，但标准上 subzone.example.com. 才是正确的主机名。 这种操作可以一路扩展下去，不断增加子域，直到超出标准允许的长度为止。但我认为，一般来说，给二级域名配三级域名解析代理，就已经是管理实践上的极限，也是实用性上的极限。","categories":[{"name":"Self-Hosting","slug":"Self-Hosting","permalink":"https://cattenlinger.github.io/categories/Self-Hosting/"}],"tags":[{"name":"DNS","slug":"DNS","permalink":"https://cattenlinger.github.io/tags/DNS/"},{"name":"域名","slug":"域名","permalink":"https://cattenlinger.github.io/tags/%E5%9F%9F%E5%90%8D/"}]},{"title":"基于依值类型来使 Map 的存储类型安全","slug":"基于依值类型来使-Map-的存储类型安全","date":"2024-11-07T08:11:49.000Z","updated":"2025-03-24T00:42:23.835Z","comments":true,"path":"2024/11/07/d2ec0fcaeb69.html","link":"","permalink":"https://cattenlinger.github.io/2024/11/07/d2ec0fcaeb69.html","excerpt":"","text":"依值类型是一个很有用的概念，它可以使函数的输入或者输出，根据输入的参数性质来产生变化，让强类型系统能类型安全地使用一些动态类型性质。其中一种用法是类型安全的属性列表。我是在 Ktor 和 Netty 的代码中学习到了这种用法。 例子在以前，Java 的世界里，像 ServletContext 或者一些 PropertyMap，它都是基于两个繁星参数的 Map 来作为存储表（或者说，注册表）。 12345678910111213final Map&lt;String, Object&gt; attr = new HashMap&lt;&gt;();attr.put(&quot;key1&quot;, new ArrayList&lt;String&gt;());attr.put(&quot;key2&quot;, &quot;This is some word&quot;);attr.put(&quot;key3&quot;, 1234);//...// 问题：取出需要 castfinal ArrayList&lt;String&gt; list = (AttaryList&lt;String&gt;) attr.get(&quot;key1&quot;);final String str = (String) attr.get(&quot;key2&quot;);final Integer num = (Integer) attr.get(&quot;key3&quot;); 以上的例子，使用了一个 key 为 String 的表来存储各样类型的数值，在取出的时候，就需要显式地作类型转换。这时候潜在的危险就来了：如果我不知道该 key 对应的含义，使用了错误的类型来转换，那么就会出现 ClassCaseException。而在有 IDE 的编程环境下，单纯一个字符串，无法在智能提示下显现其对应值的类型。在编译器看来，这完全是合法的 ── 显式转换意味着编译器相信编码者的决定，忽略对这句表达式的类型判定，这导致错误要在运行时才能看出来，这是明显的执行错误隐患。 分析编码者已经作了忽略 Map 的值类型的选择：Map&lt;String, Object&gt;，这告诉编译器“我不在乎 Value 的值，我当它们是 Object”。而后在取出的时候，值都是 Object，而我们却要求编译器将它看成是我们期望的类型，这是毫无根据的。要编译器这么做，就需要明确地给出根据，最简单的根据，便是显式的指令：强制转换。 强制转换带来的问题是，它仅仅是告诉编译器不要去理会类型错误，运行时的类型错误是无法避免的。而如果运行时也不在乎，就会出现逻辑冲突，程序运行便不正确，导致非法操作，这在程序执行中是不被允许的。 Key 的作用是从表中索引出对应的数据，Key 不同，Value 也将不同，而在强类型系统中，Value 都有其实际的类型。通过简单的 String 取出的 Object 无类型信息，产生了代码编写问题而违背运行时逻辑的可能性，而这种问题在客观上很难被发现的。针对这情况，可以设计一个机制，在编写时就解决这个问题，并在编译时确保无问题。 实现我们可以通过创建一种 Key 类型，在编译时有一个类型的参照。并创建一种新的容器，管理对一个 Map 取值时的类型转换操作。 12345678910111213141516171819202122232425262728293031323334353637public final class AttributeKey&lt;T&gt; &#123; // 增加一个 label 方便标识这个 key 代表的含义 public final String label; public AttributeKey(String label) &#123; this.label = label; &#125;&#125;public final class Attributes &#123; // Attributes 不在乎 Map 的实现 // map 仅仅是拿来存储数据用的 private final Map&lt;Key&lt;?&gt;, Object&gt; map; public Attributes(Map&lt;Key&lt;?&gt;, Object&gt; map) &#123; this.map = map; &#125; // // 将不安全的类型转换操作都包装在这些方法里，避免 // 它们到处都是 // @SuppressWarnings(&quot;unchecked&quot;) public &lt;T&gt; T put(Key&lt;T&gt; key, T value) &#123; return (T) this.map.put(key, value); &#125; @SuppressWarnings(&quot;unchecked&quot;) public &lt;T&gt; T get(Key&lt;T&gt; key) &#123; return (T) this.map.get(key); &#125;&#125; 这样，在使用的时候，就可以避免到处转换类型的危险操作了。 123456789101112// Attributes 的 Map 可使用其他实现，在使用场景上更灵活。final var attr = new Attributes(new ConcurrentHashMap&lt;&gt;());final var listKey = new AttributeKey&lt;List&lt;String&gt;&gt;(&quot;List&quot;);// 存的时候用 key 固定类型attr.put(listKey, new ArrayList&lt;&gt;());// 取的时候，就再也无需类型转换了final List&lt;String&gt; list = attr.get(listKey); 这里使用的基本技巧就是泛型。 限制可以看得出来，它是在属性存储无需被序列化的情况下使用的，并不适用于数据传输。这种用法大多出现在一个程序中需要中央地存储状态的时候使用，像 Netty、Ktor 等等面向过程的场景下就大量出现这种用法。","categories":[{"name":"编程技术","slug":"编程技术","permalink":"https://cattenlinger.github.io/categories/%E7%BC%96%E7%A8%8B%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://cattenlinger.github.io/tags/Java/"},{"name":"依值类型","slug":"依值类型","permalink":"https://cattenlinger.github.io/tags/%E4%BE%9D%E5%80%BC%E7%B1%BB%E5%9E%8B/"},{"name":"泛型","slug":"泛型","permalink":"https://cattenlinger.github.io/tags/%E6%B3%9B%E5%9E%8B/"}]},{"title":"在 shell 下使用 xmllint 来通过 XPath 解析 html","slug":"在-shell-下使用-xmllint-来通过-XPath-解析-html","date":"2024-10-31T03:33:47.000Z","updated":"2025-03-24T00:43:15.155Z","comments":true,"path":"2024/10/31/136a9b17c9e0.html","link":"","permalink":"https://cattenlinger.github.io/2024/10/31/136a9b17c9e0.html","excerpt":"","text":"突然有个想法，想直接下载 html 文件并将里面的 meta 标签都拿出来，于是便去翻 Google 了。 xmllint 命令是 libxml 附带的工具（GNOME libxml2）。其中一个用法是通过 --xpath 来选择输出对应的元素。而 XPath（XML Path Language）是一个设计来查询 xml 内容的语言，可以在对应的维基页面查看描述。 一个简单的用法： 1234567891011121314curl -s &#x27;https://www.youtube.com/watch?v=973sEAQZKzY&#x27; | xmllint --html --xpath /html/head/meta -# Outputs:# &lt;meta charset=&quot;UTF-8&quot;/&gt;# &lt;meta name=&quot;ResourceLoaderDynamicStyles&quot; content=&quot;&quot;/&gt;# &lt;meta name=&quot;generator&quot; content=&quot;MediaWiki 1.43.0-wmf.26&quot;/&gt;# &lt;meta name=&quot;referrer&quot; content=&quot;origin&quot;/&gt;# &lt;meta name=&quot;referrer&quot; content=&quot;origin-when-cross-origin&quot;/&gt;# &lt;meta name=&quot;robots&quot; content=&quot;max-image-preview:standard&quot;/&gt;# &lt;meta name=&quot;format-detection&quot; content=&quot;telephone=no&quot;/&gt;# &lt;meta name=&quot;viewport&quot; content=&quot;width=1120&quot;/&gt;# &lt;meta property=&quot;og:title&quot; content=&quot;XPath - Wikipedia&quot;/&gt;# &lt;meta property=&quot;og:type&quot; content=&quot;website&quot;/&gt; 需要注意，在对 html 使用的时候，需要加上 --html 参数。xmllint 会通过 stderr 输出原 html 里有问题的地方，可以按需忽略。 如此整齐的输出，可以在后面接诸如 sed、tr、awk、grep 之类的文本流处理命令了。","categories":[],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://cattenlinger.github.io/tags/Linux/"},{"name":"Bash","slug":"Bash","permalink":"https://cattenlinger.github.io/tags/Bash/"},{"name":"Shell","slug":"Shell","permalink":"https://cattenlinger.github.io/tags/Shell/"},{"name":"xmllint","slug":"xmllint","permalink":"https://cattenlinger.github.io/tags/xmllint/"},{"name":"XPath","slug":"XPath","permalink":"https://cattenlinger.github.io/tags/XPath/"},{"name":"XML","slug":"XML","permalink":"https://cattenlinger.github.io/tags/XML/"}]},{"title":"Linux 下 VM 使用 vfio-pci 进行 PCIe Passthrough","slug":"Linux-下-VM-使用-vfio-pci-进行-PCIe-Passthrough","date":"2022-12-19T13:22:52.000Z","updated":"2025-03-24T00:44:11.482Z","comments":true,"path":"2022/12/19/907ee8908b0c.html","link":"","permalink":"https://cattenlinger.github.io/2022/12/19/907ee8908b0c.html","excerpt":"","text":"在此记录一下如何在 Linux 下启用 PCIe Passthrough 给虚拟机提供宿主 PCIe 设备。 我用的是 Ubuntu 22.04，现在新的系统内核一般内置了 vfio-pci 模块，可以直接使用。以 Intel Xeon E5-2670 为例子。 通过内核启动参数使用需要修改 /etc/defaults/grub，给 GRUB_CMDLINE_LINUX_DEFAULT 增加如下参数： 1iommu=pt intel_iommu=on vfio-pci.ids=&#123;DEVICE_ID_1&#125;,&#123;DEVICE_ID_N&#125; vfio-pci.disable_idle_d3=1 kvm_intel.nested=1 kvm_intel.emulate_invalid_guest_state=0 intel 相关的参数是 Intel 专用，amd 的需要参阅参考资料对应修改。 vfio-pci.ids= 后填设备的 ID，可以通过 lspci -nnv 看到，例如我的 GTX560： 12345678910111213141516171819202104:00.0 VGA compatible controller [0300]: NVIDIA Corporation GF114 [GeForce GTX 560] [10de:1201] (rev a1) (prog-if 00 [VGA controller]) Subsystem: NVIDIA Corporation GF114 [GeForce GTX 560] [10de:0895] Physical Slot: 5 Flags: fast devsel, IRQ 11, IOMMU group 29 Memory at cc000000 (32-bit, non-prefetchable) [disabled] [size=32M] Memory at d0000000 (64-bit, prefetchable) [disabled] [size=128M] Memory at d8000000 (64-bit, prefetchable) [disabled] [size=64M] I/O ports at c000 [disabled] [size=128] Expansion ROM at ce000000 [disabled] [size=512K] Capabilities: &lt;access denied&gt; Kernel driver in use: nouveau Kernel modules: nvidiafb, nouveau04:00.1 Audio device [0403]: NVIDIA Corporation GF114 HDMI Audio Controller [10de:0e0c] (rev a1) Subsystem: NVIDIA Corporation GF114 HDMI Audio Controller [10de:0895] Physical Slot: 5 Flags: fast devsel, IRQ 7, IOMMU group 29 Memory at ce080000 (32-bit, non-prefetchable) [disabled] [size=16K] Capabilities: &lt;access denied&gt; Kernel driver in use: snd_hda_intel Kernel modules: snd_hda_intel 04:00.0 是设备物理位置，也就是插槽的位置，只要不换插槽就不会变。设备名称后面的 10de:1201 就是设备 ID。如果显卡带音频控制器，需要一同 passthrough。这里我就应该填 vfio-pci.ids=10de:1201,10de:0e0c。 修改完成后执行 sudo update-grub 更新 GRUB 配置。重启之后通过 lspci -nnv 查，就能看到对应设备的 Kernel driver in use 变成了 vfio-pci 了： 12345678910111213141516171819202104:00.0 VGA compatible controller [0300]: NVIDIA Corporation GF114 [GeForce GTX 560] [10de:1201] (rev a1) (prog-if 00 [VGA controller]) Subsystem: NVIDIA Corporation GF114 [GeForce GTX 560] [10de:0895] Physical Slot: 5 Flags: fast devsel, IRQ 11, IOMMU group 29 Memory at cc000000 (32-bit, non-prefetchable) [disabled] [size=32M] Memory at d0000000 (64-bit, prefetchable) [disabled] [size=128M] Memory at d8000000 (64-bit, prefetchable) [disabled] [size=64M] I/O ports at c000 [disabled] [size=128] Expansion ROM at ce000000 [disabled] [size=512K] Capabilities: &lt;access denied&gt; Kernel driver in use: vfio-pci Kernel modules: nvidiafb, nouveau04:00.1 Audio device [0403]: NVIDIA Corporation GF114 HDMI Audio Controller [10de:0e0c] (rev a1) Subsystem: NVIDIA Corporation GF114 HDMI Audio Controller [10de:0895] Physical Slot: 5 Flags: fast devsel, IRQ 7, IOMMU group 29 Memory at ce080000 (32-bit, non-prefetchable) [disabled] [size=16K] Capabilities: &lt;access denied&gt; Kernel driver in use: vfio-pci Kernel modules: snd_hda_intel 当即启用当即启用其实就是更改设备当前的驱动。更改之前需要关闭所有用到目的显卡的软件例如 xserver 以及 nVidia 相关的服务。先进入到其他的控制台例如 Ctrl + Alt + F2 进入 tty2，之后关闭对应的服务，更换驱动。 或许还需要卸载掉 nVidia 相关的驱动，可以参考这个链接的问题：VGA passthrough with QEMU and KVM - Nothing on screen 更换驱动需要知道当前设备在使用什么驱动。可以通过 ls -nnv 查看，例如我的 NVS 450： 123456789101107:00.0 3D controller [0302]: NVIDIA Corporation G98 [Quadro NVS 450] [10de:06fa] (rev a1) Subsystem: NVIDIA Corporation G98 [Quadro NVS 450] [10de:0619] ... Kernel driver in use: nouveau Kernel modules: nvidiafb, nouveau08:00.0 VGA compatible controller [0300]: NVIDIA Corporation G98 [Quadro NVS 450] [10de:06fa] (rev a1) (prog-if 00 [VGA controller]) Subsystem: NVIDIA Corporation G98 [Quadro NVS 450] [10de:0619] ... Kernel driver in use: nouveau &lt;&lt;&lt; 这个 Kernel modules: nvidiafb, nouveau 它正在使用 nouveau，且需要记下显卡的设备物理地址（也就是 bus id），这里同时带了 3D controller，所以是 07:00.0 和 08:00.0。 然后到 /sys/bus/pci/drivers 下，进入驱动名称的文件夹。我这里是 nueveau 在用显卡，所以完整路径为 /sys/bus/pci/drivers/nueveau。可以看到以上 id 都在这个文件夹下： 12cattenlinger@Z420:/sys/bus/pci/drivers/nouveau$ ls0000:07:00.0 0000:08:00.0 bind module new_id remove_id uevent unbind 需要做的就是解绑驱动，给 unbind 这个文件喂对应的 ID： 123cd /sys/bus/pci/drivers/nueveauecho 0000:07:00.0 &gt; ./unbindecho 0000:08:00.0 &gt; ./unbind 这样就能卸载驱动了。然后得挂上 vfio-pci 的驱动。进入 vfio-pci 的驱动文件夹，记下显卡的设备 ID，并喂给 new_id： 123cd /sys/bus/pci/drivers/vfio-pci# 第一个是 vendor id，第二个是 product id。echo 10de 06fa &gt; ./new_id 这样就挂上了。 把设备分配给 VM我使用的是 QEMU，virt-manager 一样，只是换成了图形化界面。 给 QEMU 命令添加上这些个设备： 12-device vfio-pci,host=04:00.0,multifunction=on,romfile=&quot;$FIRMWARE_DIR/vbios.bin&quot;-device vfio-pci,host=04:00.1 小插曲如果显卡比较老（10XX 系列以下，amd 的我不熟不知道），还需要 vbios 文件，就是上面第一条命令的 romfile 参数。这个操作比较麻烦，可以参考这个连接：Preparation and placing of the ROM file。如果的确不方便用 Windows，也没法通过对应的 firmware upgrader 获取 vbios，可以尝试去 TECHPOWERUP - VGA VIOS 下载，但其实不建议，因为每台机子的 vbios 可能都不太相同。 如果不方便用 GPU-Z ，也可以用 CPU-Z。CPU-Z 出来的文件是 ASCII 的 dump，还需要手动转换为 binary。这里建议使用这个命令： 1xxd -r -p vbios.txt vbios.bin 我的显卡就比较老，所以需要一个 vbios 来让 OVMF 去驱使显卡。 听说 N 卡比较难伺候，即便 Passthrough 进去了也很大可能用不了，我就一时能用一时不能，老显卡的话建议 AMD。","categories":[{"name":"Linux 技术应用","slug":"Linux-技术应用","permalink":"https://cattenlinger.github.io/categories/Linux-%E6%8A%80%E6%9C%AF%E5%BA%94%E7%94%A8/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://cattenlinger.github.io/tags/Linux/"},{"name":"Virtual","slug":"Virtual","permalink":"https://cattenlinger.github.io/tags/Virtual/"},{"name":"Machine","slug":"Machine","permalink":"https://cattenlinger.github.io/tags/Machine/"},{"name":"PCIe","slug":"PCIe","permalink":"https://cattenlinger.github.io/tags/PCIe/"},{"name":"Passthrought","slug":"Passthrought","permalink":"https://cattenlinger.github.io/tags/Passthrought/"},{"name":"Ubuntu","slug":"Ubuntu","permalink":"https://cattenlinger.github.io/tags/Ubuntu/"},{"name":"QEMU","slug":"QEMU","permalink":"https://cattenlinger.github.io/tags/QEMU/"},{"name":"vfio-pci","slug":"vfio-pci","permalink":"https://cattenlinger.github.io/tags/vfio-pci/"},{"name":"vfio","slug":"vfio","permalink":"https://cattenlinger.github.io/tags/vfio/"}]},{"title":"「Linux 玩耍記事」製作一個發行版·肆：make-tinycore-linux","slug":"「Linux-玩耍記事」製作一個發行版·肆：make-tinycore-linux","date":"2022-08-31T15:27:27.000Z","updated":"2025-03-24T00:44:42.302Z","comments":true,"path":"2022/08/31/a1cd478ed3f6.html","link":"","permalink":"https://cattenlinger.github.io/2022/08/31/a1cd478ed3f6.html","excerpt":"","text":"其中用到的程式碼可能會有變化。根據實際情況理解。 整體設計make-tinycore-linux 是一個把以下流程跑一遍的腳本： 12345678910111213141516apply_build_rc ---------------------- 應用 build.rc 設定（如果有）apply_tc_settings ------------------- 根據設置判斷 TinyCore 資源文件路徑prepare_workspace ------------------- 準備工作區（build 檔案夾）|\\- (clean-up hook install) --------- 安裝退出鉤子（按需清理 build 檔案夾）prepare_tinycore_linux_image -------- 下載 TinyCore 的內核以及 initrd 檔prepare_packages -------------------- 準備每一個軟件包（如果有）|\\- resolve_packages ---------------- 解析安裝包依賴| \\- resolve_package_recursively -- 遞歸處理安裝包依賴|\\- download_and_unpack_packages ---- 根據安裝包列表下載安裝包並解包extract_rootfs ---------------------- 解包 initrd 到 rootfsapply_packages ---------------------- 拷貝安裝包到 rootfsapply_additional_patchs ------------- 應用額外處理過程（如果有）generate_new_rootfs ----------------- 打包 initrd 到目的地copy_core --------------------------- 複製內核文件到目的地(execute clean-up hook) ------------- 一但腳本結束就會觸發這個退出鉤子 每一個流程都對應著一個 bash 函数，函數定義的順序也剛好就是執行順序。 整個腳本可以分成以下階段： 配置处理：apply_build_rc, apply_tc_settings, prepare_workspace 系统下载：prepare_tinycore_linux_image 軟件依賴處理：prepare_packages 修改階段：extract_rootfs, apply_packages, apply_additional_patches 構建階段：generate_new_rootfs, copy_core 配置處理於 apply_build_rc 之前，腳本還會作一系列檢查： 當前用戶是否為 root。畢竟 rootfs 內的大部分檔案權限都是 root。 檢查依賴的命令是否存在。当前来说 curl、unsquashfs、cpio、zcat、uniq 都是必须的。 這時候以下命令被定義： require：檢查給定命令是否存在 DOWNLOAD：下載檔案 FETCH：獲取 http 檔案內容 cache_files_enabled: 判斷檔案緩存是否被啟用 apply_build_rc 會在當前目錄尋找 build.rc。如果存在，則應用它。所以，變量都可從此文件中修改。 apply_tc_settings 根據設定的 TC_VERSION 和 TC_ARCH 來決定遠端 repo 裡，內核和 initrd 的的檔案名。若為 x86，則為 vmlinuz 和 core.gz；若為 x86_64，則為 vmlinuz64 和 corepure64.gz。這兩個變量的默認值是 13 和 x86_64。 prepare_workspace 做了如下事情： 檢查 build 檔案夾是否存在。若不存在則創建。 安裝退出鉤子。當腳本結束時選擇是否執行鉤子（通過 DO_NOT_CLEAN_UP 控制） 系統下載prepare_tinycore_linux_image 很簡單： 如果沒有緩存，下載內核 如果沒有緩存，下載 initrd 如果緩存被關閉，將會安裝對應的刪除鉤子。 軟件依賴處理prepare_packages 會定義三個函數： resolve_packages resolve_package_recursively download_and_unpack_packages 主要的流程是先 resolve_package，然後 download_and_unpack_packages。但為了實現遞歸依賴處理，需要 resolve_package_recursively 來幫忙。它的原理很簡單： 12345678910111213141516171819202122232425resolve_package_recursively() &#123; local pkgname=&quot;$1&quot; local depth=&quot;$2&quot; local pkgdep=&quot;$PACKAGE_DIR/$pkgname.dep&quot; # 如果包名稱為空，則推出 [ -z &quot;$pkgname&quot; ] &amp;&amp; return 0 # 好看的輸出 echo &quot;$depth|- $pkgname&quot;; # 下載依賴列表文件，輸出到位置 $pkgdep (FETCH -sf &quot;$TC_REPO/$TC_VERSION.x/$TC_ARCH/tcz/$pkgname.dep&quot; || :)&gt;&gt; &quot;$pkgdep&quot;; # 如果 依賴列表文件行數大於 0 的話，讀入每一行，清除空行，並循環讀取到 pkg 變量（這裡用了管道符，所以開啟了 subshell） [ 0 -lt `cat &quot;$pkgdep&quot; | wc -l | tr -d &#x27;[:space:]&#x27;` ] &amp;&amp; cat &quot;$pkgdep&quot; | sed &#x27;/^$/d&#x27; | while read pkg do resolve_package_recursively $pkg &quot;$depth &quot; done # Add package and dependencies to the temp file echo &quot;$pkgname&quot; &gt;&gt; &quot;$PACKAGE_LIST.tmp&quot; cat &quot;$pkgdep&quot; &gt;&gt; &quot;$PACKAGE_LIST.tmp&quot; do_not_clean_up || rm -rf &quot;$pkgdep&quot; &#125; wc -l 是計算输入文件行數的意思，但它的輸出数字开头會包含空格，所以用 tr -d [:space:] 過濾掉空格之後就只剩下数字了。tr -d 意思是刪除匹配的字符，而這裡匹配的是空格。。 cat &quot;$pkgdep&quot; | sed &#39;/^$/d&#39; 中 sed 用於過濾掉包依賴列表裡的空行。从 http 服务器获取的内容是不可控的，为了防止空行带来的问题，我这里用 sed 清除掉所有空行，同时 resolve_package_recursively 在遇到空包名的時候也會退出循環。雙保險 以上過程最後，會產出一個 PACKAGE_LISR 的文件，包含去重之後的結果。這個文件列表就可以拿去對照著從 tinycore 下載軟件了。 每次下載包含下載和解包兩個操作。當緩存中（build/tcz）存在這個包，則跳過下載。加載完成後，開啟一個 sub-shell 來執行解包。 123456789101112131415161718192021download_and_unpack_packages() &#123; echo &quot;Start preparing $(cat &quot;$PACKAGE_LIST&quot; | wc -l | tr -d &#x27;[:space:]&#x27;) packages...&quot; local _IFS=&quot;$IFS&quot; IFS=$&#x27;\\n&#x27; local i for i in $(cat &quot;$PACKAGE_LIST&quot;) do [ -z &quot;$i&quot; ] &amp;&amp; continue [ -f &quot;$PACKAGE_DIR/$i&quot; ] || ( echo &quot;Fetching package &#x27;$i&#x27;...&quot; ; cd &quot;$PACKAGE_DIR&quot; ; DOWNLOAD &quot;$TC_REPO/$TC_VERSION.x/$TC_ARCH/tcz/$i&quot; -o &quot;$i.tmp&quot; ; mv &quot;$i.tmp&quot; &quot;$i&quot; ; ) # 解包 ( echo &quot;Unpacking &#x27;$i&#x27;...&quot;; cd &quot;$BUILD_DIR&quot;; unsquashfs -quiet -f &quot;$PACKAGE_DIR/$i&quot; ; ) done IFS=&quot;$_IFS&quot;&#125; unsquashfs 使用 quiet 可以只輸出進度條。配合只顯示進度條的 DOWNLOAD 命令（稍後會講的），看著就很不錯。 修改修改的第一步是先解包。 extract_rootfs 就是簡單地把 initrd 解壓出來 1( mkdir -p &quot;$rootfs&quot;; cd &quot;$rootfs&quot;; gzip -d -c &quot;$BUILD_DIR/$TC_RAMDISK&quot; | cpio -idm ) apply_packages 把解包後的軟件拷貝到 rootfs 檔案夾，維持原有權限設置，覆蓋內容。 1cp -Rp &quot;$BUILD_DIR/squashfs-root/usr/.&quot; &quot;$BUILD_DIR/rootfs/usr/&quot; apply_additional_patches 檢查 build.rc 中是否有定義 additional_patchs。若有，則執行 123456apply_additional_patchs() &#123; if declare -f additional_patchs &gt; /dev/null 2&gt;&amp;1 then ( echo &quot;Applying additional patchs.&quot;; cd $BUILD_DIR; additional_patchs; ) fi&#125; 構建這一階段就是把 rootfs 重新打包成 initrd。然後把內核複製到目的地，完工。 12345678910generate_new_rootfs() &#123; # repackage core into initrd.gz echo &quot;Generating new rootfs&quot; ( cd &quot;$BUILD_DIR/rootfs&quot; ; find -P . | cpio -o -H newc ) | gzip -c &gt; &quot;$BUILD_OUTPUT/initrd.gz&quot;&#125;copy_core() &#123; echo &quot;Copying Linux core&quot; cp &quot;$BUILD_DIR/$TC_CORE&quot; &quot;$BUILD_OUTPUT/vmlinuz&quot;&#125; DOWNLOAD 和 FETCH我使用了 DOWNLOAD 和 FETCH 兩個指令來區分文件下載和信息獲取操作。 123456789CURL_DOWNLOAD=&quot;curl -L -# --retry 10 --retry-all-errors --connect-timeout 5 --speed-limit 10 --speed-time 5&quot;DOWNLOAD() &#123; eval &quot;$CURL_DOWNLOAD $@&quot;&#125;CURL_FETCH=&quot;curl -sfL --retry 10 --connect-timeout 5 --speed-time 5&quot;FETCH() &#123; eval &quot;$CURL_FETCH $@&quot;&#125; --retry 指定重試次數；-L 跟隨跳轉；-s 是安靜模式，不輸出信息；-f 是遇到错误时安静不输出；--retry-all-errors 任何錯誤出現都重試；--connect-timeout 連接超時秒數；--speed-limit 低於這個速度重試；--speed-time 速度低於指定速度多久之後重試，如果不指定速度，則默認為 1；-# 打印一個進度條。 下回分解下一篇文章將講解內核啟動後的配置過程是如何實現的。 （未完待續）","categories":[{"name":"Linux 技术应用","slug":"Linux-技术应用","permalink":"https://cattenlinger.github.io/categories/Linux-%E6%8A%80%E6%9C%AF%E5%BA%94%E7%94%A8/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://cattenlinger.github.io/tags/Linux/"}]},{"title":"「Linux 玩耍記事」製作一個發行版·叁：用工具搞定這些麻煩事","slug":"「Linux-玩耍記事」製作一個發行版·叁：用工具搞定這些麻煩事","date":"2022-08-31T13:59:24.000Z","updated":"2025-03-24T00:44:49.718Z","comments":true,"path":"2022/08/31/f06ba44d9ade.html","link":"","permalink":"https://cattenlinger.github.io/2022/08/31/f06ba44d9ade.html","excerpt":"","text":"回顧先前的壹、貳篇已經大概講述了一個 Linux 系統的基本要素，以及怎麼基於 tinycore linux 的 initrd 來製作自定義的 initrd。在這篇開始之前先來回顧一下。 首先，一個 Linux 系統包含兩個基本部分，程序和數據。程序是 Linux 內核，而數據就是初始的根文件系統。啟動一個 Linux 操作系統即是由引導器加載 initrd，以及命令行參數 cmdline，然後加載並調用 Linux 內核。雖然之前的例子裡直接使用 qemu 加載內核和 initrd，但其實其他啟動器（例如 GRUB）其實都是幹了相同的事情。 從源代碼編譯一個 Linux 內核是當然可以的。但對於製作一個發行版，怎麼寫系統文件以及提供什麼工具命令才是更為重要的。內核編譯的調參是屬於高級操作，是精益求精，在這之前我更注重先把基本框架描述好。 所以我們現在手頭擁有了這些概念和工具： 內核 initrd initrd 的解包和重打包 軟件的下載 用 qemu 直接加載系統調試 不斷手動重複這些操作對於人來說是繁瑣的，而且還容易出錯。這時最好就有一個你能輕易搞明白的程序幫你規範好這些操作，減少錯誤的發生、加速重複過程的執行。 規則是死的，人是活的；任何系統中最脆弱的環節一直都是人。 —— 斯·沃碩德 The tool說了這麼多，終於到了說具體工具的時候了。 make-tinycore-linux 是我把第二篇中步驟細化完善後編寫出來的 shell 腳本工具。僅需要一個（可選的）build.rc 文件即可描述對 TinyCore initrd 的修改。原理十分簡單，但這裡我先介紹如何使用。 我們先規範一下目錄結構，設定工作目錄應該如下： 123tinycore-build|- bin|- build.rc 其中 bin 存放著幫助你構建的簡單命令，而 build.rc 則是描述構建內容的文檔。 我們先來看看 build.rc 的樣例： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455# 選擇 TinyCore 的版本號# 參考 http://tinycorelinux.net/downloads.htmlTC_VERSION=13# 選擇 TinyCore 的架構# 參考 http://tinycorelinux.net/TC_VERSIONTC_ARCH=x86_64# 更改 TinyCore Linux 的倉庫地址#TC_REPO=&quot;http://tinycorelinux.net/&quot;# 更改輸出目錄，默認是當前執行目錄#BUILD_OUTPUT=&quot;$WORK_DIR&quot;# DOWNLOAD 是用於下載文件的 CURL 命令# 更改 CURL_DOWNLOAD 的值以修改其行為#CURL_DOWNLOAD=&quot;$CURL_DOWNLOAD &quot;# FETCH 是用於獲取遠端文本的 CURL 命令# 更改 CURL_FETCH 的值以修改其行為#CURL_FETCH=&quot;$CURL_FETCH &quot;# 緩存下載了的文件CACHE_FILES=true# 不要在構建完成後執行清潔鉤子# 注意，如果開啟，則需要在每次構建前清理 build 目錄# 否則構建會失敗#DO_NOT_CLEANUP=true# PACKAGES 包含需要被包含進 rootfs 的 tcz 包名字# 參考 TinyCore 的倉庫# 依賴會被自動拉取：DPACKAGES=( &quot;bash&quot; &quot;iproute2&quot; &quot;fuse&quot;)################################################################additional_patchs() &#123;################################################################# 針對 rootfs 的額外修改# rootfs 在 $BUILD_DIR/rootfs 下## PACKAGE_DIR 是包含已下載的軟件包的目錄# BUILD_DIR 是構建目錄# WORK_DIR 是工作目錄#################################################################: 在這裡寫你的其他 rootfs 修改（建議不要刪掉這行喔）################################################################&#125;# END build.rc 相信熟悉 Linux 的人都知道，build.rc 是一個 shell 腳本。但可以些少點腳本來達到「安全地靈活」的目的，何樂而不為（畢竟是我幫忙寫和調試了嘛 XD） 現在我們有 build.rc 了，執行這個工具有兩種方式： 直接通過 curl 下載並喂給 bash（在 README 裡有寫） 先下載，然後執行（下載好之後建議放到 bin 目錄裡） 注意，因為修改、打包 rootfs 涉及到塊設備、字符設備以及權限維持等等的問題，這個工具必須要以 root 權限運行 以下假設你用的是第二種方式。那麼我們就直接執行： 1sudo ./bin/make-tinycore-linux 你應該會看到一行行輸出提示它運行到哪了。成功結束後，產物就會出現在你指定的地方。 它會產生出一個 build 文件夾，裡面是構建時的緩存和中間產物。如果 DO_NOT_CLEANUP=true，連臨時文件都會出現在裡面。你可以借這個機制去觀察它的工作方式。但這樣的話，建議你每次構建前最好都手動刪掉整個 build 文件夾，我還沒讓這個腳本智能到在這種情況下依舊能自動刪除（或許以後的版本會有）。 添加點額外的修改相信你應該會留意到那個顯眼的 additional_patchs。這裡提前說一下，它會在打包 initrd 之前，所有軟件合併到 rootfs 文件夾裡的時候 經歷過構建，我猜你現在的文件目錄結構應該是這樣的了 123456tinycore-build|- bin|- build.rc|- build|- vmlinuz|- initrd.gz 在給 additional_patches 添加內容之前，建議你先創建一個 patches 目錄。 按照建議，patches 目錄應該模仿根文件系統的目錄結構。其內容會在打包 initrd 之前覆蓋到 rootfs 文件夾裡。舉個例子我們需要增加一個腳本 helloworld： 123456789tinycore-build|- bin|- build.rc|- build|- patches |- bin |- helloworld|- vmlinuz|- initrd.gz 僅僅只是塞一句話進去： 12#!/bin/busybox ashecho &quot;Hello world! Now is: $(date)&quot; 在 additional_patches 裡這樣寫： 1234# 拷貝內容到 rootfs 文件夾內cp -Rp $WROK_DIR/patches/. $BUILD_ROOT/rootfs/# 允許其被當作程式執行chmod +x &quot;$BUILD_ROOT/rootfs/bin/helloworld&quot; 重新執行 ./bin/make-tinycore-linux，啟動虛擬機，輸入 helloworld，你應該就能看到 Hello World 以及一個日期時間了。 ✅ 小提示：你可以在 build.rc 裡 source 額外的私人配置，或者額外的過程來幫助你做更複雜的構建。 不過我建議你的 shell 代碼應該要寫得夠簡潔夠清晰。比起其他編程語言，shell script 的可讀性還是不太好的。 當你的構建越來越複雜了，我希望你能用更高級的語言來實現ーー不过到那时候，你也应该不需要我的这个小工具了吧（：D ⚠️ Note: Don’t use Bash everywhere! ⚠️ Although Bash is universal and elegant to programmatically execute unix commands, and apply logic to them, it can quickly get cumbersome once you start doing complex things like working with floating point numbers or find yourself needing arrays or other sophisticated datastructures.-- Bash scripting(wiki.ghpc.au.dk) 下回分解我是很樂意分享這個工具的工作流程的，畢竟還是翻了不少資料、溫習補習了很多工具指令和 shell 特性之後造出來的「作業」。我希望它以十分簡單的方式工作，也希望它的代碼能比較簡單。 所以下一章將會講 make-tinycore-linux 的工作流程 下一篇：「Linux 玩耍記事」製作一個發行版·肆：make-tinycore-linux","categories":[{"name":"Linux 技术应用","slug":"Linux-技术应用","permalink":"https://cattenlinger.github.io/categories/Linux-%E6%8A%80%E6%9C%AF%E5%BA%94%E7%94%A8/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://cattenlinger.github.io/tags/Linux/"}]},{"title":"「Linux 玩耍記事」製作一個發行版·貳：著手開搞","slug":"「Linux-玩耍記事」製作一個發行版·貳：著手開搞","date":"2022-08-31T10:16:29.000Z","updated":"2025-03-24T00:44:53.555Z","comments":true,"path":"2022/08/31/4238b6ef5126.html","link":"","permalink":"https://cattenlinger.github.io/2022/08/31/4238b6ef5126.html","excerpt":"","text":"開搞步驟基於別人的 initrd 開始搞是很簡單的事。就像把大象放進冰箱裡一樣，思路很簡單，就四步： 下載 initrd 解壓 initrd 修改 initrd 打包 initrd 但都知道細節才是重點，本文將一步步解釋如何實現以上四點，以及其中的工具怎麼用 在繼續之前，不妨先弄一個目錄作為工作目錄，就叫 tinycore-linux-build 好了 本文將使用 x86_64 架構的 TinyCore 13 為例子。 下載從 https://distro.ibiblio.org/tinycorelinux/13.x/x86_64/release/distribution_files/corepure64.gz 下載 initrd 即可。 解壓注意，因為修改和打包 rootfs 涉及到塊設備、字符設備以及「權限保持」等問題，涉及到對 rootfs 的修改都需要使用 root 權限 新建一個目錄 rootfs，然後 12# 在一個 subshell 內執行：進入目錄 rootfs，用 gzip 解壓 initrd 到管道喂進 cpio( cd &quot;rootfs&quot;; gzip -d -c &quot;../corepure64.gz&quot; | cpio -idm ) 這裡用了括號把內容括起來，這樣語句就在 subshell 內執行，命令執行完畢對當前 shell 沒有影響。 命令內用到 gzip 和 cpio 命令，詳細講講這兩個命令以及參數 gzip 命令 -d：解壓模式 -c：輸出到 stdout，保留原檔案 cpio 命令cpio 這裡用了聚合選項，-idm 是等價於 -i -d -m 的。 -i：「輸入並解包」模式，從 stdin 讀取內容 -d：按需創建目錄 -m：保留修改時間不變 至此，就可以在 rootfs 得到 initrd 的內容了。 修改rootfs 內的東西，就是 TinyCore 啟動時使用的數據，所以可以按需修改成自己想要的東西。 後面的章節會詳細講述部分檔案和配置。現在就先把解包和打包都做一遍先。 打包修改完成後，執行： 123# 進入 rootfs，找出所有文件，並把列表喂給 cpio。將 subshell 的# stdout 喂給 gzip 壓縮，輸出到 initrd.gz( cd &quot;rootfs&quot; ; find -P . | cpio -o -H newc ) | gzip -c &gt; &quot;../initrd.gz&quot; 這裡用到了 find 和 cpio 的另一個模式 find 命令 -P：不進入鏈接，這是默認行為，可以不添加 .：指定搜索當前目錄 cpio 命令 -o：「打包並輸出」模式，從 stdin 讀取文件列表 -H：指定打包格式，這裡使用 newc（The SVR4 portable cpio format.），可以用 –help 查看支持的模式 開始測試開始測試之前，我們還得把內核搞到手，從 https://distro.ibiblio.org/tinycorelinux/13.x/x86_64/release/distribution_files/vmlinuz64 下載即可。 qemu 的使用qemu 的使用有點複雜，需要參考一下 QEMU 的 Wiki 來敲命令，也可以打開 Arch Wiki 一起使用（效果更好）。 創建虛擬硬碟雖然本例暫時不需要用到硬碟，但這裡也提及一下如何創建一個 qcow2 的硬碟： 1qemu-img create -f qcow2 disk01.qcow2 32G create：創建指令 -f：指定磁碟映像格式，這裡使用 qcow2 disk01.qcow2：文件名 32G：大小，這裡是 32 GB。 qcow2 格式默認是按用量分配的，所以立即就能創建出來。 啟動這裡先給出命令 1234567891011121314qemu-system-x86_64 \\ -m 1G -smp 2 -machine type=q35,accel=hvf \\ -drive file=disk01.qcow2,format=qcow2 \\ -netdev user,id=network0 \\ -vga virtio \\ -device ich9-intel-hda \\ -device qemu-xhci \\ -device usb-tablet \\ -device e1000,netdev=network0 \\ -display default,show-cursor=on \\ -kernel &quot;vmlinuz64&quot; \\ -initrd &quot;initrd.gz&quot; \\ -append &quot;vga=917 loglevel=3 panic=10&quot; \\ ; qemu-system-x86_64 是創建 x86_64 虛擬機 -m：指定內存，這裡給了 1GB -smp：指定核心數，這裡給了兩個核 -machine：指定模擬的機器參數，這裡 type 選 q35，accel 是加速方式，我在 macOS 上所以選 hvf，linux 需用 kvm -netdev：創建一個網絡設備，用 user network 模式，給一個引用 id network0 -vga：指定圖形驅動架構，這裡選 virtio -device：添加設備 -display：指定輸出顯示方式，這裡用默認模式，顯示指針（就是會出來一個窗口作為虛擬機的顯示器） -kernel：指定 linux 內核檔，直接啟動 -initrd：指定 linux 的 initrd 檔 -append：傳入內核參數 device 選項我添加了如下設備： ich9-intel-hda：ich9 聲卡 qemu-xhci：USB root hub，選用這個是因為它還支持 USB 3.0 usb-tablet：貌似是用來模擬觸摸屏的，必須先給了 usb root hub 才能用這個選項 e1000：e1000 網卡，網絡使用 network0 同時指定了這些內核參數： vga&#x3D;917：使用 917 作為 vga mode，更改分辨率的意思。可通過 vga&#x3D;ask 來讓內核詢問使用哪個模式。这个数字是 1600x900 顏色深度 32 的意思。但需要注意，在啟動時的詢問菜單中輸入的是十六進制，而在啟動時填入的內核參數是十進制。 loglevel&#x3D;3：設定內核的日誌等級，3 指僅輸出 ERROR 以及更重要日誌。 panic&#x3D;10：內核崩潰後，等待 10 秒自動重啟。 更多的內核參數可以查看 kernel.org 的 The kernel’s command-line parameters。 運行後就應該能看到 qemu 窗口，也看到系統的啟動了。 預安裝一些軟件如果你並沒有怎麼修改，現在的 initrd 應該是沒什麼東西的。它甚至缺乏一些現代的命令（例如 iproute2）。那麼我們就以 iproute2 為例子，把它塞進 initrd 裡吧。 包依賴處理、下載首先可以从 https://distro.ibiblio.org/tinycorelinux/13.x/x86_64/tcz 找到 iproute2.tcz，然后检查一下依赖： 1&gt; curl https://distro.ibiblio.org/tinycorelinux/13.x/x86_64/tcz/iproute2.tcz.dep 應該會得到如下返回： 1db.tcz 也就是說這個包依賴 db.tcz，那麼繼續查下去 12&gt; curl https://distro.ibiblio.org/tinycorelinux/13.x/x86_64/tcz/db.tcz.deplibdb.tcz 重複直到返回 404，我們應該就能得到一個包列表了： 123iproute2.tczdb.tczlibdb.tcz 這就是遞歸依賴處理，人工操作一個兩個還好，但如果包比較多，依賴深度大，就會很麻煩，後期我們將會用程式來實現這個過程。 解壓、合并檔案到 initrd把所需要的包都下載下來，然後用 squashfs-tools 解開 1234for i in iproute.tcz db.tcz libdb.tczdounsquashfs -f &quot;$i&quot;done unsquash 命令 -f：指定文件 默認 unsquashfs 會把文件放到 squashfs-root 中 那么现在就可以把文件内容复制到 rootfs 中： 1cp -Rp &quot;squashfs-root/usr/.&quot; &quot;rootfs/usr/&quot; cp 命令 -R：原樣拷貝文件，不跟隨軟連結 -p：保持文件的訪問控制符不變 完成現在重複打包步驟，再次啟動虛擬機，在其中輸入 ip 命令，應該就有了。 下回分解手動操作這個過程還是比較繁瑣。接下來會用到我自己寫的工具來構建這麼一個迷你發行版，也會解釋這個工具的工作方式。用它來構建的話過程會簡單很多。 可以訪問我的 GitHub 首頁倉庫獲取以及查閱幫助：tools&#x2F;make-tinycore-linux 這個迷你發行版也在我的 GitHub 上：CattenLinger&#x2F;jam.linux 下一篇：「Linux 玩耍記事」製作一個發行版·叁：用工具搞定這些麻煩事","categories":[{"name":"Linux 技术应用","slug":"Linux-技术应用","permalink":"https://cattenlinger.github.io/categories/Linux-%E6%8A%80%E6%9C%AF%E5%BA%94%E7%94%A8/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://cattenlinger.github.io/tags/Linux/"}]},{"title":"「Linux 玩耍記事」製作一個發行版·壹：何謂一個「Linux 發行版」","slug":"「Linux-玩耍記事」製作一個發行版·壹：何謂一個「Linux-發行版」","date":"2022-08-31T08:27:51.000Z","updated":"2025-03-24T00:44:33.288Z","comments":true,"path":"2022/08/31/8fd4a72309d0.html","link":"","permalink":"https://cattenlinger.github.io/2022/08/31/8fd4a72309d0.html","excerpt":"","text":"本文是一系列我嘗試製作一個迷你發行版的筆記，皆旨以最简单的语言（可能还是很啰嗦的语言）来描述如何造一個自己的迷你 Linux 發行版。 啟我還在唸書的時候有很多很大的想法，其中一個便是自己造一個系統。但操作系統編寫是一個龐大的工程，且世界上已經有很多人為此付出很多勞動和心血，業界也是碩果累累。如果論現在重新造一個操作系統有何意義，那大概就只剩下研究操作系統這個領域了。 我從一開始便明白操作系統內核是沒那麼容易編寫的，所以改一個 Linux 系統便是我的首選。 何謂一個「Linux 發行版」Linux 嚴格來說是指 Linux 內核，而 Ubuntu、CentOS、Fedora 等等則稱為「發行版」。構建出內核後，需要再配合一套配置以及一系列程式，才能算是有一個操作系統。 可以這麼簡單地理解：內核是一個可執行檔，而這些配置和程式是數據，給內核喂進去這些配置和程式，就是給程式喂數據，於是這個程式就起來了，用戶就可以開始用系統了。 一套 Linux 操作系統包含的內容可以這麼簡單地概括： 12345┌──────────────────────┐│ Config &amp; Program │└─┬──────────────────┬─┘ │ Linux Kernel │ └──────────────────┘ 一份內核，搭配一套常人概念中的“系統文件”（一般是安裝媒介寫到根目錄下的文件，或者一些嵌入式系統用的記憶體硬碟，也就是 init ram-disk，簡稱initrd ），便是一個簡單的發行版組成了。 構件一套自己的 Linux 操作系統需要些技術，也有現成的教案可以參考，例如 Linux From Scratch，可以直接在線閱讀，也可以下載 PDF（此版本為 11.0）。 從源碼構建需要關心很多東西，在 menuconfig 裡有很多的內核構建選項可以調整，內容十分地多，但為了簡單，我就直接使用別人的内核以及系统文件了。 Linux 內核是如何啟動的通常來說，Linux 內核的啟動是這樣的： 硬件上電後，主板尋找第一個可引導媒體。 主板加載 GRUB。 GRUB 加載 Linux 內核，給定 initrd，以及內核啟動參數。 Linux 內核啟動，initrd 作為根被掛載。 內核尋找 &#x2F;init 或者 &#x2F;sbin&#x2F;init 文件並執行 到這裡就是系統配置幹活的地方了。從開始執行 init 或 &#x2F;sbin&#x2F;init 開始，Linux 內核就已經啟動成功了。後面的一切事情，例如初始化系統組件、程式預啟動甚至進入桌面等等，就是系統，或者說“發行版”的行為了。本文開始自定義發行版的起始邊界就是到 init （或者 &#x2F;sbin&#x2F;init）。 內核其實就是一個普通的應用程序，只是要從 bootloader（一般是 GRUB）處輸入文件名和命令行參數以及指定其需要讀寫的文件（initrd）。內核會根據命令行參數（cmdline）來調整運作方式。cmdline 也可以在內核啟動後通過 /proc/cmdline 訪問得到，所以系統初始化程式可以讀取這個內容來判斷要作何操作。 TinyCore Linux 介紹TinyCore（Linux）是一个很小的 Linux 发行版，完整的 iso 大小就只有 16MB 左右，但也包含了一个 Linux 操作系统该有的东西。它一般直接完整载入内存运行，也可以根据手册来配置本地持久化。 官方网站就是仓库本身，但访问通常都比较慢，所以我这里所有关于 TinyCore 的资源链接都使用镜像 distro.ibiblio.org（之后以 $TC_REPO 代指）。截止目前为止 TinyCore 的版本号（$TC_VERSION 代之）是 13。本文将主要基于 x86_64 架构（$TC_ARCH 代之）的 TinyCore 讨论。 TinyCore 使用自己写的 tce-load 来下载依赖包，它从 $TC_REPO/$TC_VERSION.x/$TC_ARCH/tcz 中搜索依赖并下载安装包。它的安装包以 .tcz 结尾，是一个纯粹的 squashfs。可以在 TinyCore 中执行 tce-load -iw 软件名.tcz 来下载对应的包和依赖。其依赖检索方式很简单，路径是 $TC_REPO/$TC_VERSION.x/$TC_ARCH/tcz/$PACKAGE.tcz.dep，内容是所依赖的包的名称。如果对应的 .dep 文件不存在，也就是说这个安装包不依赖其他东西。对应包的额外后缀名含义如下： .dep：依赖列表 .info：包的说明 .list：包的内容列表 .md5.txt：包的 MD5 校验值 可以直接访问 tcz 路径来查找需要的包。 在對應版本的 release/distribution_files/ 包含了該版本的內核文件（vmlinuz）以及初始化記憶體（initrd)。我選用這個發行版作為修改基礎是因為這兩個東西的獲取簡單，而且系統的確沒有東西，十分乾淨。其使用 squashfs 分發軟件的方式也方便把軟件內嵌到 initrd 中。 TinyCore 的文件TinyCore x86_64 只有兩個文件：一個是內核，一個是 initrd。內核按照傳統，文件名叫 vmlinuz；initrd 在 amd64 版本上是 corepure64.gz。內核沒啥好說的，主要說 initrd。 TinyCore 的 initrd 是一個用 gzip 壓縮過的 cpio 檔，裏面就是整個根文件系統。這個檔案啟動的時候會被直接載入記憶體。本文要修改的目的文件其實就是它。 BusyBoxTinyCore 內嵌 BusyBox BusyBox 可以說是一個 Linux 上的瑞士軍刀。它是一堆常用 Linux 程序的集合，內建了很多基礎命令甚至額外命令，例如 mv、ls、cat、mkdir、curl 等等命令，甚至連 http 服務器都有（取決於是否有把它編譯進去）。這些常用命令都被包進一個叫 busybox 的可執行檔內，通過 busybox 命令 或者軟鏈易名的形式（這個最常用）的方式來調用想要的命令。 其本身當然也帶一個 shell，ash，是大家都熟悉的終端了。在 TinyCore 裡大部分命令都只是到 busybox 的軟鏈接而已。 下回分解下一篇文章將開始講述如何方便地修改 initrd 以達成自定義發行版的目的，以及如何通過 qemu 快速啟動虛擬機來測試。 工具提要調試需要使用 qemu，也就僅僅需要 qemu 而已。 關於啟動和調試為了方便，這裡暫時不使用傳統的 GRUB 啟動，而是用 qemu 直接加載內核和 initrd。GRUB 的內容以後再說。 下一篇：「Linux 玩耍記事」製作一個發行版·貳：著手開搞","categories":[{"name":"Linux 技术应用","slug":"Linux-技术应用","permalink":"https://cattenlinger.github.io/categories/Linux-%E6%8A%80%E6%9C%AF%E5%BA%94%E7%94%A8/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://cattenlinger.github.io/tags/Linux/"}]},{"title":"使用 UxPlay 搭建 AirPlay 服務","slug":"使用-UxPlay-搭建-AirPlay-服務","date":"2022-06-26T08:01:12.000Z","updated":"2025-03-24T00:45:05.198Z","comments":true,"path":"2022/06/26/2228545530c2.html","link":"","permalink":"https://cattenlinger.github.io/2022/06/26/2228545530c2.html","excerpt":"","text":"最近給桌面上的 24 寸 4K 找用途，打算連接到旁邊的 NUC7 服務器上做點什麼好玩的服務。於是想到投屏功能。 上網尋尋覓覓一會找到了 UxPlay 這個軟件。那就開始操作吧。 構建依賴使用 docker 製作構建用鏡像： 12345678910from ubuntu:focalWORKDIR /optRUN apt update &amp;&amp; \\ DEBIAN_FRONTEND=noninteractive TZ=Asia/Shanghai \\ apt install -y cmake libssl-dev libplist-dev libavahi-compat-libdnssd-dev \\ libgstreamer1.0-dev libgstreamer-plugins-base1.0-dev libx11-dev \\ curl git &amp;&amp; \\ apt clean 1docker build -t cattenlinger/uxplay_build:latest . 構建程序進入 docker 容器開始操作 12345@&gt; docker run --rm -it --network host -v $(pwd)/opt cattenlinger/uxplay_build:latest bash#&gt; git clone https://github.com/FDH2/UxPlay.git#&gt; cd UxPlay#&gt; cmake . &amp;&amp; make#&gt; exit 然後就能在當前目錄得到 uxplay 這個 executable 了。拿出來直接用即可。 運行時依賴要正常運行，還需要一系列 gstreamer 的 lib 才行： 123sudo apt install gstreamer1.0-plugins-base gstreamer1.0-libav \\ gstreamer1.0-plugins-good gstreamer1.0-plugins-bad gstreamer1.0-plugins-ugly \\ gstreamer1.0-gl gstreamer1.0-x gstreamer1.0-vaapi gstreamer1.0-tools 簡單運行現在可以開始運行 uxplay 了。這裏稍微介紹一下基本的參數使用： 123uxplay -n &#x27;Name&#x27; # 在 AirPlay 列表裏顯示的設備名 -nh # No hostname， 不要在設備名後面添加 @主機 -s 2160x1440 # 默認分辨率，默認值爲 1920x1080@60","categories":[{"name":"Linux 技术应用","slug":"Linux-技术应用","permalink":"https://cattenlinger.github.io/categories/Linux-%E6%8A%80%E6%9C%AF%E5%BA%94%E7%94%A8/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://cattenlinger.github.io/tags/Linux/"}]},{"title":"手動構建 wpa_supplicant","slug":"手動構建-wpa-supplicant","date":"2022-06-26T07:06:01.000Z","updated":"2025-03-24T00:44:58.752Z","comments":true,"path":"2022/06/26/0e469a5cfbf8.html","link":"","permalink":"https://cattenlinger.github.io/2022/06/26/0e469a5cfbf8.html","excerpt":"","text":"最近嘗試使用 Miraclecast 搭建一個 WiFi 投屏的服務。沒有什麼成效，不過也收穫了一些東西。 其中需要用到支援 WiFi Direct 的 wpa_supplicant，據我所知默認情況下發行版的二進制編譯是不會帶很多特別功能的。手動構建就成了首選（這麼各種編譯下去我遲早都得 gentoo 大法了 XD） 構建依賴根據查詢到的文章，在 ubuntu 下構建需要依賴一些包。我這裏爲了方便使用 docker 容器作構建環境。 1234567891011from ubuntu:jammyWORKDIR &#x27;/opt&#x27;RUN apt update &amp;&amp; \\ DEBIAN_FRONTEND=noninteractive TZ=Asia/Shanghai \\ apt-get install -y -q --force-yes libssl-dev build-essential curl tar \\ checkinstall pkg-config dbus libdbus-1-dev libdbus-glib-1-2 \\ libdbus-glib-1-dev libreadline-dev libncurses5-dev \\ libnl-genl-3-dev libnl-3-dev &amp;&amp; \\ apt clean 開始構建創建鏡像 1docker build -t cattenlinger/wpa_supplicant_build:latest . 然後就可以跑去 (http://w1.fi/wpa_supplicant/)[http://w1.fi/wpa_supplicant/] 下載最新版本的原始碼了。截至目前原始碼版本是 2.10。 12345@&gt; docker run --rm -it --host network cattenlinger/wpa_supplicant_build -v $(pwd):/opt bash#&gt; cd /opt #&gt; curl -O -L http://w1.fi/releases/wpa_supplicant-2.10.tar.gz#&gt; tar -xvf wpa_supplicant-2.10.tar.gz#&gt; cd wpa_supplicant-2.10 編譯之前需要先設置編譯參數。在 wpa_supplicant 檔案夾下創建 .config 文件 12345678910111213141516171819202122232425262728293031323334CONFIG_BACKEND=fileCONFIG_CTRL_IFACE=yCONFIG_DEBUG_FILE=yCONFIG_DEBUG_SYSLOG=yCONFIG_DEBUG_SYSLOG_FACILITY=LOG_DAEMONCONFIG_DRIVER_NL80211=yCONFIG_DRIVER_WEXT=yCONFIG_DRIVER_WIRED=yCONFIG_EAP_GTC=yCONFIG_EAP_LEAP=yCONFIG_EAP_MD5=yCONFIG_EAP_MSCHAPV2=yCONFIG_EAP_OTP=yCONFIG_EAP_PEAP=yCONFIG_EAP_TLS=yCONFIG_EAP_TTLS=yCONFIG_IEEE8021X_EAPOL=yCONFIG_IPV6=yCONFIG_LIBNL32=yCONFIG_PEERKEY=yCONFIG_PKCS12=yCONFIG_READLINE=yCONFIG_SMARTCARD=yCONFIG_WPS=y# 一些 WIFI P2P 相關的設定CONFIG_P2P=yCONFIG_WIFI_DISPLAY=y# dbus 設定CONFIG_CTRL_IFACE_DBUS_NEW=yCONFIG_CTRL_IFACE_DBUS=yCONFIG_CTRL_IFACE_DBUS_NEW=yCONFIG_CTRL_IFACE_DBUS_INTRO=yCFLAGS += -I/usr/include/libnl3 安裝在 wpa_supplicant 目錄下執行 make。成功後執行 sudo checkinstall 即可安裝並打包軟件。因爲在 docker 環境下打的包，所以需要拎到外面再 dpkg -i 一次。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960#&gt; make#&gt; checkinstallcheckinstall 1.6.3, Copyright 2010 Felipe Eduardo Sanchez Diaz Duran This software is released under the GNU GPL.The package documentation directory ./doc-pak does not exist. Should I create a default set of package docs? [y]: yPreparing package documentation...OKPlease write a description for the package.End your description with an empty line or EOF.&gt;&gt; wpa_supplicant 2.10 with wifi p2p and display # 這裏隨便輸入一點包的說明&gt;&gt; ********************************************* Debian package creation selected *********************************************** Warning: The package name &quot;wpa_supplicant&quot; contains illegal*** Warning: characters. dpkg might not like that so I changed*** Warning: them to dashes.This package will be built according to these values: 0 - Maintainer: [ root@nuc7 ]1 - Summary: [ wpa_supplicant 2.10 with wifi p2p and display ]2 - Name: [ wpa-supplicant ]3 - Version: [ 20220626 ]4 - Release: [ 1 ]5 - License: [ GPL ]6 - Group: [ checkinstall ]7 - Architecture: [ amd64 ]8 - Source location: [ wpa_supplicant ]9 - Alternate source location: [ ]10 - Requires: [ ]11 - Recommends: [ ]12 - Suggests: [ ]13 - Provides: [ wpa-supplicant ]14 - Conflicts: [ ]15 - Replaces: [ ]Enter a number to change any of them or press ENTER to continue:......... # 中間省略********************************************************************** Done. The new package has been installed and saved to /opt/wpa_supplicant-2.10/wpa_supplicant/wpa-supplicant_20220626-1_amd64.deb You can remove it from your system anytime using: dpkg -r wpa-supplicant**********************************************************************#&gt; exit#&gt; dpkg -i wpa_supplicant-2.10/wpa_supplicant/wpa-supplicant_20220626-1_amd64.deb 大功告成。 如果系統中已經安裝了 wpa_supplicant 的話得先卸載掉。 1sudo apt autoremove --purge wpasupplicant","categories":[{"name":"Linux 技术应用","slug":"Linux-技术应用","permalink":"https://cattenlinger.github.io/categories/Linux-%E6%8A%80%E6%9C%AF%E5%BA%94%E7%94%A8/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://cattenlinger.github.io/tags/Linux/"}]},{"title":"Typescript 開始我的第一個 NodeJS/Typescript 專案","slug":"Typescript-開始我的第一個-NodeJS-Typescript-專案","date":"2022-06-16T01:10:13.000Z","updated":"2025-03-24T00:45:19.382Z","comments":true,"path":"2022/06/16/4716ebf05d0a.html","link":"","permalink":"https://cattenlinger.github.io/2022/06/16/4716ebf05d0a.html","excerpt":"","text":"雖說用 Node 是經常的事情，但還是第一次嘗試用 Typescript 寫 NodeJS 程式。今天想寫一個簡單的網站，這裡記錄一下這個簡單的過程。 所需的是 TypeScript 編譯器以及對應的類型定義，我這戲需要用到 Express，所以 Express 和其類型定義也需要安裝。 12npm install expressnpm install typescript ts-node @types/node @types/express --save-dev 然後需要新建 tsconfig.json 用於描述這個 TypeScript 專案。可以沿用以前的設定，或使用以下命令常見模板設定。 1npx tsc --init 之後就會出現一個帶著註釋的 json 文件。可以按需調配。我需要用到的東西如下： 12345678910111213141516171819202122&#123; &quot;compilerOptions&quot;: &#123; /* Language and Environment */ &quot;target&quot;: &quot;es2016&quot;, /* Set the JavaScript language version for emitted JavaScript and include compatible library declarations. */ /* Modules */ &quot;module&quot;: &quot;commonjs&quot;, /* Specify what module code is generated. */ &quot;rootDir&quot;: &quot;./src&quot;, /* 程式碼檔案的根目錄. */ /* Emit */ &quot;outDir&quot;: &quot;./dist&quot;, /* JavaScript 檔案的輸出位置. */ /* Interop Constraints */ &quot;esModuleInterop&quot;: true, /* Emit additional JavaScript to ease support for importing CommonJS modules. This enables &#x27;allowSyntheticDefaultImports&#x27; for type /* Type Checking */ &quot;strict&quot;: true, /* Enable all strict type-checking options. */ &quot;skipLibCheck&quot;: true /* Skip type checking all .d.ts files. */ &#125;&#125; 每次編寫好後都需要編譯成 JavaScript 檔才能被 NodeJS 執行，編譯很簡單： 12 # 專案根目錄tsc --project ./ 那麼就把這句話直接塞進 package.json 吧 12345678&#123; /* ... */ &quot;scripts&quot;: &#123; &quot;build&quot;: &quot;tsc --project ./&quot;, /* 構建 */ &quot;start&quot;: &quot;node dist/index.js&quot; /* 運行 */ &#125;, /* ... */&#125; 於是便可以愉快地有（類）型地寫代碼了： 123456789101112import express from &#x27;express&#x27;;const app = express()app.get(&quot;/&quot;, (request, response) =&gt; &#123; response.write(&quot;Hello world!&quot;) response.end()&#125;);app.listen(8080, () =&gt; &#123; resolve()&#125;)","categories":[{"name":"编程技术","slug":"编程技术","permalink":"https://cattenlinger.github.io/categories/%E7%BC%96%E7%A8%8B%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"TypeScript","slug":"TypeScript","permalink":"https://cattenlinger.github.io/tags/TypeScript/"},{"name":"NodeJS","slug":"NodeJS","permalink":"https://cattenlinger.github.io/tags/NodeJS/"}]},{"title":"Kotlin/JS 來嘗試寫一個 Webpack 的 Kotlin DSL 吧！","slug":"Kotlin-JS-來寫一個-Webpack-的-Kotlin-DSL-吧！","date":"2022-06-14T15:25:09.000Z","updated":"2025-03-24T00:45:24.948Z","comments":true,"path":"2022/06/14/55d779cf524c.html","link":"","permalink":"https://cattenlinger.github.io/2022/06/14/55d779cf524c.html","excerpt":"","text":"本文的最終目的是編寫出能調用 Webpack 來施行構建流程的 Kotlin Build Script。 前言因為惱於 JavaScript 的無類型，又不喜歡 TypeScript 的類型系統，於是就有了嘗試用 Kotlin 開發前端的嘗試。 不過一番搜尋和嘗試後，我放棄了。兩個類型系統相差懸殊，Kotlin 依舊保留了大量的 JVM 平台行為，各種容器和類型的包裝並不能輕易地和前端開發的習慣匹配。 但我都研究了這麼多了，不拿來玩一下豈不就浪費掉了嘛。於是就把目光投向了每次都惹我惱的 Webpack 配置。（我真的討厭配 Webpack） 環境說明本文涉及 NPM、Javascript、Kotlin 以及 Bash 終端的運用。所有需要的指令都在專案目錄下局部安裝。 運行環境為 macOS，Linux 應該沒問題。Kotlin 的編寫使用的是 IDEA Ultimate。Webpack 版本 5。 使用 npm init 創建一個專案目錄後進入，然後開始操作。 如何編譯 Kotlin 程式碼？編譯 Kotlin 程式碼需要使用 kotlinc-js 指令。 1npm i --save-dev kotlin kotlin-js 的使用很簡單： 1kotlin-js [程式碼目錄] -libraries [程式庫目录] -output [最终 JavaScript 输出檔] 程式庫目錄是可選的，默認會包含 Kotlin stdlib 本身。如果僅使用 stdlib 則無須使用。 最終輸出是一個單一 JavaScript 檔案。直接執行即可。 kotlin-js 還有一些值得注意的選項： -module-kind：JavaScript 模塊類型使用，支援 plain | amd | commonjs | umd 四個選項。我個人建議只使用 commonjs 選項。其他選項構建出來的結果不適合單獨執行。 -main：是否調用 main() 函數。選項為 call | noCall，即調用或不調用，默認為調用。在寫程式庫時可能需要用到 noCall。 -meta-info：輸出 Kotlin 元數據。方便其他 Kotlin JS 程序引入使用。 更多選項可執行 kotlinc-js -help 查看。 Kotlin 程式庫依賴Kotlin stdlib 是自帶的。Webpack 運行於 Node.js，需要 Node JS 的 Kotlin API。雖然可以按需使用 extrenal 關鍵詞聲明原生 JavaScript 實現，但更方便的是使用 Kotlin 官方做好的聲明。 嘗試在 IDEA 上新建一個 Kotlin JS 專案後，找到了對應的依賴 org.jetbrains.kotlinx:kotlinx-nodejs:0.0.7，但可惜 JCenter 已經 sunset 了，我沒找到 Gradle 到底是從哪裡下載這個包的，在其 GitHub 專案首頁也沒有對應的下載連結，我暫時把它放在我們的倉庫中，如有需要可以臨時使用：https://nexus.shinonometn.com/repository/maven-public/（本人不對服務質量作保證） 雖說 stdlib 是自帶的，但我還是建議下載 org.jetbrains.kotlin:kotlin-stdlib-js:1.6.21 並將其加入 Project Library。 配置關鍵詞提醒使用 IDEA 打開專案目錄，把下載好的 kotlinx-nodejs jar 包增加至 Project Library 即可獲得關鍵詞提醒功能。 為了目錄的乾淨整潔，我新建了 buildSrc 目錄放置所有 Webpack 構建用程式。將其添加至專案的 Source Root 後，Kotlin 關鍵詞提醒將正常工作。 Javascript 程式庫依賴1npm i --save-dev webpack webpack-merge webpack-dev-server html-webpack-plugin copy-webpack-plugin mini-css-extract-plugin chalk@4 ora@1.2.0 rimraf Webpack 是必須的了。chalk、ora 和 rimraf 用於展示如何從 Kotlin 調用 JavaScript 功能，也為了順便製造點 eye candy（XDchalk 和 ora 必須使用 commonjs module 的版本，否則不能從 kotlin 調用。 開始寫代碼由於程式碼數量不少，這裡僅節選關鍵點，完整專案可訪問 GitHub 鏈接。 main 入口在 buildSrc 內的 package level main 將會成為整個程式的入口，且其只能聲明一次。可以是 suspend function 1234567import processsuspend fun main() &#123; val args = process.argv.drop(2) // 0 是 node 程式，1 是程式檔案位置，丟掉這兩個便獲得参表。 // your codes here &#125; 注意，這裡的 main 沒有 args。是可以加進去的，但只會得到一個空數組。像普通的 Node 程式，命令行参表需要從 process.argv 獲取。在引入 kotlinx-nodejs 后，所有的 Node API 都可以像 JVM 上的包那样被引入。 访问原始 JavaScript 内容123456789101112131415161718192021222324fun jsObject(): dynamic = js(&quot;(&#123;&#125;)&quot;)@DslMarkerannotation class WebpackDslclass WebpackConfigContext(internal val config : WeboackConfigContext.() -&gt; Unit) &#123; private val configObj = jsObject() @WebpackDsl fun mode(string: String) &#123; configObj.mode = string &#125; // .... 更多的 DSL fun build() = configObj&#125;@WebpackDsl@Suppress(&quot;FunctionName&quot;)fun WebpackConfig(block: suspend WebpackConfigContext.() -&gt; Unit) : (suspend () -&gt; WebpackConfigContext) = &#123; WebpackConfigContext(block)&#125; 在 Kotlin 程式碼中調用 JavaScript 函數，需使用 js(String) 函數。此函數會把內容內聯進當前位置，返回 dynamic 類型。 dynamic 類型是一個比任意類型還任意類型的類型，代表著一個原始 JavaScript 存在。可以對此類型變數作任何操作： 賦予變數：例如 a 為 dynamic 類型， a.b = &quot;1&quot;; a.b = 2; a.b = suspend &#123; &#125;; a.b = Unit … 都是合法的 取變數 調用：例如 a 為 dynamic 類型， a(); a(string1, value2, option3); a(...arrayOf(&#39;a&#39;, &#39;b&#39;, &#39;c&#39;)) … 都是合法的，返回值會是 dynamic 類型。 dynamic 類型也是危險的，因為等同於臨時關閉幾乎所有類型檢查，而且 undefined | null 也是以 dynamic 的形式返回，我們不能過度依賴它，只能在與 JavaScript 交互時使用。 同時需要注意的是： 輸入的字符串不能是變數，必須是編譯時靜態的，任何動態的字符串拼接與變數的使用會觸發編譯時錯誤。 但我們可以這樣： 12val a = &quot;Hello World&quot;js(&quot;console.log(a)&quot;) 還需要注意的是，此用法需在同一作用域內使用，否則 a 在編譯後的 JavaScript 裏可能會被帶上作用域後綴（最常見的是作用域深度後綴，例如_0）引起運行時錯誤： 123456789101112val webpack = js(&quot;require(&#x27;webpack&#x27;)&quot;)object Webpack &#123; fun invokeWebpack0(config : dynamic) = js(&quot;webpack(config)&quot;) // 這時候就可能出錯了，可以查看編譯後的 JavaScript 程式了解原因。 fun invokeWebpack1(config: dynamic) &#123; val w = webpack // 建議先拿到當前作用域再調用 js(&quot;w(config)&quot;) &#125; fun invokeWebpack2(config : dynamic) = webpack(config) // 當然，在此示例中直接調用 webpack 變數即可。&#125; 使用這種方法，我們可以創建已有 JavaScript 庫的包裝（wrapper）： 123456789101112class OraSpinner(text : String) &#123; private val spinner = ora(text) fun start() = spinner.start() fun stop() = spinner.stop() companion object &#123; private val ora = js(&quot;require(&#x27;ora&#x27;)&quot;) &#125;&#125; 聲明原始 JavaScript API除了以上直接調用 JavaScript 的方法，還能夠使用 @JsModule 注解配合 external 关键词 1234567@JsModule(&quot;chalk&quot;)@JsNonModule // 默認情況下，@JsModule 下的聲明在編譯後才能被使用，若此聲明服務於當前源碼，則需要加上 @JsNonModule 註解。external object Chalk &#123; fun red(string : String) : dynamic fun blue(string: String) : dynamic&#125; 以 chalk 为例，若已知其方法聲明，則可以直接原樣翻譯進 Kotlin 中，然後在外部調用這個聲明。 suspend function 與 Promise 的互相轉換調用 webpack 或 webpack-dev-server 的 api 是會遇到 Promise 與 suspend function 的互相轉換問題。Kotlin JS 中自帶 coroutine，但其實現依舊是原汁原味的 Kotlin Coroutine。 關於這部分內容可參考我的另一篇文章：Kotlin&#x2F;JS Promise 與 Coroutine 的互相轉換 JavaScript 類型實現與 Kotlin 類型實現的轉換在 Webpack 配置中，最常用的除了標量類型（String、Number、Boolean 等）就是集合類型（Array 和 Map）。但 Kotlin 中的 List 和 Map 的實現都不是使用 JavaScript 的 Array 和 Object，Regex 是個 wrapper，在使用的時候就需要編寫點轉換函數了。 1234567891011121314151617181920212223242526272829303132// 構建 JS Object（Map）fun jsObject(): dynamic = js(&quot;(&#123;&#125;)&quot;) // 構建 JS Array（List）// 其實 Kotlin 的 array 就是 js 的 array，但 kotlin 的實現不變長。fun jsArray(): dynamic = js(&quot;([])&quot;) // 構建 JS RegExpfun jsRegex(@Suppress(&quot;UNUSED_PARAMETER&quot;) pattern: String): dynamic = js(&quot;new RegExp(pattern)&quot;)// 把 Kotlin Regex 變成 JS RegExp@Suppress(&quot;UNUSED_VARIABLE&quot;)fun Regex.nativePattern(): dynamic &#123; val that = this return js(&quot;(that.nativePattern_0)&quot;) // Kotlin 的 Regex 內有個 nativePattern_0 ，把它拿出來就是了&#125;// 把任何 String 為 Key 的 Map 變成 JS Objectfun Map&lt;String, *&gt;.toJsObject(): dynamic &#123; val obj = jsObject() for ((key, value) in this) obj[key] = value return obj&#125;// 把任何 Collection 變成 JS Arrayfun Collection&lt;*&gt;.toJsArray(): dynamic &#123; val array = jsArray() forEachIndexed &#123; index, item -&gt; array[index] = item &#125; return array&#125; 調用 Webpack 和 Webpack Dev Serverwebpack 函數吃一個 webpack 配置和一個回調 1234567891011121314151617181920private val webpack = js(&quot;require(&#x27;webpack&#x27;)&quot;)suspend fun webpack(config : WeboackConfigContext) = suspendCoroutine&lt;dynamic&gt; &#123; val rawConfig = config.build() webpack(rawConfig) &#123; error, stats -&gt; // error 是一個 JS Error， 可等價於 Kotlin 的 Throwable。 // stats 是一個 Webpack 的運行結果，內容參考 Webpack 的類型聲明 val casedError = error as? Throwable if(casedError != null) &#123; // 有錯誤 console.log(casedError.message ?: &quot;Webpack meets error&quot;) console.log(casedError) it.resumeWithException(casedError) &#125; else &#123; // ... 如果成功就繼續幹活～ it.resume(stats) &#125; &#125;&#125; webpack-dev-server 的本體在 webpack-dev-server/lib/Server.js。它吃一個 compiler （Webpack）和 options（配置），返回一個 Promise&lt;void&gt;，把它引進來就可以了： 1234567891011121314151617181920212223242526272829val webpack = js(&quot;require(&#x27;webpack&#x27;)&quot;)val webpackDevServer = js(&quot;require(&#x27;webpack-dev-server/lib/Server&#x27;)&quot;)fun webpackDevServer(webpackConfig : dynamic, devServerConfig : dynamic) : Promise&lt;Unit&gt; &#123; // Promise&lt;void&gt; 等於 Promise&lt;Unit&gt; val compiler = try &#123; webpack(webpackOptions) // 嘗試創建一個 webpack compiler &#125; catch (e : Throwable) &#123; console.log(e) process.exit(1) // 這裡就直接退出不管了 &#125; @Suppress(&quot;UNUSED_VARIABLE&quot;) val devServer = webpackDevServer val server = try &#123; // 這裡必需用原生的 new。Kotlin 分不清這個 dynamic 是一個 class 還是一個 function，直接調用會按照 function 處理。 js(&quot;new devServer(devServerConfig, compiler)&quot;) &#125; catch (e : Throwable) &#123; console.log(e) // 這裡就直接退出不管了 process.exit(1) &#125; listOf(&quot;SIGINT&quot;, &quot;SIGTERM&quot;).forEach &#123; // 當遇到 Signal Interrupt 和 Signal Terminal 的時候就關閉 dev server 並退出 process.on(it) &#123; _: Any -&gt; server.stop &#123; process.exit() &#125;; Unit &#125; &#125; // 啟動 Server，走你 (～ ￣ ▽ˉ) return server.start() as Promise&lt;Unit&gt;&#125; package.json 的配置我們已經使用代碼來調用 webpack 和 webpack dev server 了，package.json 的入口就也得改成 Kotlin JS 構建後的輸出。我這裡使用 kotlin_build/buildscript/buildscript.js 作為輸出，那麼 package.json 就得這麼改了： 123456&#123; &quot;scripts&quot;: &#123; &quot;serve&quot;: &quot;node ./kotlin_build/buildscript/buildscript.js serve&quot;, &quot;build&quot;: &quot;node ./kotlin_build/buildscript/buildscript.js build&quot;, &#125;&#125; 編譯 Kotlin 程式碼，包含它的依賴。編譯之前還需要做一件事情。 kotlinc-js 並不能讀取 jar ，我們需要把它們解壓出來。需要用到的只有 kotlinx-nodejs，那麼就把它解壓到一個地方去，例如 kotlin_build/bulidscript/lib 1unzip ./lib/kotlinx-nodejs-0.7.0.jar -d kotlin_build/bulidscript/lib 這時候就可以調用 kotlinc-js 編譯我們的 buildscript 了： 1kotlinc-js ./buildSrc -module-kind commonjs -main call -source-map -libraries ./kotlin_build/bulidscript/lib -output ./kotlin_build/buildscript/buildscript.js 每次都手动调用构建是一件很麻烦的事情，我们可以写个脚本来自动化这些事情： 123456789101112131415161718192021222324252627282930build_script() &#123; # 清理舊產物 rm -rf ./kotlin_build/buildscript -v mkdir -pv ./kotlin_build/buildscript unzip ./lib/kotlinx-nodejs-0.7.0.jar -d kotlin_build/bulidscript/lib # 編譯 kotlinc-js ./buildSrc -module-kind commonjs -main call -source-map -libraries ./kotlin_build/bulidscript/lib -output ./kotlin_build/buildscript/buildscript.js&#125;serve() &#123; node kotlin_build/buildscript/buildscript.js serve&#125;build() &#123; node kotlin_build/buildscript/buildscript.js build&#125;case $1 inserve) serve ;;build) build ;;*) echo &quot;Usage: script (serve|build)&quot; echo ;;esac 寫好之後執行這個腳本，serve 或者 build 就自動啦～ 後記實際做這個東西花了好幾天，更多的還是卡在理解 Webpack 那神奇的配置上。快做好的時候才發現原來我參考的 webpack 配置已經是很老的版本了，於是對著新版本重新修整了一番。現在的 Webpack 配置比以前舊版本的要好，做完這個 DSL 之後其實效率一般般，編譯 buildscrip 也要花一定的時間，而且強弱類型系統之間的差距導致給 Webpack 寫 Kotlin DSL 是一件很燒事件燒腦袋的事情。 我嘗試過用 dukat 工具來生成 Webpack API。結果是失敗了，dukat要不 property not found 要不 stack overflow 讓我失望得很，所以只好乖乖手寫。 在 JavaScript 的代碼中引入 Kotlin 包內聲明，需要按照像 Java 那樣的包結構定位聲明位置。Kotlin 的代碼編譯後都被閉包起來封在局部，除非主動修改外圍環境，否則聲明內容不會洩漏。 完整產物要比文章內的功能多，shell 檔中包含了從 maven 倉庫下載依賴的過程，所以會更複雜，可以在 GitHub 上查看原始碼。 只是個能用的玩具，沒有打算深入開發，所以 DSL 不完整也不夠友好，如果繼續有想法的話或許會改進它。","categories":[{"name":"编程技术","slug":"编程技术","permalink":"https://cattenlinger.github.io/categories/%E7%BC%96%E7%A8%8B%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"Javascript","slug":"Javascript","permalink":"https://cattenlinger.github.io/tags/Javascript/"},{"name":"Kotlin","slug":"Kotlin","permalink":"https://cattenlinger.github.io/tags/Kotlin/"},{"name":"JS","slug":"JS","permalink":"https://cattenlinger.github.io/tags/JS/"},{"name":"Kt","slug":"Kt","permalink":"https://cattenlinger.github.io/tags/Kt/"},{"name":"Webpack","slug":"Webpack","permalink":"https://cattenlinger.github.io/tags/Webpack/"}]},{"title":"Kotlin/JS Promise 與 Coroutine 的互相轉換","slug":"Kotlin-JS-Promise-與-Coroutine-的互相轉換","date":"2022-06-10T11:40:01.000Z","updated":"2025-03-24T00:45:33.542Z","comments":true,"path":"2022/06/10/1fe255310eca.html","link":"","permalink":"https://cattenlinger.github.io/2022/06/10/1fe255310eca.html","excerpt":"","text":"最近在嘗試 Kotlin&#x2F;JS 的程式構建，遇到 Coroutine 和 Promise 的互相轉換問題。 Promise -&gt; suspend func從 Promise 轉換為 suspend function 是比較簡單的。Kotlin 的 suspend function 都能通過 suspendCoroutine() 暫時掛起。給 Promise 增加一個擴展函數 await()： 1234567suspend fun &lt;T&gt; Promise&lt;T&gt;.await() : T = suspendCoroutine &#123; coroutine -&gt; then &#123; coroutine.resumeWith(Result.success(it)) &#125;.catch &#123; coroutine.resumeWith(Result.failure(it)) &#125;&#125; suspend func -&gt; Promise但反過來讓 suspend function 變 Promise 則稍微有點麻煩，遂查閱 Google⋯⋯ 結果發現方法還蠻簡單的。需要使用 Kotlin&#x2F;JS 給 suspend 函數提供的 startCoroutine() 函數，該函數需要一個 Continuation&lt;T&gt; 傳入為 suspend function 提供上下文。 在此新建一個函數 promise()： 1234567891011fun &lt;T&gt; promise(coroutineContext : CoroutineContext = EmptyCoroutineContext, block: suspend () -&gt; T) : Promise&lt;Result&lt;T&gt;&gt; &#123; return Promise &#123; resolve, reject -&gt; block.startCoroutine(object : Continuation&lt;T&gt; &#123; override val context: CoroutineContext get() = coroutineContext override fun resumeWith(result: Result&lt;T&gt;) &#123; if(result.isFailure) reject(result.exceptionOrNull() ?: Exception(&quot;Coroutine failed.&quot;)) else resolve(result) &#125; &#125;) &#125;&#125; 直接把 suspend function 的 resume result 返回出去，這樣也能暴露更多控制權以及減少 promise() 函數的工作量。提供一個默認的 coroutineContext，允許以後按需切換。 以上。","categories":[{"name":"编程技术","slug":"编程技术","permalink":"https://cattenlinger.github.io/categories/%E7%BC%96%E7%A8%8B%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"Javascript","slug":"Javascript","permalink":"https://cattenlinger.github.io/tags/Javascript/"},{"name":"Kotlin","slug":"Kotlin","permalink":"https://cattenlinger.github.io/tags/Kotlin/"},{"name":"Promise","slug":"Promise","permalink":"https://cattenlinger.github.io/tags/Promise/"},{"name":"Coroutine","slug":"Coroutine","permalink":"https://cattenlinger.github.io/tags/Coroutine/"},{"name":"JS","slug":"JS","permalink":"https://cattenlinger.github.io/tags/JS/"},{"name":"Kt","slug":"Kt","permalink":"https://cattenlinger.github.io/tags/Kt/"}]},{"title":"EntityFileService - 基于实体的简单文件管理设计","slug":"EntityFileService-基于实体的简单文件管理设计","date":"2020-08-04T14:37:43.000Z","updated":"2025-03-24T00:45:38.955Z","comments":true,"path":"2020/08/04/8b5c91d5d5f0.html","link":"","permalink":"https://cattenlinger.github.io/2020/08/04/8b5c91d5d5f0.html","excerpt":"","text":"它从何而来在我的项目里，经常会出现一个叫做 FileServiceAdapter 的东西，从第一个项目开始我就设计了这个东西，到现在它的设计还没有完善。根据命名规则可知，它并不是一个实体类。的确它并不能实际使用，必须继承他实现一个子类才能使用。 它的设计基于业务实体，例如订单、票据、用户等。订单可能有订单相关的附件，票据也会有票据相应的附件。实体有不同的种类，实体都有其对应的实体 ID （Entity ID），而每个实体都可能会有其对应的文件，所以检索实体相关的文件，只需要找到实体的类型和实体的 ID 即可。 EntityFileService 的设计就是这么来的，它通过实体类型和实体 ID 来管理归属于不同实体的附件文件。 结构它的构造函数长这样： 12345678public FileServiceAdapter(File rootFolder, String domainName) &#123; this.rootFolder = rootFolder; this.domainName = domainName; File currentContextFolder = new File(rootFolder, domainName); if (!currentContextFolder.exists() &amp;&amp; !currentContextFolder.mkdir()) throw new RuntimeException(&quot;Could not create domain folder &quot; + currentContextFolder.getAbsolutePath());&#125; 继承他的子类需要给予一个 rootFolder 和一个 domainName。rootFolder 一般是指根数据目录，是固定的，在 Spring 的上下文内指定一个就好。 domainName 就是所谓的“实体类型”——但叫他“域名”可能会比较好。在我的设计里，它服务于“业务域”，代表了一个域下面的所有文件。而每个域都应该有其唯一的主要业务域实体（例如订单、商品），也就是 Entity 。 Entity 在实现上一般就是一条数据库记录。EntityFileService 的设计里，通过 Entity 的 ID ，通过负责对应业务域的 FileService 就可以拿到这个 Entity 专用的文件夹，这样就可以开始存放文件了。 保存上下文的 FileContext.class在我的设计里，获取实体的附件文件夹的方法并没有直接返回一个 File 类型，而是返回一个包装类 FileContext.class。 12345678910public FileContext contextOf(I id) &#123; if (Objects.isNull(id)) throw new NullPointerException(); FileContext fileContext = new FileContext(); fileContext.setRootPath(getRootFolder().toPath()); fileContext.setDomainPath(String.format(&quot;%s/%s&quot;, getDomainName(), String.valueOf(id))); fileContext.setFile(new File(getRootFolder(), fileContext.getDomainPath())); return fileContext;&#125; FileContext.class 存储了对应的领域位置上下文，包括实际文件、根目录的绝对路径以及领域内路径。 123456789101112public class FileContext &#123; // The file entity, maybe null private File file; // Absolute path of the root folder private Path rootPath; // Relative path of the current domain, related to the rootPath private String domainPath; //....&#125; file 是指向领域路径所对应的真实文件系统的文件对象，上下文初始化的时候它不一定被初始化。触发初始化的是 getFile() ，而 exists() 也会间接触发初始化。 getFile() 作用是直接获取原始的文件对象，如果没有就直接创建一个。因为 EntityFileService 的设计很原始，所以选择尽量不限制原来的文件处理逻辑。exists() 的作用就是判断实际文件是否存在。 1234567891011121314151617181920212223242526/*** Check if target context file is exists,* rootPath and domainPath is necessary** @return true or false* @throws NullPointerException if rootPath or domainPath is null*/public boolean exists() &#123; return getFile().exists();&#125;//// 获取上下文的文件本身，有可能是文件夹也有可能是文件。// 要求 rootPath 和 domainPath 都不能为 null//// rootPath 指向根存储文件夹，domainPath 指向域内位置。// 实际上来说，domainPath 只是一个基于 rootPath 的相对路径。//public File getFile() &#123; if (Objects.isNull(file)) &#123; assertCanGetContextFolder(); this.file = new File(rootPath.toFile(), domainPath); &#125; return this.file;&#125; 当需要把文件名存储在数据库里时，需要先取出文件在域内的位置 1234567//// 获取领域内路径，这个路径的结构是 &quot;域名/实体 ID/&#123;一级或多级文件夹或文件&#125;&quot;// 总体跟文件系统很类似//public String getDomainPath() &#123; return domainPath;&#125; 当前上下是文件夹的话，就会有需要取出文件的需求，靠这两个方法： 12345678910111213141516171819202122232425//// 通过文件名，获取下一级文件夹的文件的上下文对象。// 原则上当前级上下文必须是文件夹，但这里并没有做限制。//public FileContext contextOf(String filename) &#123; FileContext fileContext = new FileContext(); fileContext.setDomainPath(String.format(&quot;%s/%s&quot;, domainPath, filename)); fileContext.setRootPath(this.rootPath); fileContext.setFile(new File(rootPath.toFile(), fileContext.getDomainPath())); return fileContext;&#125;//// 通过文件名，直接获取上下文下的文件。// 原则上当前级上下文必须是文件夹，但这里并没有做限制。//public File fileOf(String filename) &#123; if(!this.exists()) throw new IllegalStateException(&quot;Context folder not exists&quot;); if (!this.getFile().isDirectory()) throw new IllegalStateException(&quot;Not a directory&quot;); return new File(this.file, filename);&#125; FileContext.class 扮演了另外一个 File.class 的角色，它负责存储的是领域存储内的上下文信息，在需要的时候转化为真实的文件对象。 其他的常用的文件操作，例如列出文件夹内容，就直接通过 File.class 本身的功能去做了。 存储文件作为负责处理文件的 Service ，除了查出文件，当然还得写入文件。写入文件的操作靠 save() 方法处理 12345678910111213141516public FileContext save(I i, String filename, InputStream inputStream) throws IOException &#123; // 根据 Entity Id 获取 Entity 的存储上下文 FileContext fileContext = contextOf(i); // 如果对应的文件夹实际不存在则新建一个 if (!fileContext.exists() &amp;&amp; !fileContext.getFile().mkdir()) throw new IllegalStateException(&quot;Could not create entity folder &quot; + fileContext.getDomainPath()); // 通过 FilenameGenerator 更改文件名 String newFilename = filenameGenerator.get(filename); FileContext newFile = fileContext.contextOf(newFilename); // 获取实际的文件对象，写入文件内容 File targetFile = newFile.getFile(); IOUtils.copyLarge(inputStream, new FileOutputStream(targetFile)); // 返回新文件的 FileContext return newFile;&#125; FilenameGenerator.classFilenameGenerator.class 是个接口，提供文件改名的抽象。 123456789public interface FilenameGenerator &#123; /** * Generate a new filename * * @param origin origin filename, might be empty(&quot;&quot;) * @return new filename */ String get(String origin);&#125; 有时候为了防止上传上来的文件因为重名而被覆盖，需要为上传上来的每个文件改一个唯一的名字。在 FileServiceAdapter.class 初始化的时候，会默认设定一个文件名生成器，而它的行为是按照原来的文件名来存储文件。 1234567891011121314151617181920public class FileServiceAdapter&lt;I extends Serializable&gt; implements FileService&lt;I&gt; &#123; public final static FilenameGenerator DEFAULT_GENERATOR = s -&gt; s; //... // 默认的文件名生成器 private FilenameGenerator filenameGenerator = DEFAULT_GENERATOR; // // Getter &amp; Setter // public FilenameGenerator getFilenameGenerator() &#123; return filenameGenerator; &#125; public void setFilenameGenerator(FilenameGenerator filenameGenerator) &#123; this.filenameGenerator = filenameGenerator; &#125;&#125; 要修改的话，在实现子类的时候，于构造函数内修改它就可以了，例如： 12345678910// 一个专门存储用户信息文件的存储服务public class UserFileService extends FileServiceAdapter&lt;String&gt; &#123; public UserFileService(FileServiceConfiguration configuration) &#123; // 塞预先设定好的配置类内的 rootFile ，给一个 domainName 叫 &quot;user&quot; super(configuration.dataDirectoryFile(), &quot;user&quot;); // 修改文件名生成器为 UUID 生成器 setFilenameGenerator(FilenameGenerators.RANDOM_UUID); &#125;&#125; 我写了两个文件名生成器 123456789101112131415public final class FilenameGenerators &#123; // 基于 UUID 的生成器，保留后缀 public final static FilenameGenerator RANDOM_UUID = (origin) -&gt; &#123; String ext = origin.substring(origin.lastIndexOf(&quot;.&quot;)); return String.format(&quot;%s%s&quot;, UUID.randomUUID().toString(), ext); &#125;; // 基于时间戳和随机数字的生成器，保留后缀 public final static FilenameGenerator TIMESTAMP_WITH_RANDOM = (origin) -&gt; &#123; String ext = origin.substring(origin.lastIndexOf(&quot;.&quot;)); return String.format(&quot;%d_%s%s&quot;, System.currentTimeMillis(), Randoms.randomString(6), ext); &#125;;&#125; 取文件在我的设计里，一个 Entity 一般只有一级的存储，当只是要取里面的文件的时候，可以直接使用 get() 来获取 123public FileContext get(I i, String filename) &#123; return contextOf(i).contextOf(filename);&#125; 这里会造成一点麻烦，因为返回的是 FileContext 而不是 File ，所以需要再用 getFile() 来把路径转换成真实文件。 其实一般来说，取文件的时候都是直接拿到存储在业务实体内的 domainPath 到 FileService 取文件，所以我做了另外一个更为常用的方法。 1234public File fileOfContextPath(String contextPath) &#123; File file = new File(rootFolder, contextPath); return file.exists() ? file : null;&#125; 这个方法直接把 EntityFileService 这个东西的实际操作暴露无遗（-w -||| ） 删除删除文件直接通过取到文件之后直接删除实现，也可以通过 deleteByContextPath() 直接输入 domainPath 删除。而删除实体文件夹的方法我还没并入到现在的实现里，但在其他的 FileService 里是有实现的。 123public void deleteContextFolder(Long id) throws IOException &#123; FileUtils.deleteDirectory(contextOf(id).getFile());&#125; 嗯很干脆直接。。。 反思其实它本身没有名字。最后觉得它应该叫 EntityFileService，因为它是附随实体存在的。 我在不同的项目里使用它的同时，已经迭代了三次。我依旧觉得它对我来说有点怪异。它更多地是一个 Helper 去辅助“根据实体 ID 和实体类型来归组文件”的想法。 在文件的存储和定位 url 的拼接上，首先是： 实体文件夹（&#x2F;domainName&#x2F;id&#x2F;) 存储文件（&#x2F;domainName&#x2F;id&#x2F;filename） 然后得到这个完整的地址之后，存储在需要的地方（例如实体信息本身）。需要用的时候，通过 service 找到文件本身，然后对文件进行读取删除操作。 因为它本身也反映了真实文件位置，在没有权限控制要求的情况下，我直接使用 nginx 暴露这个文件夹，就能直接通过普通 http 请求获取到文件本身，service 的读功能基本没有什么太大的作用。 在内部代码操作上，只要获取到 context ，基本就直接 getFile 来获取到实际的文件并开始操作，FileContext 本身承担的功能很少。 我有点想让它变成类似 RedisTemplate 的存在，每个 Service 持有一个 Template 而不是继承一个 FileServiceAdapter 然后再持有 。 或者让它变成一些更加高级的文件管理服务允许 Auditing 之类的，但不确定这是否是个好想法。","categories":[{"name":"编程技术","slug":"编程技术","permalink":"https://cattenlinger.github.io/categories/%E7%BC%96%E7%A8%8B%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://cattenlinger.github.io/tags/Java/"},{"name":"Spring","slug":"Spring","permalink":"https://cattenlinger.github.io/tags/Spring/"},{"name":"Web","slug":"Web","permalink":"https://cattenlinger.github.io/tags/Web/"}]},{"title":"使用攔截器實現基於 JWT Token 的權限控制","slug":"使用攔截器實現基於-JWT-Token-的權限控制","date":"2020-08-03T01:20:16.000Z","updated":"2025-03-24T00:45:44.058Z","comments":true,"path":"2020/08/03/04cf98df93c0.html","link":"","permalink":"https://cattenlinger.github.io/2020/08/03/04cf98df93c0.html","excerpt":"","text":"本篇所使用的雖然不是標準的 Jwt Token ，重點不在此，而是 Spring 的攔截器使用。 Jwt Token 是一串字符串，分三個部分： 頭 內容 簽名 例如： 1dWlkPTEmZXhwaXJlPTE1OTY0MTg0MDExMDAmdHlwZT10ZXN0JnVzZXI9MTIz.cGVybWl0dGVkPXRlc3Qmcm9sZXM9YSUyQ2IlMkNjJTJDZCUyQ2Umc3BlY2lhbD1zb21ldGhpbmc=.kG-dsK2shfLpOvPgO2VnxLfCcMoryqmBKg1WqosDNK4 三個部分都需要使用 Base64 for Url 來編碼內容。Jwt Token 使用 . 來分割這三部分。 簽名用於確認 token 的合法性，是可選的，但建議都帶上這個部分，這樣 Token 就無法被僞造。簽名是前兩個部分用 . 分割后，加上一個密碼作散列計算，之後把結果拼接在尾部。 我這條 Token 是使用 sha265 的方式作簽名，可以根據自己的需求來使用不同的散列函數。 基本思路Spring 的攔截器可以對請求做很多的事情。 所有的請求進入應用，都需要入站後被處理才能到達 Controller 並讓業務邏輯代碼作相應的處理動作。簡單來說，入站之後就是 Servlet 。 1(inbound) -&gt; (Servlet) -&gt; DispatcherServlet -&gt; (Servlet) -&gt; (outbound) Spring DispatcherServlet 會處理所有的 Servlet 請求，所以 Servlet 這一層基本上可以不用管。 進入 DispatcherServlet 之後，對開發者來說事情就變得十分的簡單： 1(inbound) -&gt; Interceptor -&gt; (ContentResolver) -&gt; Controller -&gt; Interceptor -&gt; (ContentResolver) -&gt; (outbound) 只要配置好 Intecpetor 就能攔截自己想要提前處理的請求。一般來說繼承 HandlerInterceptorAdapter.class 即可，主要用到的方法只有一個： 12345678910public abstract class HandlerInterceptorAdapter implements AsyncHandlerInterceptor &#123; public HandlerInterceptorAdapter() &#123; &#125; public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception &#123; return true; &#125; // .... other methods&#125; preHandle(...) 發生在 Controller 執行之前，它的返回值是一個 Boolean 。true 代表允許繼續執行，請求會繼續傳遞到下一個攔截器（如果有）或者直接到達請求方法；false 代表從這裏結束請求，而返回的內容則通過 response 的 function 來操作。這是實現權限控制的關鍵點，畢竟權限控制也就是“如果有權限就執行沒權限就不執行”。 handler 一般傳入的是 HandlerMethod.class ，可以獲取到與請求對應的 Cotroller 上的 Java Method。它是個包裹類型，外加了一些很便利的 Function 去獲取 Controller Method 的信息。 request 傳入的是基本的 ServletRequest， 能獲取到請求的幾乎所有信息。 response 傳入的是基本的 ServletResponse，因爲這個 Method 在 Controller 之前，所以它並不能操作 Controller 所返回的內容，但可以修改它以在 Controller 處理完之後一併把東西返回給客戶端。 Token 塞哪裏Token 是要塞在請求頭上面的。 Http 請求分成兩部分：請求頭和請求體。在 Interceptor 內，它們都能獲取到，但有所區別： 請求頭已經預先被讀取，所以內容可以直接通過方法讀取（例如請求頭的字段和內容） 請求體會延遲讀取，需要從 request 裏取得請求體的流並處理一遍才能讀取內容。 把 Http 請求看成一個信封就很好解釋了。 請求頭是信封上的標識，讓人一眼看得到這個信封大概是幹什麼的。 請求體是信封的內容，拆開信封才能看。 當然，其中的原因還有很多，不過就沒必要在這裏說明了。 實現我這裏把 Token 的解釋和權限的處理拆分成兩個步驟。首先實現的是 Token 的解釋。 解析 Token新建一個 Class 直接繼承它之後，覆寫 preHandle(...)。打上 @Component 註解讓 Spring 自動初始化它 1234567891011@Componentpublic class TokenCheckerInterceptor extends HandlerInterceptorAdapter &#123; // 這裏我用一個 Configuration Bean 存儲一些需要用到的東西 private final TokenSecurityConfiguration tokenSecurityConfiguration; @Override public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception &#123; &#125;&#125; 頭信息能從 request 裏取出來，通過 getHeader(String) 方法。因爲有可能頭上沒有這個數據，所以需要判斷一下是否爲空。 12345678910111213141516171819202122232425262728293031String header = request.getHeader(&quot;Token&quot;);// 當沒有 Token 的時候，就不處理了。if(StringUtils.isEmpty(header)) return true;// secret 存儲在外部了String secret = tokenSecurityConfiguration.getTokenSecret();JwtToken token = JwtToken.parse(header);if(!token.verifySign(secret)) return true;TokenHead head = TokenHead.fromPayload(token.getHeadBase64());long currentDate = System.currentTimeMillis();if(head.getExpireDate() &lt; currentDate) &#123; logger.debug( &quot;Expired token from [&#123;&#125;(&#123;&#125;)] with type [&#123;&#125;] will not be accepted, token: &#123;&#125;&quot;, head.getUserId(), head.getUsername(), head.getType(), header ); return true;&#125;SecurityTokenUtils.setToken(request, token);SecurityTokenUtils.setTokenHead(request, head);return true; 當簽名校驗失敗或者 Token 過期的時候，也直接 pass，但並不會解釋 Token 。這樣在後面的攔截器裏就能通過這點簡單判斷一下請求是否合法。 善用 request.setAttribute(String,Object)SecurityTokenUtils.setToken(...) 和 SecurityTokenUtils.setTokenHead(...) 是兩個自己寫的方法。它僅僅是把解釋后的 Token 信息放置到 request 的 attribute 列表裏。每次請求都會帶這樣一個 attribute list，可以利用它往下存儲一些信息。其實 SpringMVC 的很多功能都是通過在這個列表裏存取信息實現的。需要注意的是自己所塞的內容的 key 不能跟框架的相同，這樣會引發異常行爲。簡單的解決方法是按照 java 的命名空間規範來設置存儲的 key ，直接使用包名是最簡單的方法。我這裏爲了簡單就直接使用了 security.* 這個命名空間，一般也沒有框架會這麼直接地用它。 1234567891011121314151617public final class SecurityTokenUtils &#123; public final static String ATTRIBUTE_TOKEN = &quot;security.token&quot;; public final static String ATTRIBUTE_TOKEN_HEAD = &quot;security.token.head&quot;; // .... static void setToken(HttpServletRequest request, JwtToken token) &#123; request.setAttribute(ATTRIBUTE_TOKEN, token); &#125; static void setTokenHead(HttpServletRequest request, TokenHead head) &#123; request.setAttribute(ATTRIBUTE_TOKEN_HEAD, head); &#125; // ...&#125; 存取這個東西的時候，把 key 作爲靜態字段存儲起來是最好的，這樣可以防止打錯字。 我還用了一個自己寫的 JwtToken.class 來解釋和存放 Token 信息。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778public class JwtToken &#123; private static final int TOKEN_HEAD = 0; private static final int TOKEN_PAYLOAD = 1; private static final int TOKEN_SIGN = 2; private String headBase64; private String payloadBase64; private String signBase64 = null; private JwtToken() &#123; &#125; public boolean verifySign(String secret) &#123; String content = headBase64 + &quot;.&quot; + payloadBase64; return Base64.encodeBase64URLSafeString(DigestUtils.sha256( secret == null ? content : (content + secret) )) .equals(signBase64); &#125; public boolean verifySign() &#123; return verifySign(null); &#125; public void sign(String secret) &#123; String content = headBase64 + &quot;.&quot; + payloadBase64; signBase64 = Base64.encodeBase64URLSafeString(DigestUtils.sha256( secret == null ? content : (content + secret) )); &#125; public void sign() &#123; sign(null); &#125; public String toString() &#123; return headBase64 + &quot;.&quot; + payloadBase64 + (signBase64 == null ? &quot;&quot; : (&quot;.&quot; + signBase64)); &#125; /* * * Constructors * * */ public static JwtToken fromBinary(byte[] head, byte[] payload, byte[] sign) &#123; JwtToken token = new JwtToken(); token.headBase64 = Base64.encodeBase64String(head); token.payloadBase64 = Base64.encodeBase64String(payload); token.signBase64 = Base64.encodeBase64String(sign); return token; &#125; public static JwtToken newToken(byte[] head, byte[] payload) &#123; JwtToken token = new JwtToken(); token.headBase64 = Base64.encodeBase64String(head); token.payloadBase64 = Base64.encodeBase64String(payload); return token; &#125; public static JwtToken parse(String stringToken) &#123; JwtToken token = new JwtToken(); String[] s = stringToken.split(&quot;\\\\.&quot;); if (s.length != 3) throw new IllegalStateException(&quot;Invalid Jwt Token&quot;); token.headBase64 = s[TOKEN_HEAD]; token.payloadBase64 = s[TOKEN_PAYLOAD]; token.signBase64 = s[TOKEN_SIGN]; return token; &#125; /* * * Getters.... * * */&#125; TokenHead.class 用來存放解釋后的 Jwt Token 的頭信息，也定義了一些 function 方便構建和解釋它。 123456789101112131415161718192021222324252627282930313233343536373839404142434445public class TokenHead &#123; private String userId; private String username; private String type; private Long expireDate; // // Getter setters.... // /* * * */ public String toUrlParams() &#123; Map&lt;String,String&gt; params = new HashMap&lt;&gt;(); params.put(&quot;uid&quot;, userId); params.put(&quot;type&quot;, type); params.put(&quot;user&quot;, username); params.put(&quot;expire&quot;, String.valueOf(expireDate)); return UrlParams.encodeParamMap(params); &#125; /* * * */ public static TokenHead fromPayload(String headBase64) &#123; String content = new String(Base64.getDecoder().decode(headBase64)); Map&lt;String,String&gt; params = UrlParams.parseParamMap(content); TokenHead tokenHead = new TokenHead(); tokenHead.setUserId(params.get(&quot;uid&quot;)); tokenHead.setType(params.get(&quot;type&quot;)); tokenHead.setUsername(params.get(&quot;user&quot;)); try &#123; tokenHead.setExpireDate(Long.parseLong(params.get(&quot;expire&quot;))); &#125; catch (Exception e) &#123; throw new IllegalArgumentException(&quot;invalid_expire_date_format&quot;); &#125; return tokenHead; &#125;&#125; 這也是我爲什麼說我這個 Jwt Token 不標準，因爲我是使用 UrlParam 而不是 Json 的形式存儲 Token 內容。標準的 Jwt Token 應該是使用 Json 來存儲。大概我這個叫 “UPwt” 會比較好（-w-||| )。。 UrlParams.class 這個 Utils 我就不列出來了，它的代碼在這裏：(UrlParams.java)[https://github.com/ShinonomeTN/snnmtn-tools/blob/master/snnmtn-utils/src/main/java/com/shinonometn/commons/tools/UrlParams.java] 判斷權限判斷權限使用另外一個 Interceptor 就好了。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110public class TokenSecurityInterceptor extends HandlerInterceptorAdapter &#123; private final Logger logger = LoggerFactory.getLogger(&quot;security.securityInterceptor&quot;); public final static String ATTRIBUTE_ROLES = &quot;security.user.roles&quot;; public final static String ATTRIBUTE_PERMISSIONS = &quot;security.user.permissions&quot;; public TokenSecurityInterceptor() &#123; &#125; private Collection&lt;String&gt; getRequiredPermission(HandlerMethod handlerMethod) &#123; RequiredTokenPermissions permissions = handlerMethod.getMethodAnnotation(RequiredTokenPermissions.class); if(permissions == null) return Collections.emptyList(); return Arrays.asList(permissions.value()); &#125; private Collection&lt;String&gt; getRequiredRoles(HandlerMethod handlerMethod) &#123; RequiredTokenRole roles = handlerMethod.getMethodAnnotation(RequiredTokenRole.class); if(roles == null) return Collections.emptyList(); return Arrays.asList(roles.value()); &#125; @Override public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception &#123; // 如果不是 HandlerMethod 就不處理了 if (!(handler instanceof HandlerMethod)) &#123; logger.info(&quot;Not handle class: &#123;&#125;, name: &#123;&#125;&quot;, handler.getClass(), handler.toString() ); return true; &#125; HandlerMethod handlerMethod = (HandlerMethod) handler; Collection&lt;String&gt; requiredRoles = getRequiredRoles(handlerMethod); Collection&lt;String&gt; requiredPermissions = getRequiredPermission(handlerMethod); // 如果 Controller Method 沒有打註解或者沒有寫權限和角色要求，則直接讓其通過 if (requiredRoles.isEmpty() &amp;&amp; requiredPermissions.isEmpty()) &#123; // Api no role or permission required return true; &#125; // 沒有 Token 很明顯不給過 JwtToken token = (JwtToken) request.getAttribute(SecurityTokenUtils.ATTRIBUTE_TOKEN); if (token == null) &#123; response.sendError(HttpServletResponse.SC_UNAUTHORIZED); return false; &#125; TokenHead tokenHead = (TokenHead) request.getAttribute(SecurityTokenUtils.ATTRIBUTE_TOKEN_HEAD); if (tokenHead == null) &#123; response.sendError(HttpServletResponse.SC_UNAUTHORIZED, &quot;invalid_permission_info&quot;); return false; &#125; logger.debug(&quot;User [&#123;&#125;(&#123;&#125;)] invoked method [&#123;&#125;].&quot;, tokenHead.getUserId(), tokenHead.getUsername(), handlerMethod ); Map&lt;String, String&gt; tokenPayload = UrlParams.parseParamMap( new String(Base64.getUrlDecoder().decode(token.getPayloadBase64())) ); // Token 的結構後面再說 Collection&lt;String&gt; roleList = UrlParams.parseList(tokenPayload.get(&quot;roles&quot;)); Collection&lt;String&gt; permissionList = UrlParams.parseList(tokenPayload.get(&quot;permitted&quot;)); if(!requiredPermissions.isEmpty()) &#123; if(!permissionList.containsAll(requiredPermissions)) &#123; logger.debug(&quot;User [&#123;&#125;(&#123;&#125;)] has no permission to invoke [&#123;&#125;]&quot;, tokenHead.getUserId(), tokenHead.getUsername(), handlerMethod.toString() ); response.sendError(HttpServletResponse.SC_FORBIDDEN, &quot;insufficient_permission&quot;); return false; &#125; &#125; if(!requiredRoles.isEmpty()) &#123; if(!roleList.containsAll(requiredRoles)) &#123; logger.debug(&quot;User [&#123;&#125;(&#123;&#125;)] has not granted to invoke [&#123;&#125;]&quot;, tokenHead.getUserId(), tokenHead.getUsername(), handlerMethod.toString() ); response.sendError(HttpServletResponse.SC_FORBIDDEN, &quot;forbidden&quot;); return false; &#125; &#125; if(!roleList.isEmpty()) &#123; request.setAttribute(ATTRIBUTE_ROLES, roleList); &#125; if(!permissionList.isEmpty()) &#123; request.setAttribute(ATTRIBUTE_PERMISSIONS, permissionList); &#125; return true; &#125;&#125; 在這裏我利用兩個自定義的註解： 123456789@Retention(RetentionPolicy.RUNTIME)public @interface RequiredTokenPermissions &#123; String[] value();&#125;@Retention(RetentionPolicy.RUNTIME)public @interface RequiredTokenRole &#123; String[] value();&#125; 在 Controller method 上寫的註解，通過 HandlerMethod.class 可以很輕易地獲取到。這樣在攔截器裏就可以獲取到對應 method 所需的權限。對比一下 token 上所描述的權限，就可以判斷是否允許當前請求訪問對應方法。 12345678private Collection&lt;String&gt; getRequiredPermission(HandlerMethod handlerMethod) &#123; // 就在這裏簡簡單單地用上了反射 RequiredTokenPermissions permissions = handlerMethod.getMethodAnnotation(RequiredTokenPermissions.class); // 如果方法沒打註解，只會拿到 null if(permissions == null) return Collections.emptyList(); return Arrays.asList(permissions.value());&#125; Token 的內容結構，我設定爲兩個 list ，一個 roles 一個 permitted，分別對應角色和權限。所以在這裏解碼讀取： 123456Map&lt;String, String&gt; tokenPayload = UrlParams.parseParamMap( new String(Base64.getUrlDecoder().decode(token.getPayloadBase64())));Collection&lt;String&gt; roleList = UrlParams.parseList(tokenPayload.get(&quot;roles&quot;));Collection&lt;String&gt; permissionList = UrlParams.parseList(tokenPayload.get(&quot;permitted&quot;)); 結構按照自己喜歡的來就好了，但我建議取短名的同時兼顧可讀性，在長度和可維護性上作點平衡。畢竟 base64 之後的字符串會增加約三分之一的體積，而且塞在頭部的數據太多讓請求的處理效率降低。 派發 Token上面都是對 Token 解釋和判斷的實現，如果沒有 Token 它就沒什麼用。寫一個 Controller Method 來派發 Token 就好了。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152@RestController@RequestMapping(&quot;/token&quot;)public class TokenSignController &#123; private final TokenSecurityConfiguration tokenSecurityConfiguration; public TokenSignController(TokenSecurityConfiguration tokenSecurityConfiguration) &#123; this.tokenSecurityConfiguration = tokenSecurityConfiguration; &#125; @PostMapping(&quot;/sign&quot;) public String signToken(@RequestParam(&quot;username&quot;) String username, @RequestParam(&quot;id&quot;) String userId, @RequestParam(&quot;password&quot;) String password) &#123; // 簡單地弄個密碼模擬登錄 if (!&quot;123456&quot;.equals(password)) &#123; return &quot;error:password&quot;; &#125; // 構造一個 Token 頭信息 TokenHead head = new TokenHead(); // 假裝我有個用戶 Id 和用戶名 head.setUserId(userId); head.setUsername(username); // 這個字段隨意 head.setType(&quot;test&quot;); // 弄個過期時間，這樣 Token 就能自己過期了 head.setExpireDate(System.currentTimeMillis() + TimeUnit.MINUTES.toMillis(60)); // 構造點 Token 內容，塞點權限信息和其他信息 String headParams = head.toUrlParams(); String content = UrlParams.encodePairs(Arrays.asList( pair(&quot;permitted&quot;, &quot;test&quot;), pair(&quot;roles&quot;, &quot;a,b,c,d,e&quot;), pair(&quot;special&quot;, &quot;something&quot;) )); // 然後構造個 Token ，把內容塞進去 JwtToken token = JwtToken.newToken( headParams.getBytes(), content.getBytes() ); // 簽名后返回 token.sign(tokenSecurityConfiguration.getTokenSecret()); return token.toString(); &#125;&#125; 再寫點測試的方法來查看 Token 內容和驗證權限控制是否生效 1234567891011121314151617181920212223242526272829303132333435363738394041// 檢測一下當前的角色@RequiredTokenRole(&quot;a&quot;)@GetMapping(&quot;roles&quot;)public Object testRole( @RequestAttribute(value = TokenSecurityInterceptor.ATTRIBUTE_ROLES, required = false) Collection&lt;String&gt; roles) &#123; if(roles != null) &#123; return roles; &#125; return &quot;no_roles&quot;;&#125;// 檢測一下當前的權限@RequiredTokenPermissions(&quot;test&quot;)@GetMapping(&quot;permissions&quot;)public Object testPermissions( @RequestAttribute(value = TokenSecurityInterceptor.ATTRIBUTE_PERMISSIONS, required = false) Collection&lt;String&gt; permissions) &#123; if(permissions != null) &#123; return permissions; &#125; return &quot;no_permissions&quot;;&#125;// 同時檢測權限和角色@RequiredTokenRole(&quot;b&quot;)@RequiredTokenPermissions(&quot;test&quot;)@GetMapping(&quot;/all&quot;)public Object testAll( @RequestAttribute(value = TokenSecurityInterceptor.ATTRIBUTE_PERMISSIONS) Collection&lt;String&gt; permissions, @RequestAttribute(value = TokenSecurityInterceptor.ATTRIBUTE_ROLES) Collection&lt;String&gt; roles) &#123; Map&lt;String,Object&gt; result = new HashMap&lt;&gt;(); result.put(&quot;roles&quot;, roles); result.put(&quot;permission&quot;, permissions); return result;&#125; 就這樣就能實現 JwtToken 的權限鑑別了。 後話Jwt 更多地只是個 “base64頭.base64內容.base64簽名” 的這麼一個格式。看官方的實現，我相信應該還有一些內容上的標準，就像 HTTP 只是一個簡單的基於文本的請求格式，但關於頭字段的命名和內容就有一大堆的規範。Jwt 作爲一個擺在頭的東西，是不適合存放大量內容的。我認爲 HTTP 頭存在的目的，是以輕量的數據來提示服務器和客戶端請求的方式和內容的格式。請求的內容可能會很大，但同時可能這次請求並不是一次應該處理的請求，所以設計成懶加載方式，避免在正常情況下過早地處理大量內容。 現在的 Web 越來越多的 Single Page Application，也越來越多的客戶端。Token 用作授權憑據的載體，越來越多地被用在 Web 上。我思考過服務器端會話（SESSION）的存在意義，觀察過 SESSION 的原理、Token 的大小和 Token 帶來的問題，我認爲服務器端會話的存在還是很有必要的。Session 通過一串數字標識一個在服務器上持久化存儲的內容，客戶端把這串數字存儲在 COOKIE 裏。每次請求只要知道 SESSION 的 ID， 服務器就知道當前用戶到底是誰。Session 在請求裏很輕量級，這樣避免每次請求的體積過大。但 Session 和 Token 都無法避免被盜用的問題。Session 的有效性是服務器端控制的，服務器只需要銷毀掉 Session 的內容，那麼被盜用的 Session 即會無效；而 Token 需要額外的措施，例如給予一個 ID 在請求的時候判斷，或者使用類似 Session 的機制。 我認爲其實這些更多地只是概念上的問題，實際上的實現還是數據的存儲交換和處理。這些概念的存在是爲了引導實現上的組合來達成一定的目的。過於實現爲上或概念爲上都不利於目的的實現。","categories":[{"name":"编程技术","slug":"编程技术","permalink":"https://cattenlinger.github.io/categories/%E7%BC%96%E7%A8%8B%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://cattenlinger.github.io/tags/Java/"},{"name":"Spring","slug":"Spring","permalink":"https://cattenlinger.github.io/tags/Spring/"},{"name":"SpringMVC","slug":"SpringMVC","permalink":"https://cattenlinger.github.io/tags/SpringMVC/"},{"name":"Jwt","slug":"Jwt","permalink":"https://cattenlinger.github.io/tags/Jwt/"}]},{"title":"【项目重构】修手机项目的焕新尝试 #1","slug":"【项目重构】修手机项目的焕新尝试-1","date":"2020-07-30T18:33:22.000Z","updated":"2025-03-24T00:58:03.172Z","comments":true,"path":"2020/07/31/aaf9143b5bcf.html","link":"","permalink":"https://cattenlinger.github.io/2020/07/31/aaf9143b5bcf.html","excerpt":"","text":"历史遗留问题，让人无奈的过去大约三年前，我还没正式毕业。实习期懒得出去找什么公司做实习了，就跟某位同学合作。来了一个软件项目，客户是修手机的，需要有一个系统来支撑他们的业务。 这个系统的价值交付方式是通过 WebApp（SPA）。用户前端的功能主要是： 浏览可维修的机种与维修服务 下单并开始一次维修 管理账单与查看维修进度 购买保险 查看已购保险并选择开始理赔服务 还有一些杂乱功能： 查看平台发布的文章 查看维修站点 管理自己的地址 作为老板的同学只给了我一个月的工期，现在想起来都觉得是剥削。（虽然以现在的技术水平来说只做个后端是没有太大问题的） 那时候还是 Spring IoC 和 MVC 独立配置的时代，SpringBoot 是个刚刚听说的新玩意，完全不知道怎么用。刚刚毕业出来，脑袋里还有所谓「三层架构」的思维。那时候所教的三层架构，实际只是“分三层来管代码”这么个概念，实践上是完全傻乎乎地把一个 maven 的项目硬生生分成三个模块： controller 、service 、database 。现在我的眼光来看，简直就是幼稚得不行让人发笑。但回想过来实际上这些都是老师教的，就感觉有点唏嘘和无奈了。 结构项目总共有这些模块： core-commons core-modules core-web-modules web-backend web-fontend core-commons核心的 Commons 模块。我那时候并没有太多的积累，直到上一年的年底都还有这个东西存在。它是我至今位置所有的 commons 基底，经过了好几次的迭代，某些层面上来说代表了我的积累（每次起项目都会直接 copy 的东西）。在我后来的项目里，它已经退化成项目包树下私有的 commons 包，只存放针对项目本身的通用 utilities 和 bean 。而早期的 commoms ，在后来跑出了项目，成为了独立的 commons 依赖包。 core-modules整个系统的核心功能模块，database 和 service 都共存于此。 我是比较追新而且希望能了解技术细节和问题原因的人，在早期我就尝试抛弃所教的所谓三层。那时候的我认为，这种数据层和服务层分离的操作，在这种 spring 项目下是完全没有必要的：我老早就使用 Spring Data JPA 了。 学校的教学里，还是 SSH（Structs2 + Spring + Hibernate），即便是新的，也不过只是 Spring IoC + Spring MVC + Hibernate （SSMH）。感觉不是 Struct2 的确太难用都不意识到 Spring MVC …… 而 Hiberbate ，老师们还沉浸于他们祖传的 BaseDAO ，那时候我意识到这个 BaseDAO 并没有解决太多的问题：它只针对实体本身的 CRUD 操作：基于 ID 的查询、新建实体、更新实体和删除实体。其他的地方完全就是纯粹的 SQL ，进阶点顶多就是 HQL 的拼装。我在想：HQL 拼装和 SQL 拼装有什么区别嘛（摔）！而且他们那种 Hibernate 的用法是 XML 弄一大堆的 mapping （Jesus）。这根本就没解决什么问题，我还不如直接用 PreparedStatement 开玩？后来的我是在某个意外认识的师兄（后来成为同睡同住的好朋友 w ）的帮助下，接触了真实的 Spring 生态，完全抛弃了学校教的所有东西， Spring 全家桶一起上！一键起飞直接秒掉同专业方向的几乎所有人（咳咳，飘了）。 不过，那时候的我还没有充足的理由去说服自己抛弃所谓的三层架构，于是使用“代码分离”的想法，只分两份代码： facade + logic 层。 logic 层包含了 service 和 data 以及 service 本身需要的一些 dao （我现在一般叫它 bean）和 utilities ；facade 层管理在 HTTP 之前的数据递交过程，包括权限和数据转换。这些东西在后来的日子里，它们都不再根据项目分开，变成基于高层次的抽象而共同存在，于是后来的项目也大多是单体项目了。 web-backend 和 web-frontend它们是切切实实的、需要直接干掉的历史遗留问题（&#x2F;w \\）。这两层其实是上述的 facade 层，管理数据交换过程。 项目本身没有什么权限上的要求，同时因为那时候的我技术能力有限，我是使用 interceptor（拦截器）来处理权限问题。用它来处理权限，在 Spring MVC 的范围里是简直一劳永逸的。那时候的权限判断逻辑很简单：我判断当前用户登录的方式，如果是用普通用户登录的方式（手机、微信登录），则通过 Session 只会获取到 NormalUser 类型的用户；通过管理员方式登录，则只能获取到 ManagerUser 类型的用。NormalUser 类型的用户只能访问 web-fontend 的接口、ManagerUser 只能访问 web-backend 的接口（至于如何实现这个限制，在后面会提到）。 我记得那时候应该是因为开发周期紧张的原因，所以其实这个系统没有什么「鉴别权限」的机制可言的。而系统运行起来的确是可以鉴别权限，这点我是记得的（毕竟是要交付，功能得完整），这是怎么做到的呢？其实这个操作很 trick ，且后面很多操作都很没必要。 web-backend 和 web-frontend 是两个 war 类型的 maven 工程，它们共同依赖 commons-modules 。 两个 war 工程分别 build 当然是会出现两个 war 了。一般来说，我做的项目都有个特点：前台（用户端）和后台（管理端）都是分别的两个子域名。 build 出来的两个 war 都会是独立运行的应用程序（linux 系统层面），我用 nginx 针对两个不同的 war 分别使用不同的 server_name 来分别 proxy_pass ，相当于在 Tomcat 上是两个不同的 web 应用。同时，两边的 login 方法查询数据库表和登录的函数都是不一样的，这样就使得从两个域名访问的 login 接口的对应函数会有几乎完全不同的行为，而且因为两个应用在 Tomcat 里是独立的，更加不会有两边的 User 实例相同的情况（其实 NormalUser 和 ManagerUser 都继承了 User 接口），毕竟连内存区域都不一样，ClassLoader 就更加不一样了。 即便 ManagerUser 和 NormalUser 同名，因为没有对应的操作接口（还记得 frontend 和 backend 实际上是两个 war 吗？），所以在应用代码里（也就是独立 build 出来的 war 里）也不可能是同一种类 instance ，即便不在 interceper 上使用 instanceof 判断，也可以区分是那种用户。 上面那么多废话，说白了就是： 它们用了同一份 core-modules 代码，所以拥有了同一个 service 层代码，但 因为是不同的 war ，所以在 Tomcat 上是独立应用。不在独立 war 里对应的 controller 里写 method 去暴露 service 的操作是不可能实现等价意义的操作。 因为暴露出去的接口是不同的 war 处理的，所以代码功能不可能串（就像妈是女的爸是男的一样）。 最后再简化一下，其实这就是两个不同的 web 应用在草同一个数据库…… （看自己以前写的屎就是会晕） 怀缅 Servlet看着项目某个里的 /src/main/webapp/WEB-INF 加上里面的 web.xml 就能感觉到一股浓浓的时代气息，经典的 Servlet 时代产物。的确那时候我的大专学校是在教 Servlet （已经懂了还掌握新技术的我就是那个天天睡觉耍帅也不会被老师批评的家伙 w ）。 我开始意识到 Servlet 这玩意要被时代淘汰的地方在这里： 1234567891011121314&lt;!-- Web MVC Dispatcher Configuration(Back) (from ./web-backend/src/main/webapp/WEB-INF/web.xml --&gt; &lt;servlet&gt; &lt;servlet-name&gt;springMVCDispatcher_back&lt;/servlet-name&gt; &lt;servlet-class&gt;org.springframework.web.servlet.DispatcherServlet&lt;/servlet-class&gt; &lt;init-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt;classpath*:context-webmvc-back.xml&lt;/param-value&gt; &lt;/init-param&gt; &lt;load-on-startup&gt;1&lt;/load-on-startup&gt; &lt;/servlet&gt; &lt;servlet-mapping&gt; &lt;servlet-name&gt;springMVCDispatcher_back&lt;/servlet-name&gt; &lt;url-pattern&gt;/*&lt;/url-pattern&gt; &lt;/servlet-mapping&gt; 一个 Servlet 应用应该通过很多个 &lt;servlet-mapping&gt; 去处理不同的 servlet 请求。但 SprintMVC 直接就是 &lt;url-pattern&gt;/*&lt;/url-pattern&gt;， 就是说任何 URL 都会丢给 SpringMVC 处理。那 Servlet 除了用于配置抢先 SpringMVC 的处理请求，就没有其他存在意义了。毕竟 DispatcherServlet 之后大致的处理方式就是 (inbound) -&gt; interceptor -&gt; controller methods -&gt; content renders (json, xml, template engines...) -&gt; (outbound)，那 Servlet 没意义不就是写明白的了么， Servlet 就这么被 Spring 反客为主了（x 看到这里实在是感叹 Servlet 时代的消逝和 SpringMVC 时代的崛起。 怀缅 application-context.xml（其实 SpringIoC 的初始化不一定是这个名字，看配置的） Servlet 让我想起那些 old days, Spring IoC 其实也是。Sprint IoC 现在更多的是躲在幕后，使用 package scanner 配合各种 annotation ，不被人感知地默默工作。 再看 web.xml 里 &lt;servlet-mapping&gt; 之前需要依赖的配置: 12345678910111213141516171819&lt;!-- Get current web root dir --&gt;&lt;!-- It must be loaded before other Listener and Servlet!! --&gt;&lt;context-param&gt; &lt;param-name&gt;webAppRootKey&lt;/param-name&gt; &lt;param-value&gt;xxxxxxxx.back.web.root&lt;/param-value&gt;&lt;/context-param&gt;&lt;listener&gt; &lt;listener-class&gt;org.springframework.web.util.WebAppRootListener&lt;/listener-class&gt;&lt;/listener&gt;&lt;!-- Application Context Configuration --&gt;&lt;context-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt;classpath*:context-application.xml&lt;/param-value&gt;&lt;/context-param&gt;&lt;listener&gt; &lt;listener-class&gt;org.springframework.web.context.ContextLoaderListener&lt;/listener-class&gt;&lt;/listener&gt; 关于 webAppRootKey 的说明网上有很多，它的作用更多的是跟随标准。我就不额外说明这些“远古技术”了，可以参考这个：SpringMVC 监听器 WebAppRootListener 与 ContextLoaderListener；官方：WebAppRootListener 注意一下 &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; 这个存在，它跟上面的是对应的。 &lt;listener-class&gt;org.springframework.web.context.ContextLoaderListener&lt;/listener-class&gt; ，顾名思义，就是“上下文加载监听器”， Spring 通过这个东西，在 Servlet 应用启动之前，开始加载自己。而用于在 Servlet 应用里“反客为主”的 &lt;servlet-class&gt;org.springframework.web.servlet.DispatcherServlet&lt;/servlet-class&gt; 就是靠这个东西初始化的上下文内容来工作的。 Spring 的 CotextLoader 起来之后，在 DispatcherServlet 之前会初始化 Spring IoC 本身，根据 &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; 去读取配置文件，像这里我就读取 classpath 下的 context-aplication.xml 了。这样 Spring 就会按照经典的 xml IoC 配置去初始化整个容器，效果就是初始化我整个应用的内容。 可以看得到，这两个是分别的 Listener ，对应的 Params 我按依赖其传参的 Listener 归组了。它们会被放在一个大 Map 里等着需要它们的组件去获取它。 不禁感叹以前的东西真够复杂的。。现在我一个 SpringBoot parent 起来就自带个 Tomcat&#x2F;Jetty Server 帮我搞好所有东西，我只需要 src 下写点代码打点注解就好了。 再往里面就是 applicationContext 的配置。 1234567891011121314151617181920212223242526272829&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:context=&quot;http://www.springframework.org/schema/context&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd&quot;&gt; &lt;context:property-placeholder location=&quot;WEB-INF/application.properties&quot;/&gt; &lt;context:component-scan base-package=&quot;xx.xxxxxxxx.modules&quot; use-default-filters=&quot;false&quot;&gt; &lt;context:include-filter type=&quot;annotation&quot; expression=&quot;org.springframework.stereotype.Repository&quot;/&gt; &lt;context:include-filter type=&quot;annotation&quot; expression=&quot;org.springframework.stereotype.Service&quot;/&gt; &lt;context:include-filter type=&quot;annotation&quot; expression=&quot;org.springframework.stereotype.Component&quot;/&gt; &lt;context:exclude-filter type=&quot;regex&quot; expression=&quot;cn\\.lexiuxia\\.modules\\.sms\\.SmsService&quot;/&gt; &lt;context:exclude-filter type=&quot;regex&quot; expression=&quot;cn\\.lexiuxia\\.modules\\.mail\\.MailingService&quot;/&gt; &lt;/context:component-scan&gt; &lt;!-- 我设计的 FileManager ，以后再说 --&gt; &lt;bean class=&quot;xx.xxxxxxxx.commons.resources.config.StorageServiceConfiguration&quot;&gt; &lt;property name=&quot;webRoot&quot; value=&quot;$&#123;xxxxxxxx.back.web.root&#125;&quot;/&gt; &lt;property name=&quot;rootPath&quot; value=&quot;static/&quot;/&gt; &lt;property name=&quot;createDirIfNotExist&quot; value=&quot;true&quot;/&gt; &lt;property name=&quot;filenameGenerator&quot;&gt; &lt;bean class=&quot;xx.xxxxxxxx.commons.resources.file.DateTimeFilenameGenerator&quot;/&gt; &lt;/property&gt; &lt;/bean&gt; &lt;import resource=&quot;context-infrastructure.xml&quot;/&gt;&lt;/beans&gt; 以前还得用 &lt;context:property-placeholder location=&quot;WEB-INF/application.properties&quot;/&gt; 来声明一个 property 文件，这样就能在外部直接修改部分属性而不用重新编译整个容器。现在直接使用 SpringBoot 在启动 jar 包的时候直接传参告诉它去文件系统里找替代配置文件就行了。 &lt;context:component-scan&gt; 拿来告诉 spring 容器应该管包树的哪个地方，而现在使用 SpringBoot 就能让 Spring 知道自己该管哪里：以打了 @SpringBootApplication 的注解所在的包开始找就好了。这个魔法倒是不难做。因为 main 函数一般都在这个类里，直接从 main 函数的代码上下文开始就行了（利用反射是 Spring 的拿手好戏不是吗 w ） 定义一个 bean ，可以使用 &lt;bean&gt; 标签来做，不过既然用了 &lt;context:component-scan&gt; 的话，就没必要了。那时候的我应该是不熟悉 spring 的配置，不知道注解情况下如何初始化的时候配置 bean ，所以并没有直接使用注解的方式初始化。 &lt;import resource=&quot;context-infrastructure.xml&quot;/&gt; 是那时候用来分割配置文件用的。我一直看不习惯 xml 所以就把一些关于数据库的配置塞里面了。 有点孤独的 context-webmvc-backend.xml它的加载点在 web.xml 的 &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; 它的加载独立于 Spring IoC ，但同时又依赖它。Spring MVC 的内容，会作为一个子级容器，塞在主容器下，主容器访问不了它，但它能访问主容器的内容。它的初始化，戴表着实际的数据递交门面（facade） 的初始化。因为它也其实是 spring ioc 容器初始化的配置文件，所以按照上面 context-application.xml 来配置是没有问题的。分开的原因很简单：它本来就是独立于 spring IoC 加载的一个子容器。 我还记得当时踩的坑：重复加载了两次父容器的内容，导致获取的实例有歧义点：会拿到两个。所以在里面我直接限制了它的加载范围：（这也是我当时对 Spring 有点害怕的原因。。。） 1234&lt;context:annotation-config/&gt; &lt;context:component-scan base-package=&quot;xx.xxxxxxxx.web.back&quot; use-default-filters=&quot;false&quot;&gt; &lt;context:include-filter type=&quot;annotation&quot; expression=&quot;org.springframework.stereotype.Controller&quot;/&gt;&lt;/context:component-scan&gt; 于是很简单地，关于门面数据的代码我都在这里配置了，例如 interceptors 、content negotiation （非页面内容渲染）、negotiatingViewResolver（页面内容渲染） 和一些 exception 处理器。看着这个复杂但又还能理解的 xml 配置，感觉就是“给我一次机会我绝对不会再这样做这个玩意”（x 这个项目现在怎样了？这个项目当时实际是花了三个月去处理，后来客户违约，项目搁置，我们所做的东西都没有了价值，我也没收到钱。三年过去了，这个东西一直静静地躺在这里。作为一家破烂大专在读生的我，能做出这种应用后端，我有点小自豪的同时有点失望。自豪是因为，我独力做出一个能用的后端，规模绝对比任何一个同级的同学做出来的都要大，结构比任何一个同学的都要好。失望的就是，我比得过同级的人又怎么样，超越了落后的人不代表水平跟得上时代。当时的我最失望的就是我居然没把权限系统做上去。我为了让前台后台分开而做的这个 trick 实在是脏得不行，而且对比起自己网上见过的朋友们，这种没有架构、也是慌乱糊出来的屎真的拿不出手。 现在看来，它还是我的实践，证明了我不少以前的想法，为我以后的其他实践继续提供了支持。 重构三年后到今天，觉得自己并没有太多的经验积累，觉得内疚，觉得自己是时候面对以前的遗憾了。 首先下手整顿的是这些毫无意义的模块分割。在 maven 下要分模块，我现在的经验是这样的： 高度独立且通用的工具库：例如任何项目都能用上的 commons 。这种模块不能太大，因为不可能什么项目都能完整用上它。不能太小，这样各个项目都会存在相同的工具。应该谨慎地增加它的内容。后来我制作了 snnmtn-utils ，它只包含一些我常用的东西。而 web 相关的 snnmtn-utils-web 则包含我在 web 工程内才用到的东西。 组件：专门针对这个项目的组件，可能是一些中间件或者局部框架。这种模块一般在巨型项目里会用到，我的项目都没有巨型一说，很少考虑这种情况。而且它一般都会跟第一种一样，被分离出项目独立存在。 自成一体的项目：一个大项目下的子项目，例如独立部署的分布式系统中的子系统。它们也是组件的一种，不过层面在项目结构上而不是一些关键部位的构建。 特殊用途：这种我暂时还没经验，见过一些专门用于管理依赖的模块（例如以前的 Spring）；额外的 maven 插件（这种算是组件了，不过它在项目以外的层面，例如代码管理、自动生成）；协议库，专门管理项目之间的抽象（我个人不是很喜欢这个东西，它其实是组件库的一种）。 回到这个项目本身，它除了第一种，并没有任何需要分模块的必要。所以我把它全部代码塞回去 root project 下的 &#x2F;src 下面。 使用 SpringBoot老旧的 Spring 工程改造，最好的办法大概就是直接 SpringBoot 化。这样可以直接一个 jar 包启动，不需要再配置额外的 Servlet 容器。而且它减少很多手工配置的依赖，Spring 已经把以前很多常用的依赖加进去了，例如 contentNegotiation 一般来说会配置成 json ，现在的 Spring 默认就是 jackson 来处理。比起以前，现在只需要一个 @RestController 就能搞定 REST Api 而不需要额外配置。 不仅仅是 SpringMVC ，数据库也是方便了很多，直接使用 Spring Data JPA ，就能把以前的项目数据层依赖全部提换掉，例如 hibernate 的一大串以及针对 JPA 的 EntityManager 的 Spring 配置。 构建部分再也不需要 war 插件来打包工程了，直接一个 spring boot 的构建插件就能出来对应的 jar 包。 消灭了很多 pom.xml 的内容，以及以前 Servlet 那些又难看又冗余的内容，就可以开始对实际的业务部分进行操作了。 后续在下一篇我会继续记录这个过程。","categories":[],"tags":[{"name":"Java","slug":"Java","permalink":"https://cattenlinger.github.io/tags/Java/"},{"name":"Spring IoC","slug":"Spring-IoC","permalink":"https://cattenlinger.github.io/tags/Spring-IoC/"},{"name":"项目开发","slug":"项目开发","permalink":"https://cattenlinger.github.io/tags/%E9%A1%B9%E7%9B%AE%E5%BC%80%E5%8F%91/"},{"name":"Spring MVC","slug":"Spring-MVC","permalink":"https://cattenlinger.github.io/tags/Spring-MVC/"},{"name":"Servlet","slug":"Servlet","permalink":"https://cattenlinger.github.io/tags/Servlet/"}]},{"title":"x86 軟路由設置記事","slug":"x86-軟路由設置記事","date":"2019-08-02T23:15:37.000Z","updated":"2025-03-24T00:45:55.998Z","comments":true,"path":"2019/08/03/5b24714099c1.html","link":"","permalink":"https://cattenlinger.github.io/2019/08/03/5b24714099c1.html","excerpt":"","text":"有一天，因為要著手開發，剛好我工作站重裝了，所有各個軟件的代理配置都沒有去備份，想著我設備太多了，也是時候需要在家的路由上做個代理了。這個計畫一直因為沒有時間所以拖了很久。雖然家裡也有一個已經配置好的 pdm 固件的路由器，但裡面的設定都是 ASUS 固件專屬，加上其性能比較差，而且是我隨身用的，就不方便做家裡的路由器。 現在我附近比較流行和普遍的代理軟件一般就是 Shadowsocks， 雖然有些朋友比較高級用 IPsec 解決問題，但畢竟我不是專門搞網絡的，就用身邊有的東西吧。 我用的解決方案是 iptables + ipset + shadowsocks 做自動分流， dhcpd 作 DHCP 服務器， bind + overture 作 DNS 解釋。 DNS 解釋用 bind 是因為我還需要在局域網裡部署一個 LAN 專用的 DNS 解釋，以及想嚐鮮。overture 是網友介紹的，說實現我的目的的話能省點事，而且 x86 路由不需要考慮存儲空間問題（ 這個 Golang 寫的 DNS 代理解釋服務體積上到 20M + ，有點龐大了）。 接下來的操作建議直接在真機上操作，並直接 sudo su 進入管理員權限以省去頻繁鑑權的麻煩。 NAT 配置我的機器是擁有四個獨立網卡的 i5 ，系統是 AOSC OS 5.0 ，但只要是 Debian 系的，這個設置方法都能用。 四個網卡分別是 enp1s0 - enp4s0 。我使用 enp1s0 作為 WAN 接外網，外面接一個 Mikrotik 撥號，暫時不搞 ppp 撥號了。其餘的網卡作為 LAN 使用。 首先確認 iptables 工具集存在，能使用 iptables 命令修改防火牆。然後，打開內核的網絡轉發功能 12345678# 如果結果為 1 ，就是打開了，那接下來不需要操作sysctl net.ipv4.ip_forward# 臨時打開一下sysctl -w net.ipv4.ip_forward=1# 可以使用文本編輯工具增加這個配置到自己系統的 sysctl.conf 或者等價配置文件內# 我這裡是 /etc/sysctl.d/02-net.confecho &#x27;net.ipv4.ip_forward=1&#x27; &gt;&gt; /etc/sysctl.d/02-net.conf nmtui 配置網絡設備系統使用 NetworkManager 管理網絡，下面我就直接在 nmtui 內操作了。 enp1s0 對應的配置不需要修改，默認 DHCP 獲取 IP 和網絡設置就行。 接下來新增一個橋設備，把所有其他的網卡橋接在一起。 在 IPv4 選項，填上你喜歡的路由器 IP 地址和子網掩碼，例如默認的 192.168.1.1&#x2F;24 (&#x3D;192.168.1.1 255.255.255.255)。 之後選擇 Add ，逐個添加 Ethernet slave 就好。 Device 填上網卡設備名。 配置好之後就不用其他東西了，出去前檢查一下 Automatically connect 都勾上了沒。 這樣，我們就有了一個 WAN 口和三個 LAN 口了，接下來需要在 iptables 上調整讓內核作 NAT 工作。 iptables 配置 NAT我本人對防火牆配置很不熟悉，所以就照葫蘆畫瓢就好了。 1234# 從 nm-bridge（也就是 LAN ）來的包轉發都允許iptables -t filter -A FORWARD -i nm-bridge -j ACCEPT# 不知道什麼東西，大概就是從 enp1s0 出去的都 MASQUERADE 方式處理iptables -t nat -A POSTROUTING -o enp1s0 -j MASQUERADE 然後就行了，現在這個機子就變成路由器了。接到 LAN 口們的設備，只要設置好 ip 、子網掩碼和路由器 IP 就能上網了。 DHCP 配置接下來的軟件不一定要用 Systemd 來控制，只要知道配置文件位置，直接運行也可。 畢竟這個是通過 Systemd 精準控制的路由器，所以我肯定是要用 Systemd 管理接下來的各種軟件啦。（大霧） 我系統內的 dhpc 服務器 service unit 是 dhcpd-ipv4 首先需要配置一下 dhcpd.conf 配置，我的配置位置在 &#x2F;etc&#x2F;dhcp&#x2F;dhcpd.conf 1234567891011121314151617# 域名稱和域的域名服務器，這個自己隨便吧。option domain-name &quot;cattenlinger_hut.lan&quot;;option domain-name-servers ns.cattenlinger_hut.lan;# 續租時間default-lease-time 3600;max-lease-time 7200;# 分配的 dhcp 段，填上路由器所在的網段即可subnet 192.168.114.0 netmask 255.255.255.0 &#123; option routers 192.168.114.1; option subnet-mask 255.255.255.0; option domain-search &quot;cattenlinger_hut.lan&quot;; option domain-name-servers 192.168.114.1; # 範圍 range 192.168.114.100 192.168.114.240;&#125; 保存好之後，systemctl enable dhcpd-ipv4 --now 即可現在立馬原地開始並開機啟動（x 現在，內網中的電腦不需要手動設置即可 DHCP 自動分配地址上網了（不過不知道為什麼我實際使用的時候 dhcp 的反應很慢），但因為還沒設置域名解析服務，所以還不能通過路由器解釋域名。 Bind 域名解析服務先安裝 bind 1apt install bind -y 然後配置 /etc/named.conf 123456789101112131415161718192021222324252627282930313233343536373839404142434445// Access control list ，建議配置一下僅允許內網訪問。acl allowed_clients &#123; // 允許所有本地請求 127.0.0.0/24; // 允許所有內網請求 192.168.0.0/16;&#125;;// 這裡只配置域名緩存和解釋轉發，所以只需要使用最基本配置options &#123; // 工作目錄和 pid 文件 directory &quot;/var/named&quot;; pid-file &quot;/run/named/named.pid&quot;; // 監聽內網和本地 listen-on &#123; 192.168.114.1; 127.0.0.1; &#125;; // 轉發給誰解析 forwards &#123; // Cloudflare //1.1.1.1; // Google //8.8.8.8; //8.8.4.4; // Open DNS //208.67.222.222; //208.67.220.220; // Alibaba DNS //223.6.6.6; //223.5.5.5; // Plain old 114 DNS //114.114.114.114; // Local DNS Proxy 127.0.0.1 port 2053; &#125;; // 這個設置有兩個選項， only 和 first。 // only 代表只轉發不緩存 // first 代表如果轉發目的服務器無法獲得結果，則使用本地緩存 forward first;&#125; 如果關掉 Local DNS Proxy 選項，直接啟動上面的 DNS 服務器，就能現在通過路由器轉發解釋出去了。不過接下來還得配置 DNS 解釋代理所以我就先只留下代理的地址了。 systemctl enable bind --now 即可立馬享受 DNS 服務且開機自啟動。 Shadowsocks雖然 Shadowsocks 配置已經爛大街，不過這裡也稍微再囉嗦一下好了。 如果是 Ubuntu ，直接 apt install shadowsocks-libev -y 就行了，而且其帶上對應的模板服務可多配置啟動。在 /etc/shadowsocks-libev 內配置 對應的 config ，然後 systemctl enable shadowsocks-libev-redir@config-name --now 即可。 我這裡的不帶 service ，就自己寫了個。 啟動好之後就行了，不用管什麼。但建議同時開啟一個 ss-redir 一個 ss-local ，方便之後的 DNS 解釋使用。 OvertureOverture 的 Github 主頁 使用比較簡單，啟動即可。不過建議稍微更改一下配置文件、填充 IP 和域名列表。 這裡貼出我的配置。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748&#123; &quot;BindAddress&quot;: &quot;:2053&quot;, &quot;DebugHTTPAddress&quot;: &quot;127.0.0.1:5555&quot;, &quot;PrimaryDNS&quot;: [ &#123; &quot;Name&quot;: &quot;Alibaba DNS&quot;, &quot;Address&quot;: &quot;223.6.6.6:53&quot;, &quot;Protocol&quot;: &quot;udp&quot;, &quot;SOCKS5Address&quot;: &quot;&quot;, &quot;Timeout&quot;: 6, &quot;EDNSClientSubnet&quot;: &#123; &quot;Policy&quot;: &quot;auto&quot;, &quot;ExternalIP&quot;: &quot;&quot;, &quot;NoCookie&quot;: true &#125; &#125; ], &quot;AlternativeDNS&quot;: [ &#123; &quot;Name&quot;: &quot;OpenDNS&quot;, &quot;Address&quot;: &quot;208.67.222.222:443&quot;, &quot;Protocol&quot;: &quot;tcp&quot;, &quot;SOCKS5Address&quot;: &quot;127.0.0.1:1080&quot;, &quot;Timeout&quot;: 6, &quot;EDNSClientSubnet&quot;: &#123; &quot;Policy&quot;: &quot;auto&quot;, &quot;ExternalIP&quot;: &quot;&quot;, &quot;NoCookie&quot;: true &#125; &#125; ], &quot;OnlyPrimaryDNS&quot;: false, &quot;IPv6UseAlternativeDNS&quot;: false, &quot;WhenPrimaryDNSAnswerNoneUse&quot;: &quot;PrimaryDNS&quot;, &quot;IPNetworkFile&quot;: &#123; &quot;Primary&quot;: &quot;/opt/software/overture/ip_network_primary_sample&quot;, &quot;Alternative&quot;: &quot;/opt/software/overture/ip_network_alternative_sample&quot; &#125;, &quot;DomainFile&quot;: &#123; &quot;Primary&quot;: &quot;/opt/software/overture/domain_primary_sample&quot;, &quot;Alternative&quot;: &quot;/opt/software/overture/gfw_all_domain.txt&quot; &#125;, &quot;HostsFile&quot;: &quot;/etc/hosts&quot;, &quot;MinimumTTL&quot;: 0, &quot;DomainTTLFile&quot; : &quot;/opt/software/overture/domain_ttl_sample&quot;, &quot;CacheSize&quot; : 0, &quot;RejectQType&quot;: [255]&#125; 詳細的配置可以參考一下官方文檔。我這裡程序和配置路徑都是 &#x2F;opt&#x2F;software&#x2F;overture ，所以就把裡面的文件地址都寫成絕對的了。方便通過 systemd 啟動。 PrimaryDNS 和 AlternateDNS 分別是兩個不同的 DNS 服務器， Overture 通過接下來的 Primary 和 Alternative 配置分別作不同的解析操作。優先使用 Primary ，然後再 Alternative 。一般都是把 Primary 配置成國內的 DNS 解釋服務，然後 Alternative 配置為國外的。配置內給出的是 OpenDNS 的 DNS over HTTPS ，然後通過開在 1080 端口上的 ss-local 代理訪問。這樣就能實現 DNS 出國查詢了。 IPNetworkFile 以及 DomainFile 獲取比較需要關注的兩個文件，IPNetworkFile 內的 Primary 和 DomainFile 內的 Alternative 。 第一個文件，直接填上整個中國的網段列表即可。 第二個文件，填上 GFW 列表即可。 網段列表來源有兩個，GeoLite 或者是 APNIC ，可以運行下面的腳本從 APNIC 獲取中國網段。 123#!/bin/bashURL=&#x27;http://ftp.apnic.net/apnic/stats/apnic/delegated-apnic-latest&#x27;curl &quot;$URL&quot; | grep ipv4 | grep CN | awk -F\\| &#x27;&#123; printf(&quot;%s/%d\\n&quot;, $4, 32-log($5)/log(2)) &#125;&#x27; &gt; china.list GeoLite 的話，從 MaxMind 這個連接 下載後，自己 grep + awk 提煉出來也可以 w ，文件格式很簡單。有了這個甚至能實現不同國家走不同的代理。不過我在這裡就不多寫了。 GFW 列表的獲取，我是看的這篇文章。這裡貼出腳本。 1234567891011121314151617181920212223242526#!/bin/bash## Origin - https://moe.best/tutorial/overture.html#curl https://raw.githubusercontent.com/gfwlist/gfwlist/master/gfwlist.txt \\ | base64 -d \\ | sort -u \\ | sed &#x27;/^$\\|@@/d&#x27; \\ | sed &#x27;s#!.\\+##; s#|##g; s#@##g; s#http:\\/\\/##; s#https:\\/\\/##;&#x27; \\ | sed &#x27;/\\*/d; /apple\\.com/d; /sina\\.cn/d; /sina\\.com\\.cn/d; /baidu\\.com/d; /qq\\.com/d&#x27; \\ | sed &#x27;/^[0-9]\\+\\.[0-9]\\+\\.[0-9]\\+\\.[0-9]\\+$/d&#x27; \\ | grep &#x27;^[0-9a-zA-Z\\.-]\\+$&#x27; \\ | grep &#x27;\\.&#x27; \\ | sed &#x27;s#^\\.\\+##&#x27; \\ | sort -u \\&gt; /tmp/temp_gfwlist.txtcurl https://raw.githubusercontent.com/hq450/fancyss/master/rules/gfwlist.conf \\ | sed &#x27;s/ipset=\\/\\.//g; s/\\/gfwlist//g; /^server/d&#x27; \\&gt; /tmp/temp_koolshare.txtcat /tmp/temp_gfwlist.txt /tmp/temp_koolshare.txt \\ | sort -u \\&gt; gfw_all_domain.txt 原來的文章內也有 Overture 的相關說明，可以參照。 接下來，寫個 OvertureDNS.service 然後丟到 /lib/systemd/system 內，重加載 unit 後啟動即可。現在就能享受到一個路由和一個正常的 DNS 了。 ipset 自動出國接下來配置自動根據 IP 所屬地確定使用代理還是直連。 ipset 配置首先安裝 ipset ， apt install ipset -y 。 然後在 ipset 創建一個集合，存放中國網段。我這裡就叫這個集合 net_list_cn 。 1ipset create net_list_cn hash:net 然後把所有的中國 ip 丟進去就好了，可以直接利用之前 Overture 的 IP 列表。 1IFS=$&#x27;\\n&#x27;; for i in $(cat china.list); do ipset add net_list_cn $i; done 是個十分低效的辦法呢。。。算了能用就行了。 iptables 配置iptables 配置繼續照葫蘆畫瓢，炒了 shadowsocks 的說明然後加點料。 123456789101112131415161718192021# 創建個鏈，方便管理規則iptables -t nat -N router_auto_proxy# 所有到 Shadowsocks 的連接全部直連， 假設代理服務器是 114.51.4.19 端口 19810iptables -A router_auto_proxy -d 114.51.4.19/32 -p tcp -m tcp --dport 19810 -j RETURNiptables -A router_auto_proxy -d 114.51.4.19/32 -p udp -m udp --dport 19810 -j RETURN# 內網連接全部 passiptables -A router_auto_proxy -d 0.0.0.0/8 -j RETURNiptables -A router_auto_proxy -d 10.0.0.0/8 -j RETURNiptables -A router_auto_proxy -d 127.0.0.0/8 -j RETURNiptables -A router_auto_proxy -d 169.254.0.0/16 -j RETURNiptables -A router_auto_proxy -d 172.16.0.0/12 -j RETURNiptables -A router_auto_proxy -d 192.168.0.0/16 -j RETURNiptables-A router_auto_proxy -d 224.0.0.0/4 -j RETURNiptables -A router_auto_proxy -d 240.0.0.0/4 -j RETURN# 中國連接也 passiptables -A router_auto_proxy -m set --match-set net_list_cn dst -j RETURN# 其他的都通過代理訪問iptables -A router_auto_proxy -p tcp -j REDIRECT --to-ports 9527# 生效iptables -A PREROUTING -p tcp -j router_auto_proxy 至此，完事。。。 後記記得通過 iptables-save 和 ipset save 保存好 iptables 和 ipset 的配置，不然重啓關機又要手動配置一次。可以寫個 service 自動開機的時候 restore 回去。 一開始一點都不懂，現在懂了一點點，然後就這樣做了這個路由器 + 代理。匆忙寫下來怕日後忘記。 x86 的話，這個方案還有很多可以擴展的地方，例如軟件本身的配置優化、增加分流選項、自動更新 ip 和域名列表⋯⋯ 這些都是等以後再搞了。 接下來有時間，可能還會嘗試重新做一套能在 openwrt 上運行的方案。","categories":[{"name":"Linux 技术应用","slug":"Linux-技术应用","permalink":"https://cattenlinger.github.io/categories/Linux-%E6%8A%80%E6%9C%AF%E5%BA%94%E7%94%A8/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://cattenlinger.github.io/tags/Linux/"},{"name":"iptables","slug":"iptables","permalink":"https://cattenlinger.github.io/tags/iptables/"},{"name":"Network","slug":"Network","permalink":"https://cattenlinger.github.io/tags/Network/"}]},{"title":"Spring Data Redis - RedisTemplate 随说","slug":"Spring-Data-Redis-RedisTemplate-随说","date":"2018-12-17T23:12:50.000Z","updated":"2025-03-24T00:48:01.538Z","comments":true,"path":"2018/12/18/ed668ee369c7.html","link":"","permalink":"https://cattenlinger.github.io/2018/12/18/ed668ee369c7.html","excerpt":"","text":"一直用 Spring Data Redis 偷懒了不少次，但遇到问题了才明白了这个玩意到底怎么回事。 它干了啥首先，RedisTemplate 封装了一系列 Redis 操作，常用的 Key-Value 操作、HashMap 操作以及数组操作等等，直接操作 Jedis 跟操作它其实是没啥两样的，不过既然能叫 Template 了，也就是说它考虑了很多常用的操作。（稍微说一下 Spring 对不同的数据库都有 Template 例如 JdbcTemplate 封装 SQL 常用草组，MongoTemplate 封装 MongoDB 常用操作）。 然后，它里面还管理了序列化：Key、Value 在 Redis 里面都是 byte ，所以需要把 Java 的对象序列化成 byte 数组。 Redis 支持事务* ，所以 RedisTemplate 也提供了事务管理。 查看它到底自己存储了什么东西就知道了 12345678910111213141516171819202122232425public class RedisTemplate&lt;K, V&gt; extends RedisAccessor implements RedisOperations&lt;K, V&gt;, BeanClassLoaderAware &#123; private boolean enableTransactionSupport = false; private boolean exposeConnection = false; private boolean initialized = false; private boolean enableDefaultSerializer = true; private @Nullable RedisSerializer&lt;?&gt; defaultSerializer; private @Nullable ClassLoader classLoader; @SuppressWarnings(&quot;rawtypes&quot;) private @Nullable RedisSerializer keySerializer = null; @SuppressWarnings(&quot;rawtypes&quot;) private @Nullable RedisSerializer valueSerializer = null; @SuppressWarnings(&quot;rawtypes&quot;) private @Nullable RedisSerializer hashKeySerializer = null; @SuppressWarnings(&quot;rawtypes&quot;) private @Nullable RedisSerializer hashValueSerializer = null; private RedisSerializer&lt;String&gt; stringSerializer = new StringRedisSerializer(); private @Nullable ScriptExecutor&lt;K&gt; scriptExecutor; // cache singleton objects (where possible) private @Nullable ValueOperations&lt;K, V&gt; valueOps; private @Nullable ListOperations&lt;K, V&gt; listOps; private @Nullable SetOperations&lt;K, V&gt; setOps; private @Nullable ZSetOperations&lt;K, V&gt; zSetOps; private @Nullable GeoOperations&lt;K, V&gt; geoOps; private @Nullable HyperLogLogOperations&lt;K, V&gt; hllOps;&#125; 看，其实很简单，相信很多人在用 Redis 的时候都做过类似的东西去处理相关操作。 操作（Operations）在 RedisTemplate 有不少自己的 operation domain（操作概念），调用对应的方法就能获取一个 domain operator（操作对象），方便使用者去做不同的操作： opsForValue - 操作 Key - Value ，简单的键值对 opsForList - 操作列表 opsForSet - 操作集合（set） opsForZSet - 操作有序集合（sorted set，在 Redis 内叫 zSet） opsForHash - 操作 Map 集合 opsForGeo - 操作地理信息，可以当作 HashSet 看，不过里面的 Key 是二维地理坐标 opsForHyperLogLog - 操作 HyperLogLog 值，是 counter 。 opsForCluster - 操作集群，管理集群用。 稍微说一下 HyperLogLog ，给它塞数据进去就给你 count 已经有多少个，因为是基于“基数估计”所以不会很准确。用于大客流计算。 除了 HyperLogLog 和 Cluster 两个 domain，其他都有对应的 bounds（绑定操作），用于绑定到某个键，例如这两个操作可以互换： 12opsForValue().set(&quot;key&quot;,&quot;value&quot;);boundValueOps(&quot;key&quot;).set(&quot;value&quot;); // 不要这样操作，会产生很多 bounded operator（绑定操作对象） 允许这样做是为了保留上下文信息方便使用。其实 domain operator 和 bounded domain operator 都是用来保留上下文信息的对象，前者保留 redisTemplate 的上下文信息，后者则是前者加上 key 上下文信息，你可以把它保留并传递下去，这样就不需要直接暴露 redisTemplate 增加无谓的设计上的麻烦了（最小责任原则）。 序列化因为 Java 是个强类型语言，所以序列化&#x2F;反序列化都需要有类型信息，而类型信息怎么存储就是个问题了。 每个 RedisTemplate 都有自己的序列化器。你是可以持有多个 RedisTemplate 的。使用多个 RedisTemplate 实例会方便存储各种类型信息（当然也是可以存储在持久化到 Redis 的数据里面的，只是我不喜欢这么干），看看泛型传参就知道了。 每个 Template 都有四个字段存储序列化器 keySerializer - key 序列化器 valueSerializer - 值序列化器 hashKeySerializer - 用于 Hash 操作的 key 序列化器 hashValueSerializer - 用于 Hash 操作的 value 序列化器 默认情况下如果不设置， 各个序列化器会直接使用 defaultSerializer ，如果不全部都指定的话，建议设置一个 defaultSerializer 。这个行为是在 RedisTempalte 的 afterPropertiesSet() 方法里的。新建完一个 RedisTemplate 必须调用一次这个方法，不然会报错叫你再调用一次，我就是踩过这个坑（ 序列化器都需要实现接口 RedisSerializer ，这个类实在很简单，就两个方法，序列化和反序列化。直接贴源码 1234567891011121314151617181920212223242526272829/** * Basic interface serialization and deserialization of Objects to byte arrays (binary data). It is recommended that * implementations are designed to handle null objects/empty arrays on serialization and deserialization side. Note that * Redis does not accept null keys or values but can return null replies (for non existing keys). * * @author Mark Pollack * @author Costin Leau * @author Christoph Strobl */public interface RedisSerializer&lt;T&gt; &#123; /** * Serialize the given object to binary data. * * @param t object to serialize. Can be &#123;@literal null&#125;. * @return the equivalent binary data. Can be &#123;@literal null&#125;. */ @Nullable byte[] serialize(@Nullable T t) throws SerializationException; /** * Deserialize an object from the given binary data. * * @param bytes object binary representation. Can be &#123;@literal null&#125;. * @return the equivalent object instance. Can be &#123;@literal null&#125;. */ @Nullable T deserialize(@Nullable byte[] bytes) throws SerializationException;&#125; 十分宽松噢，能抛异常还能抛 null （wwwwwww 如果你不想这么麻烦，那直接用官方提供的两个默认 Serializer 就好了： StringRedisSerializer - 直接序列化成 String ，只支持 String 。 GenericJackson2JsonRedisSerializer - 序列化成 Json String ，啥都能序列化。 一般来说这两个就够用了。 GenericJackson2JsonRedisSerializer 有一点要说明一下，它做了些工作。 它会对 null 值作特殊处理，内带一个自己的 NullValueSerializer ，在创建的时候会注册到自己的 ObjectMapper 上（就是 Jackson 的 ObjectMapper），把 Null 值序列化成 Spring 的 Cache 专用的 NullValue.class 。所以如果这个 Feature 对你有害，考虑对照它自己写一个新的。 它默认会把类型信息同时写入 Redis ，方便兼容各种 Class 的 instance 的序列化，但我自己在用的时候发现输出到 Http Body 的 JSON 会带上 @class 字段，容易泄漏代码信息，想了几个办法都去不掉。所以如果这个对你有影响的话，自己实现一个比较好。 我自己方便使用的原因，所以每个拥有自己的 scope 的用到 Redis 的实例都带有类型信息而且单独拥有一个 RedisTemplate 并单独拥有 ValueSerializer。这里贴个我自己轮子的代码作示范，主要在里面的 valueSerializer 。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364public abstract class InMemoryStoreAdapter&lt;T&gt; implements InMemoryStore &#123; private final static byte[] EMPTY_ARRAY = new byte[0]; // ......其他无关紧要的东西 protected final RedisTemplate&lt;String, T&gt; redisTemplate; // 所有的子类都使用同一个 KeySerializer 实例 private final static RedisSerializer&lt;String&gt; keySerializer = new StringRedisSerializer(); // 所有的子类都使用同一个 ObjectMapper 实例 private final static ObjectMapper objectMapper = new ObjectMapper(); // 构造器 protected InMemoryStoreAdapter(RedisConnectionFactory redisConnectionFactory, String domain) &#123; // 这里新建一个 RedisTemplate 给自己用 this.redisTemplate = new RedisTemplate&lt;&gt;(); redisTemplate.setConnectionFactory(redisConnectionFactory); // 获取自己的泛型参数类型信息，自己存储。 Type mainType = getClass().getGenericSuperclass(); ParameterizedType parameterizedType = (ParameterizedType) mainType; Class&lt;T&gt; mainTypeClass = (Class&lt;T&gt;) parameterizedType.getActualTypeArguments()[0]; // 每个子类的 redisTemplate 都有自己的 ValueSerializer ，我直接把它写成匿名类了。 RedisSerializer&lt;T&gt; valueSerializer = new RedisSerializer&lt;T&gt;() &#123; // ObjectReader 其实也是个上下文存储对象，里面包含了类型信息， // 用的 ObjectMapper 还是原来的那个 private final ObjectReader objectReader = objectMapper.readerFor(mainTypeClass); private final ObjectWriter objectWriter = objectMapper.writer(); @Override public byte[] serialize(T t) throws SerializationException &#123; try &#123; return t == null ? EMPTY_ARRAY : objectWriter.writeValueAsBytes(t); &#125; catch (JsonProcessingException e) &#123; throw new SerializationException(&quot;Could not write object to JSON: &quot;, e); &#125; &#125; @Override public T deserialize(byte[] bytes) throws SerializationException &#123; try &#123; return (bytes == null || bytes.length &lt;= 0) ? null : objectReader.readValue(bytes); &#125; catch (IOException e) &#123; throw new SerializationException(&quot;Could not read object from JSON: &quot;, e); &#125; &#125; &#125;; // 设定各个序列化器 redisTemplate.setDefaultSerializer(valueSerializer); redisTemplate.setKeySerializer(keySerializer); redisTemplate.setHashKeySerializer(keySerializer); redisTemplate.setValueSerializer(valueSerializer); // 记得调用 afterPropertiesSet() redisTemplate.afterPropertiesSet(); // ......其他代码 &#125;&#125; 唠叨话要自己实现一个 redisTemplate 也不难，但重复造轮子实际上是一种浪费时间的做法，如果已经有了一个不难用的轮子，直接拿来用就好了，they are life saver。不过，在不想和 Spring 有依赖的场合里，做一个小轮子还是有必要的。","categories":[{"name":"开发框架","slug":"开发框架","permalink":"https://cattenlinger.github.io/categories/%E5%BC%80%E5%8F%91%E6%A1%86%E6%9E%B6/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://cattenlinger.github.io/tags/Java/"},{"name":"Spring","slug":"Spring","permalink":"https://cattenlinger.github.io/tags/Spring/"}]},{"title":"运维流水账 #1","slug":"运维流水账-1","date":"2018-08-21T23:10:42.000Z","updated":"2025-03-24T00:57:58.378Z","comments":true,"path":"2018/08/22/f80d22fd140a.html","link":"","permalink":"https://cattenlinger.github.io/2018/08/22/f80d22fd140a.html","excerpt":"","text":"唉，要搭个 SOA 的基建架子，感觉自己学那么多东西会忘掉，所以不如开个流水账话题来记录一下好了 装系统整个系统结构是这样的。一个服务器做 Nginx 门面，两个跑业务程序的节点服务器，一个数据库服务器。门面和节点都是双核 4GB 内存，垃圾阿里云又不让我买那种单核 1GB 的，不然还能省点钱。数据库比较厉害，大了一半，虽然硬盘还是那么一点。 我写了点运维脚本让流程半自动化，买回来之后改成了统一密码，写了个脚本通过 ssh 自动做了这几件事情： 新建自己的用户（并不喜欢用 root 干所有事情，宁愿 sudo su） 初始化自己的密码（这样搞定之后就能直接 ssh-id-copy 了） 把自己加入管理员组（ \\ sudo &#x2F; ） 安装 epel 源（ CentOS 7.4 嘛） 更新系统软件（默认镜像都是旧的软件不喜欢） 安装自己的服务器软件（ nginx、 java 、 tmux 、 htop 、 doker ……） 重启（懒得逐个服务器重启） 嗯。四台服务器我就是一边喝奶茶一边等着输密码。 搭数据库搞定之后呢，我首先搭数据库。yum install mairadb-server -y 。启动 mariadb 的守护进程，然后运行一遍 secure installation 就好了。 配置用户方面，因为是数据库节点，所以我给用户设定的 host 是整个 C 类网段，app_xxx@172.23.4.% 这样就好了，再在同网段的服务器上测试一下登录，搞定。 搭应用嘛公司的垃圾应用我就不说啥了，jeeSite 只适合拿来快速交付的，这沙雕就拿来做产品，不说了。 节点机上面我分别做了两次，因为觉得就两台机子没必要故意写个脚本了。安装 tomcat 把 war 包丢进去，数据库配置就换一下 ip 就行了，访问两个节点的 8080 ，都活了，搞定。 不过我并没有首先直接访问 8080，而是用了 ssh 隧道拉到本地打开了。 1ssh -v -NT -L 8080:localhost:8080 server_address; （喜欢 -v 参数是因为我喜欢这种看临时运行的进程的 log （wwww 搭门面配置一下 nginx 就好了，因为内网都是互通的，proxy pass 到这些服务器的端口就好了。我有个习惯，喜欢把 nginx.conf 内的 server 都丢到同级 server.conf.d 内，分文件存放，然后在 nginx.conf 里 include，这样方便处理很多。 负载均衡的配置我觉得需要稍微记录一下，因为就只有这里我是需要去查资料的。 123456789101112131415161718upstream nodes &#123; server 172.30.1.1:8080 max_fails=3; # node 0 server 172.30.1.2:8080 max_fails=3; # node 1&#125;server &#123; listen 80 default_server; listen [::]:80 default_server; server_name _; #root /usr/share/nginx/html; location / &#123; proxy_pass http://nodes; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; &#125;&#125; 写好保存，nginx -t 测试一下配置文件无误，然后就能nginx -s reload 了。 测试建议同时开启两个节点以及门面服务器的 journal 以获得更好的玩耍体验（大雾 1journalctl -u tomcat -f 不断访问门面的公网 IP 就能看到两个服务器的 tomcat 轮流出 log 了 wwwwwww （调优？以后吧","categories":[],"tags":[]},{"title":"现代前端 + SpringBoot 结合开发的 Maven 配置","slug":"现代前端-SpringBoot-结合开发的-Maven-配置","date":"2018-07-30T23:06:39.000Z","updated":"2025-03-24T00:47:49.222Z","comments":true,"path":"2018/07/31/b6bdc77a64f4.html","link":"","permalink":"https://cattenlinger.github.io/2018/07/31/b6bdc77a64f4.html","excerpt":"","text":"好些日子之前就在网上看见一篇文章，说一个小后端想用 Vue 作前端技术结合 SpringBoot 后端作开发，但又想方便点让前端的工程能够自己跑进 Jar 包里。很感兴趣诶，于是就动手跟着实现一遍。 原文：A Lovely Spring View: Spring Boot &amp; Vue.js 原理实际是利用 frontend-maven-plugin 来调用 node ，不过这个插件有个好处，它是在工程的目录下安装 node，这样能摆脱对本机 node 的依赖，在很多地方进行构建。 起来先建一个普通的 SpringBoot 工程项目，然后普通地把 src/ 删掉开始建立子模块。我是建立了 backend 和 frontend 两个模块。 12345678910springboot-vue/ |- frontend/ | |- src/ | | |- ... | |- pom.xml |- backend/ | |- src/ | | |- ... | |- pom.xml |- pom.xml 根 pom ： 123456789101112131415161718192021222324252627282930313233343536373839&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;net.catten&lt;/groupId&gt; &lt;artifactId&gt;springboot-vue&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;modules&gt; &lt;module&gt;backend&lt;/module&gt; &lt;module&gt;frontend&lt;/module&gt; &lt;/modules&gt; &lt;packaging&gt;pom&lt;/packaging&gt; &lt;name&gt;project-management&lt;/name&gt; &lt;description&gt;Team project progress management system&lt;/description&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.0.1.RELEASE&lt;/version&gt; &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt; &lt;/parent&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-jpa&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-logging&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; 后端，backend 需要配置一下 maven-resource-plugin 123456789101112131415161718192021222324252627282930313233343536373839404142434445&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;parent&gt; &lt;artifactId&gt;springboot-vue&lt;/artifactId&gt; &lt;groupId&gt;net.catten&lt;/groupId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;artifactId&gt;backend&lt;/artifactId&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;artifactId&gt;maven-resources-plugin&lt;/artifactId&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;copy Vue frontend content&lt;/id&gt; &lt;phase&gt;generate-resources&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;copy-resources&lt;/goal&gt; &lt;/goals&gt; &lt;configuration&gt; &lt;outputDirectory&gt;src/main/resources/static&lt;/outputDirectory&gt; &lt;overwrite&gt;true&lt;/overwrite&gt; &lt;resources&gt; &lt;resource&gt; &lt;directory&gt; $&#123;project.parent.basedir&#125;/frontend/dist &lt;/directory&gt; &lt;/resource&gt; &lt;/resources&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; 对这个插件熟悉的就可以跳过下面说明了。 其中 plugin 的 configuration 内，outputDirectory 是指输出的地方， resource 指从哪里复制文件，复制的文件当然就是 webpack 打包出来的了。 前端，配置 frontend-maven-plugin 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;parent&gt; &lt;artifactId&gt;springboot-vue&lt;/artifactId&gt; &lt;groupId&gt;net.catten&lt;/groupId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;artifactId&gt;frontend&lt;/artifactId&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;com.github.eirslett&lt;/groupId&gt; &lt;artifactId&gt;frontend-maven-plugin&lt;/artifactId&gt; &lt;version&gt;1.6&lt;/version&gt; &lt;executions&gt; &lt;!-- Install our node and npm version to run npm/node scripts--&gt; &lt;execution&gt; &lt;id&gt;install node and npm&lt;/id&gt; &lt;goals&gt; &lt;goal&gt;install-node-and-npm&lt;/goal&gt; &lt;/goals&gt; &lt;configuration&gt; &lt;nodeVersion&gt;v9.11.1&lt;/nodeVersion&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;!-- Install all project dependencies --&gt; &lt;execution&gt; &lt;id&gt;npm install&lt;/id&gt; &lt;goals&gt; &lt;goal&gt;npm&lt;/goal&gt; &lt;/goals&gt; &lt;!-- optional: default phase is &quot;generate-resources&quot; --&gt; &lt;phase&gt;generate-resources&lt;/phase&gt; &lt;!-- Optional configuration which provides for running any npm command --&gt; &lt;configuration&gt; &lt;arguments&gt;install&lt;/arguments&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;!-- Build and minify static files --&gt; &lt;execution&gt; &lt;id&gt;npm run build&lt;/id&gt; &lt;goals&gt; &lt;goal&gt;npm&lt;/goal&gt; &lt;/goals&gt; &lt;configuration&gt; &lt;arguments&gt;run build&lt;/arguments&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; 这个基本上不用去动，如果对 nodeVersion 有要求可以修改一下。这里的配置是会在 generate-resources 的时候调用 npm run build ，实际拷贝资源文件的操作还是 backend 内的插件做的，所以拷贝的源文件路径需要和 webpack 的配置配合，按需修改 backend 的 configurations。 是一篇只知道怎么用不去深究喂到嘴边式快餐文（逃）","categories":[{"name":"开发框架","slug":"开发框架","permalink":"https://cattenlinger.github.io/categories/%E5%BC%80%E5%8F%91%E6%A1%86%E6%9E%B6/"}],"tags":[{"name":"Maven","slug":"Maven","permalink":"https://cattenlinger.github.io/tags/Maven/"},{"name":"Web App","slug":"Web-App","permalink":"https://cattenlinger.github.io/tags/Web-App/"}]},{"title":"手动安装 RabbitMQ","slug":"手动安装-RabbitMQ","date":"2018-06-08T23:04:28.000Z","updated":"2025-03-24T00:47:08.578Z","comments":true,"path":"2018/06/09/a549e33e8828.html","link":"","permalink":"https://cattenlinger.github.io/2018/06/09/a549e33e8828.html","excerpt":"","text":"想装个 RabbitMQ，然后源上没有，就只好手动装了。（对着果冻就摁下 pakreq 先从官方网站下载 Generic UNIX 的二进制包，地址不用贴了吧 Google 一下就有了。。 找个地方就解压下来，我现在比较喜欢在 /opt 下面放这些自己安装的服务软件。 1234cd /opttar pxfv ~/Downloads/rabbitmq-server-generic-unix-3.7.2.tar.xzmv rabbitmq_server-3.7.2 rabbitmqcd rabbitmq 说实话，不喜欢里面的文件夹命名。。。又不是系统级别工具干嘛叫自己 sbin 呢。 12345678910111213ls -al[OUTPUT]-------------------------------------------------------------------------------total 72drwxrwxr-x 14 rabbitmq wheel 4096 Dec 30 04:30 .drwxrwxr-x 8 root wheel 4096 Dec 29 18:13 ..drwxrwxr-x 2 rabbitmq wheel 12288 Dec 23 15:00 ebindrwxrwxr-x 2 rabbitmq wheel 4096 Dec 23 15:00 escriptdrwxrwxr-x 2 rabbitmq wheel 4096 Dec 23 15:00 includedrwxrwxr-x 3 rabbitmq wheel 4096 Dec 30 03:49 logdrwxrwxr-x 2 rabbitmq wheel 4096 Dec 23 15:00 pluginsdrwxrwxr-x 3 rabbitmq wheel 4096 Dec 23 15:00 privdrwxrwxr-x 2 rabbitmq wheel 4096 Dec 23 15:00 sbindrwxrwxr-x 3 rabbitmq wheel 4096 Dec 23 15:00 share 权限是我自己事先设置好的，我增加了一个 rabbitmq 用户专门用来跑 rabbitmq-server 。顺便为了方便管理，增加了 config 、data 、log 三个文件夹。 123456useradd -b /opt/rabbitmq -d /opt/rabbitmq -s /sbin/nologin rabbitmqusermod -a -G wheel rabbitmqmkdir configmkdir datamkdir log 新建了一个 rabbitmq.server 方便直接用 systemd 启动。 123456789101112[Unit]Description=RabbitMQ - Message Queue ServiceRequires=network.target[Service]EnvironmentFile=/opt/rabbitmq/config/rabbitmq-environmentExecStart=/opt/rabbitmq/sbin/rabbitmq-serverUser=rabbitmq[Install]WantedBy=multi-user.target 环境变量我独立在外部文件 /opt/rabbitmq/config/rabbitmq-environment 了 12345678910111213141516171819# The HOME directoryHOME=/opt/rabbitmq# Home for RabbitMQRABBITMQ_HOME=/opt/rabbitmq# Base DirectoryRABBITMQ_BASE=$RABBITMQ_HOME/data# MNESIA DirectoryRABBITMQ_MNESIA_BASE=$RABBITMQ_HOME/data/mnesia# Log baseRABBITMQ_LOG_BASE=$RABBITMQ_HOME/log# Config file location and new filenameRABBITMQ_CONFIG_FILE=$RABBITMQ_HOME/config/rabbitmq-defRABBITMQ_ADVANCED_CONFIG_FILE=$RABBITMQ_HOME/config/rabbitmq-adv 把文件复制到 /etc/systemd/system 然后 systemctl daemon-reload 就可以用 systemd 启动 RabbitMQ 了。rabbitmq-def 和 rabbitmq-adv 这两个配置文件不需要增加后缀名，启动的时候 RabbitMQ 会自动创建对应的文件。 建议把 HOME 删掉之后导出到环境变量里，我的环境变量是从 /etc/profile.d 额外加载的，所以我在里面创建了 rabbitmq.sh ，之后要 chmod +x rabbitmq.sh 。 123456789101112131415161718# Home for RabbitMQexport RABBITMQ_HOME=/opt/rabbitmq# Base Directoryexport RABBITMQ_BASE=$RABBITMQ_HOME/data# MNESIA Directoryexport RABBITMQ_MNESIA_BASE=$RABBITMQ_HOME/data/mnesia# Log baseexport RABBITMQ_LOG_BASE=$RABBITMQ_HOME/log# Config file location and new filenameexport RABBITMQ_CONFIG_FILE=$RABBITMQ_HOME/config/rabbitmq-defexport RABBITMQ_ADVANCED_CONFIG_FILE=$RABBITMQ_HOME/config/rabbitmq-adv#Export variablesexport PATH=$PATH:$RABBITMQ_HOME/sbin 注意 RABBITMQ_BASE 是必须要的，因为 rabbitmqctl 命令从环境变量里获得 RabbitMQ 的位置来操作 rabbitmq-server 。还注意的是，RabbitMQ 的 socket 文件，只有运行 RabbitMQ 的用户可操作，所以在这里需要用 rabbitmq 的权限来使用 rabbitmqctl ，我增加了个 alias 来使用（怎么这么刁钻啊 1alias rabbitmqctl=&#x27;sudo -E -u rabbitmq rabbitmqctl&#x27;; 好了这样就可以愉快地使用 RabbitMQ 开发了（吧？ 其他进阶设置请参考资料 &#x3D;w &#x3D; ： RabbitMQ - Install on Generic Unix","categories":[{"name":"Linux 技术应用","slug":"Linux-技术应用","permalink":"https://cattenlinger.github.io/categories/Linux-%E6%8A%80%E6%9C%AF%E5%BA%94%E7%94%A8/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://cattenlinger.github.io/tags/Linux/"},{"name":"RabbitMQ","slug":"RabbitMQ","permalink":"https://cattenlinger.github.io/tags/RabbitMQ/"}]},{"title":"微信支付开发经历 - 坑爹的微信","slug":"微信支付开发经历-坑爹的微信","date":"2018-06-08T22:58:49.000Z","updated":"2024-09-30T12:28:22.400Z","comments":true,"path":"2018/06/09/8c5b52c6c79b.html","link":"","permalink":"https://cattenlinger.github.io/2018/06/09/8c5b52c6c79b.html","excerpt":"","text":"唠叨几句因为被微信那个破烂文档坑了我两个星期，导致项目进度慢了很多。本来微信的 API 的确是设计得烂，但烂我也觉得不要紧了，文档也烂那我就真的火了，跟人捉迷藏似的东一块西一块（玩猜谜吗你）。这里也记录一下我做开发遇到的坑。 如何申请公众号以及商户平台不在本文范畴内，因为项目经理已经拿到这这些东西了，我所做的就是完成代码的编写。 环境这里使用了 com.github.binarywang 的 jar，下面默认都是在这个前期下讨论。其他自己实现的或者其他人的库请配合文档和其他人分享的资料看。 1234567891011&lt;dependency&gt; &lt;groupId&gt;com.github.binarywang&lt;/groupId&gt; &lt;artifactId&gt;weixin-java-mp&lt;/artifactId&gt; &lt;version&gt;2.8.0&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;com.github.binarywang&lt;/groupId&gt; &lt;artifactId&gt;weixin-java-pay&lt;/artifactId&gt; &lt;version&gt;2.8.0&lt;/version&gt;&lt;/dependency&gt; 正文首先有一个十分重要的提醒： 配合前端开发人员测试微信支付的时候千万千万不能用微信的沙箱。 那个沙箱没有他们文档说的那么厉害，只能确认微信回调我们服务器没问题，不能用来模拟测试整个支付流程，而且这个沙箱设计得十分垃圾，连沙箱都算不上（支付金额只允许用例内的。你见过只能画指定几个图案的沙箱吗？？），所以还是乖乖地测一次给一分钱吧。 开发一般开发主要用到微信的两种支付方式 JSAPI ： 用于在微信自己的浏览器里面唤起微信支付 NATIVE ： 用于扫码支付 JSAPI 不用多说，就是触发之后会唤起微信的支付对话框给用户选择支付与否。 NATIVE 就是生成订单之后给用户用微信扫码付款的。这个方式我看了文档，微信给本来的设计貌似是给那些自动贩卖机用的，不过稍微改变一下使用方法就可以适用于任意扫码支付。 JSAPI 和 NATIVE 两种支付方式均使用统一下单接口先获取微信预付款订单信息，然后再进行剩下的操作。两者传参几乎一样，不同的是： JSAPI 需要传入 openId，NATIVE 不需要。 NATIVE 需要传入 productId，JSAPI 不需要。 上面所说的稍微改变一下使用方法，就是在 NATIVE 支付的时候 productId 使用自己的订单 ID 就好了。 NATIVE 支付方式首先说这个支付方式是因为，这个方式很简单，而且我也很推荐用这个，但扫码就需要用另外一台手机了。 根据微信的文档向统一下单接口传入相应的参数之后，就得到预付款订单了。这里得到的预付款订单包含了参数 codeUrl ，传这个给前端开发的去生成二维码或者自己服务器端生成二维码都可以，扫码之后就可以用微信付款。付款成功之后，微信会通过预先指定的回调 API 发送订单支付的结果。根据结果完成自己的订单逻辑这个就不说了。 JSAPI 支付方式我觉得这个就是最坑爹的地方了。 首先传入参数之后，微信返回了预付款订单信息，然后这个信息需要返回给前端。但是，这之前需要对预付款订单的某些字段拼接起来，作一次签名，签名需要严格按照字段序排序以及注意大小写： appId nonceStr package signType timeStamp 1234567StringBuilder params = new StringBuilder() .append(&quot;appId=&quot;).append(wxPayService.getConfig().getAppId()).append(&quot;&amp;&quot;) .append(&quot;nonceStr=&quot;).append(nonceStr).append(&quot;&amp;&quot;) .append(&quot;package=&quot;).append(&quot;prepay_id=&quot;).append(orderResult.getPrepayId()).append(&quot;&amp;&quot;) .append(&quot;signType=&quot;).append(&quot;MD5&quot;).append(&quot;&amp;&quot;) .append(&quot;timeStamp=&quot;).append(timestamp);//appId=&#123;appId&#125;&amp;nonceStr=&#123;nonceStr&#125;&amp;package=prepay_id=&#123;prepayId&#125;&amp;signType=MD5&amp;timeStamp=&#123;timestamp&#125; （真心对微信大小写随便来表示很无语）其中 nonceStr prepay_id 需要与微信返回的预付款订单内的一致。timeStamp 也要传给前端，到时候前端需要把这个 timeStamp 传进唤起微信支付对话框的函数。 拼接好这个之后，再在后面拼接参数 key 并进行一次 MD5。 12params.append(&quot;&amp;&quot;).append(&quot;key=&quot;).append(wxPayService.getConfig().getMchKey());String prepay_sign = DigestUtils.getMD5(true, params.toString()); 所以所需要传给前端的参数如下： 123456&#123; &quot;appId&quot;:&quot;你的 appId&quot;, &quot;nonceStr&quot;:&quot;订单内的 nonceStr&quot;, &quot;timeStamp&quot;:&quot;订单参数签名的时间&quot;, &quot;prepay_sign&quot;:&quot;订单签名结果&quot;&#125; 这时候不要急着去唤起微信的支付窗口，因为还有后面一系列步骤。 这里需要注意这些返回的参数： nonceStr timeStamp 这两个参数在整个支付的过程中要一致，而且参数大小写也需要注意。流程内的 API 有的地方给弄驼峰命名法有的地方则用全小写。 然后，前端需要再拿当前调用 JSAPI 支付的浏览器地址栏的路径，向服务器请求一个签名，这个签名就是前端唤起 JSAPI 所需要的签名，我这里请求的 API 以及示例如下： 1234567POST -&gt; https://shinonometn.com/WC/ticket&#123; &quot;url&quot;:&quot;https://shinonometn.com/?#/order/11&quot;, &quot;nonceStr&quot;:&quot;8897djsk09ll&quot;, &quot;timeStamp&quot;:1560789&#125; url 那里一定一定要注意，对于 SPA 应用，路由前缀那里，绝对不能只有一个#，微信的这个安全机制很傻屄。首先你需要去商户平台那里注册 JSAPI 支付允许的“支付目录”（我晕，目录），然后在调用 JSAPI 支付的时候他们会校验你地址栏”在“不”在“已注册的“支付目录”，不在就拒绝下单。我猜他们这个机制是做给服务器端渲染页面的应用做的：你会发现你的 SPA 应用拿到的 URL 经常跟他们微信拿到的 URL 不匹配，从而一直提示你 URL 未注册 然后拒绝下单。这其实不算坑，文档在很隐蔽的地方提及需要前端拿这个 sign 去调用 JSAPI 支付 and 支付前需要调用 config 一次才是坑死人。 这个签名是这样的，如下参数全小写，严格按照字典顺序排序： jsapi_ticket（我一直不知道这个东西的存在，因为文档里面没有提及） noncestr（小写，小心） timestamp （小写，小心） url （就是上面提及的 URL） 然后如此拼接： 123jsapi_ticket=&#123;你拿到的 JSAPI TICKET&#125;&amp;noncestr=&#123;订单上的 nonceStr&#125;&amp;timestamp=&#123;你订单的 timeStamp&#125;&amp;url=&#123;URL&#125;//不算大括号，只是为了好看加上去的 然后对这这个拼接好的字符串，SHA1 一次，拿小写的字符串，返回给前端，那么前端就可以很愉快地填上对应的参数去 wx.config 一下，唤起微信支付窗口了。 那么这个 URL 在商户平台注册的时候需要注意什么呢？对于服务器端渲染页面，你需要填写支付页面的地址，删掉最后的”目录“： 1234//订单支付页面https://shinonometn.com/order/pay/1//注册的 URLhttps://shinonometn.com/order/pay/ 对于 SPA （单页应用）来说，你只需要填写你的应用地址，路由那里怎么方便怎么做手脚。 12345//带上路由的 SPA 的页面https://shinonometn.com/?#/order/pay/1 ^我就弄了个问号//注册的 URLhttps://shinonometn.com/ 唉，就是因为 JSAPI 的沙雕设计我加班到凌晨 2 点陪前端的人调试。 ##参考链接在Web应用中接入微信支付的流程之极简清晰微信开发，分享部分出现的问题微信支付：“当前页面的URL未注册”","categories":[],"tags":[{"name":"第三方平台","slug":"第三方平台","permalink":"https://cattenlinger.github.io/tags/%E7%AC%AC%E4%B8%89%E6%96%B9%E5%B9%B3%E5%8F%B0/"},{"name":"微信","slug":"微信","permalink":"https://cattenlinger.github.io/tags/%E5%BE%AE%E4%BF%A1/"},{"name":"支付","slug":"支付","permalink":"https://cattenlinger.github.io/tags/%E6%94%AF%E4%BB%98/"}]},{"title":"如何使用 vsftpd","slug":"如何使用-vsftpd","date":"2018-06-08T22:55:08.000Z","updated":"2025-03-24T00:47:19.008Z","comments":true,"path":"2018/06/09/1aa353568331.html","link":"","permalink":"https://cattenlinger.github.io/2018/06/09/1aa353568331.html","excerpt":"","text":"因为需要简单地共享一些文件，所以就找到了 vsftpd 这个软件。vsftpd 是一款安全的 ftp (File Transport Protocol) 软件。但是这里只说明一些最最最基本的东西。 使用 vsftpd 很简单，在终端下安装好就行了，我以 Ubuntu 16.04 作例子 1sudo apt-get install vsftpd 安装好之后就行了。 vsftpd 是一款基于用户作权限管理的 ftp 软件，所以任何的访问都是使用用户来访问，在 Ubuntu 下安装好之后能够看到 ftp 这个用户 12cat /etc/passwd | grep ftpftp:x:128:139:ftp daemon,,,:/srv/ftp:/bin/false 如果现在启动 vsftpd 并且开启匿名登录的话，那么使用者所访问的目录就是 ftp 用户的主目录 /srv/ftp 。只要把文件放在这个目录即可与别人共享。开启匿名登录需要修改 /etc/vsftpd.conf 。找到 anonymous_enable 开头的那行，改成 YES 即可。 启动服务只需要执行 1sudo systemctl start vsftpd 之后即可匿名访问 ftp://localhost","categories":[{"name":"Linux 技术应用","slug":"Linux-技术应用","permalink":"https://cattenlinger.github.io/categories/Linux-%E6%8A%80%E6%9C%AF%E5%BA%94%E7%94%A8/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://cattenlinger.github.io/tags/Linux/"},{"name":"vsftpd","slug":"vsftpd","permalink":"https://cattenlinger.github.io/tags/vsftpd/"}]},{"title":"基于注解配置的 Spring 使用 WebFlux","slug":"基于注解配置的-Spring-使用-WebFlux","date":"2018-06-08T22:51:47.000Z","updated":"2025-03-24T00:47:43.858Z","comments":true,"path":"2018/06/09/badfed180c37.html","link":"","permalink":"https://cattenlinger.github.io/2018/06/09/badfed180c37.html","excerpt":"","text":"我有一个 Netty 的项目要增加一个 HTTP Server ，不能改成 Spring Boot ，但是本身使用 Spring 作依赖注入，然后就想着能不能直接使用 Netty 处理这些 Http 请求。。。在网上搜了半天，感觉往里面塞个 Servlet 不太好，于是还是回去用 Spring 的 WebFlux。虽然 WebFlux 一般都捆着 Spring Boot ，但是想着应该可以单独使用吧。。。于是就试了一下。。 一开始先找到这里 23.3.2 Manual Bootstrapping ，结果半天找不到 DispatcherHandler.toHttpHandler() 方法（懵）然后就想了些歪门邪道了（x Maven 依赖 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960&lt;properties&gt; &lt;spring.version&gt;5.0.4.RELEASE&lt;/spring.version&gt; &lt;jackson.version&gt;2.9.0&lt;/jackson.version&gt;&lt;/properties&gt;&lt;dependency&gt; &lt;groupId&gt;com.fasterxml.jackson.core&lt;/groupId&gt; &lt;artifactId&gt;jackson-core&lt;/artifactId&gt; &lt;version&gt;$&#123;jackson.version&#125;&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;com.fasterxml.jackson.core&lt;/groupId&gt; &lt;artifactId&gt;jackson-databind&lt;/artifactId&gt; &lt;version&gt;$&#123;jackson.version&#125;&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;com.fasterxml.jackson.core&lt;/groupId&gt; &lt;artifactId&gt;jackson-annotations&lt;/artifactId&gt; &lt;version&gt;$&#123;jackson.version&#125;&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-context&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-context-support&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt;&lt;/dependency&gt;&lt;!-- Reactor + Webflux 依赖 --&gt;&lt;dependency&gt; &lt;groupId&gt;io.netty&lt;/groupId&gt; &lt;artifactId&gt;netty-all&lt;/artifactId&gt; &lt;version&gt;4.1.13.Final&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-webflux&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;io.projectreactor.ipc&lt;/groupId&gt; &lt;artifactId&gt;reactor-netty&lt;/artifactId&gt; &lt;version&gt;0.7.5.RELEASE&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;io.projectreactor&lt;/groupId&gt; &lt;artifactId&gt;reactor-core&lt;/artifactId&gt; &lt;version&gt;3.1.5.RELEASE&lt;/version&gt;&lt;/dependency&gt; ApplicationConfigure.java 不需要写什么东西 123456@Configuration@EnableWebFlux@ComponentScan(&quot;com.example&quot;)public class ApplicationConfigure &#123; &#125; ApiServer.java 是我项目里的 HTTP 服务器 123456789101112131415161718192021222324252627@Componentpublic class ApiServer&#123; private ApplicationContext applicationContext; private HttpServer httpServer; public ApiServer(ApplicationContext applicationContext)&#123; this.applicationContext = applicationContext; httpServer = HttpServer.create(&quot;0.0.0.0&quot;,8080); &#125; // 可以丢到 Configuration 里面，这样就不需要像我这样注册钩子了 @PostConstruct public void start()&#123; httpServer.start(new ReactorHttpHandlerAdapter( WebHttpHandlerBuilder .applicationContext(applicationContext) .build() )); &#125; // 习惯性写上去的没啥用。。。 @PreDestroy public void stop()&#123; &#125;&#125; 随便写个 HelloController.java 。这里类注解要用 @RestController ，不然返回结果的时候会冒 viewResolver Not Found 之类的错误。 1234567@RestControllerpublic class HelloController &#123; @GetMapping public String hello() &#123; return &quot;Hello world&quot;; &#125;&#125; 启动用的 Main.java 12345678910111213public class Main &#123; private final static Logger logger = LoggerFactory.getLogger(Loggers.APPLICATION); public static void main(String... args) &#123; logger.debug(&quot;Loading application context...&quot;); AbstractApplicationContext context = new AnnotationConfigApplicationContext(ApplicationConfig.class); // 生命周期钩子用的而已 context.registerShutdownHook(); logger.info(&quot;Application context loaded.&quot;); &#125;&#125; 然后访问 http://localhost:8080 就出来一个 HelloWorld 囖~ 关于视图或者其他的话还得去查一下 WebFlux 相关的内容。","categories":[{"name":"开发框架","slug":"开发框架","permalink":"https://cattenlinger.github.io/categories/%E5%BC%80%E5%8F%91%E6%A1%86%E6%9E%B6/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://cattenlinger.github.io/tags/Java/"},{"name":"Spring","slug":"Spring","permalink":"https://cattenlinger.github.io/tags/Spring/"},{"name":"WebFlux","slug":"WebFlux","permalink":"https://cattenlinger.github.io/tags/WebFlux/"}]},{"title":"在软件菜单启动 Xmind 8 的姿势","slug":"在软件菜单启动-Xmind-8-的姿势","date":"2018-06-08T22:48:10.000Z","updated":"2025-03-24T00:46:31.915Z","comments":true,"path":"2018/06/09/c526f3ff7a7a.html","link":"","permalink":"https://cattenlinger.github.io/2018/06/09/c526f3ff7a7a.html","excerpt":"","text":"要用到 Xmind 8，于是就去下载了一个。 因为我的发行版比较特殊，AOSC OS + Cinnamon，所以就没法通过常规途径安装，也就没有去故意执行 setup.sh 了。直接双击对应发行版的 Xmind 执行文件是可以运行的，但当我尝试增加 Launcher 的时候却发现不能正常运行，Xmind 报错。 我想是不是因为启动参数有问题。在正常运行 XMind 的状况下，我打开终端看了一下它的启动参数，发现就是个很普通的 jar 包启动，然而有两个参数比较特殊。 1-configuration ./configuration -data ../workspace 通过 Launcher 启动的话，这两个地址的指向就肯定不对了，于是我就稍微修改一下 Launcher 1/opt/software/xmind/XMind_amd64/XMind -configuration &#x27;/opt/software/xmind/XMind_amd64/configuration&#x27; -data &#x27;/opt/software/xmind/workspace&#x27; 然后就正常运行起来了。","categories":[{"name":"Linux 技术应用","slug":"Linux-技术应用","permalink":"https://cattenlinger.github.io/categories/Linux-%E6%8A%80%E6%9C%AF%E5%BA%94%E7%94%A8/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://cattenlinger.github.io/tags/Linux/"}]},{"title":"关于 context:component-scan 的一次使用经验","slug":"关于-context-component-scan-的一次使用经验","date":"2018-06-08T22:41:57.000Z","updated":"2025-03-24T00:48:05.605Z","comments":true,"path":"2018/06/09/fa3ee61e1fa2.html","link":"","permalink":"https://cattenlinger.github.io/2018/06/09/fa3ee61e1fa2.html","excerpt":"","text":"问题是这样的，我按照正常的配置文件结构配置，然后每次启动起来都提示找不到 Controller ，反反复复看配置文件没发现问题，依赖也正确，甚至连数据库连接池都换了，也没解决 Controller Not Found 的问题。。。 后来过了一天我想了一下，既然是找不到 Controller ，那么就是 Controller 的类没被找到，那么如果没被找到的话，是不是扫描的时候出了问题呢？ 我原来的配置是这样的 1&lt;context:component-scan base-package=&quot;cn.lncsa.controller.*&quot;/&gt; 然后我试了一下增加了 Controller 的 filter 123&lt;context:component-scan base-package=&quot;cn.lncsa.controller.*&quot;&gt; &lt;context:include-filter type=&quot;annotation&quot; expression=&quot;org.springframework.stereotype.Controller&quot;/&gt;&lt;/context:component-scan&gt; 问题并没有被解决。 后来观察，发现 base-package 参数是 “cn.lncsa.controller.*“，然后回头对比了一下按照教程做的能正常运行的 Helloworld ，是 “net.catten.mvc.*“ 而不是”net.catten.mvc.controller.*“，我在想是不是这个通配符的问题，于是便试着把 base-package 改成 “cn.lncsa.controller” 1&lt;context:component-scan base-package=&quot;cn.lncsa.controller&quot;/&gt; 问题解决。。。。 然后在想为什么呢？ 是这样的，base-package 指的是扫描器从那个包开始扫描， “cn.lncsa.controller.*“ 指的是扫描 controller 包下面的任何包，也就是说 * 通配符是改变了扫描基于的包了，不再是 controller 而是 controller 里面的各个子包。而我的 Controller 类是放在这个包下的，扫的是根包里的子包的类而不是根包里的类，当然就搜索不到 Controller 了。 那么这个错误的配置除了上面这么改还能怎么改呢？ 123&lt;context:component-scan base-package=&quot;cn.lncsa.*&quot;&gt; &lt;context:include-filter type=&quot;annotation&quot; expression=&quot;org.springframework.stereotype.Controller&quot;/&gt;&lt;/context:component-scan&gt; 这样改就好了。虽然方法不同但是原理都是更改扫描的根包。第一种方法是直接明确地指出扫描的地方。第二种方法是扫描 cn.lncsa 里面的子包，但是增加 include-filter， 使其只扫描 Controller 类。 当然我的习惯是使用第一种。 还有需要注意的是，因为 SpringMVC 一般是和 Spring 共用， 所以会有重复扫描类的问题。我们的 Controller 是交给 SpringMVC 所属的容器管理的，所以应该让主要的 Spring IOC 容器忽略掉这些 Controller。不然会造成重复扫描，生成重复的对象在两个 IOC 容器里。 所以除了配置 spring-mvc 的 applicationContext 以外，也要在主要的 applicationContxt 里配置扫描器。 123&lt;context:component-scan base-package=&quot;cn.lncsa&quot;&gt; &lt;context:exclude-filter type=&quot;annotation&quot; expression=&quot;org.springframework.stereotype.Controller&quot;/&gt;&lt;/context:component-scan&gt; 增加 exclude-filter 就能让主要的 IOC 容器忽略掉这些 Controller","categories":[{"name":"开发框架","slug":"开发框架","permalink":"https://cattenlinger.github.io/categories/%E5%BC%80%E5%8F%91%E6%A1%86%E6%9E%B6/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"https://cattenlinger.github.io/tags/Spring/"},{"name":"Spring IoC","slug":"Spring-IoC","permalink":"https://cattenlinger.github.io/tags/Spring-IoC/"}]},{"title":"使用 Docker 建立 MySQL 集群","slug":"使用-Docker-建立-MySQL-集群","date":"2018-06-08T22:33:58.000Z","updated":"2025-03-24T00:47:13.338Z","comments":true,"path":"2018/06/09/62b202f6dee0.html","link":"","permalink":"https://cattenlinger.github.io/2018/06/09/62b202f6dee0.html","excerpt":"","text":"官方说明是实验性质，生产环境应用还请自行斟酌 没事干，突然想到 MySQL 集群，上网搜了一下看看想搭一个玩一下。 不过人在公司，刚好昨晚 autossh 还没弄好。。所以就直接用了最偷懒的方式搭建了。这里用傻瓜化的步骤来记录一下我搭集群的步骤，这里贴出官方的做法结合理解吧。 首先说一下结构，mysql 集群主要由三个部分协作形成，分别是一个 manager 节点，多个子节点，以及一个用于访问的门面节点，manager 节点对应 ndb_mgmd ，子节点对应 ndbd，门面节点就是常规的 mysqld 。 我建议首先配置好集群的配置文件，配置文件主要有两个 123456cattenlinger@cattenlinger-Office:/opt/mysql_cluster_docker$ ls -altotal 16drwxr-xr-x 2 root root 4096 Apr 26 11:39 .drwxr-xr-x 3 root root 4096 Apr 26 10:51 ..-rw-r--r-- 1 root root 838 Apr 26 11:38 my.cnf-rw-r--r-- 1 root root 1146 Apr 26 11:38 mysql-cluster.cnf my.cnf 给子节点以及 mysql 门面用。主要内容是使用集群模式并设定 manager 节点 IP 1234567[mysqld]ndbclusterndb-connectstring=172.18.1.100user=mysql[mysql_cluster]ndb-connectstring=172.18.1.100 mysql-cluster.cnf 给 manager 节点和子节点用的，主要内容是配置节点数量，使用内存大小以及各个子节点的 IP 配置，包括 mysqld。 12345678910111213141516171819202122232425262728293031323334[ndbd default]NoOfReplicas=4DataMemory=128MIndexMemory=32M[ndb_mgmd]NodeId=1hostname=172.18.1.100datadir=/var/lib/mysql[ndbd]NodeId=2hostname=172.18.1.101datadir=/var/lib/mysql[ndbd]NodeId=3hostname=172.18.1.102datadir=/var/lib/mysql[ndbd]NodeId=4hostname=172.18.1.103datadir=/var/lib/mysql[ndbd]NodeId=5hostname=172.18.1.104datadir=/var/lib/mysql[mysqld]NodeId=6hostname=172.18.1.199 准备好这两个文件之后，接下来操作 docker，里面的文件路径请根据自己的实际情况作修改。 官方建议是创建一个私有子网络给集群内部使用，然后再开始创建节点，我偷懒我就写个 bash 算了 XD 123456789101112131415161718192021222324252627282930313233#!/bin/bash# 创建私有网络，上面提到的docker network create mysql-cluster --subnet=172.18.1.0/24;# 创建管理节点docker create \\ --net=mysql-cluster \\ --name=mysql-mngr-0 \\ --ip=172.18.1.100 \\ -v /opt/mysql_cluster_docker/mysql-cluster.cnf:/etc/mysql-cluster.cnf \\ mysql/mysql-cluster ndb_mgmd;# 创建 4 个子节点for i in 1 2 3 4; do docker create \\ --net=mysql-cluster \\ --name=mysql-node-$i \\ --ip=172.18.1.10$i \\ -v /opt/mysql_cluster_docker/mysql-cluster.cnf:/etc/mysql-cluster.cnf \\ -v /opt/mysql_cluster_docker/my.cnf:/etc/my.cnf \\ mysql/mysql-cluster ndbd;done;# 创建门面节点docker create \\ --net=mysql-cluster \\ --name=mysql-facade \\ --ip=172.18.1.199 \\ -p 3307:3306 \\ -v /opt/mysql_cluster_docker/my.cnf:/etc/my.cnf \\ -e MYSQL_RANDOM_ROOT_PASSWORD=true \\ mysql/mysql-cluster mysqld; 然后就可以开始启动了，启动是有顺序的，先启动管理节点，然后启动子节点，再启动门面节点。（继续是 bash。。。 123456789101112#!/bin/bash# 启动管理节点docker start mysql-mngr-0;# 启动各个子节点for i in 1 2 3 4; do docker start mysql-node-$i;done# 启动门面节点docker start mysql-facade; 大概等两分钟，你就会看到成功启动了，现在通过门面节点的 log 获取随机生成的 root 密码就好了。 1docker logs mysql-facade 2&gt;&amp;1 | grep PASSWORD 然后登陆 1docker exec -it mysql1 mysql -uroot -p 改密码、增加远程账户，然后就可以在外部链接到集群了。","categories":[{"name":"Linux 技术应用","slug":"Linux-技术应用","permalink":"https://cattenlinger.github.io/categories/Linux-%E6%8A%80%E6%9C%AF%E5%BA%94%E7%94%A8/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://cattenlinger.github.io/tags/Linux/"},{"name":"Docker","slug":"Docker","permalink":"https://cattenlinger.github.io/tags/Docker/"},{"name":"MySql","slug":"MySql","permalink":"https://cattenlinger.github.io/tags/MySql/"}]},{"title":"Jackson 注解的使用经验 #1","slug":"Jackson-注解的使用经验-1","date":"2018-06-08T22:16:04.000Z","updated":"2025-03-24T00:46:22.882Z","comments":true,"path":"2018/06/09/b722a7d07d3f.html","link":"","permalink":"https://cattenlinger.github.io/2018/06/09/b722a7d07d3f.html","excerpt":"","text":"唠叨几句​ 公司项目涉及到金额运算，我作为后端的设计以及编码，对所有进入系统的金额字段，全部使用放大了 100 倍并四舍五入后的整数作为金额的数据类型。我为了避免浮点数计算带来的问题，把所有浮点数拒绝于系统之外。但是，前端就不高兴了。 ​ 毕竟前端是搞前端的嘛。。对他们来说浮点数计算问题几乎都不可能碰上。。这时候作为一个后端人员就要展现自己的宽容大量和万能了（偷笑）。 ​ 因为后端系统的视图层清一色使用 JSON 作为返回格式，所以我们只需要对要返回给前端的数据动手脚就行了。 ​ 先明确一下目标：所有有存储金额数据的对象，在返回给前端的时候，金额数据要变成缩小 100 倍的浮点数。 开始假设我有一个类 Order.class ，上面以放大了 100 倍的方式存储金额 123456789101112131415161718public class Order &#123; private Integer id; private List&lt;Items&gt; items; private Integer value; //... //这里我只写涉及到的变量的 getter 和 setter public Integer getValue()&#123; return value; &#125; public void setValue(Integer value)&#123; this.value = value; &#125; //...&#125; Jackson 转换出来之后就会变成这样 1234567&#123; &quot;id&quot; : 1, &quot;items&quot; : [ ..... ], &quot;value&quot; : 18978 /* 189.78￥，因为我这里放大 100 倍存储*/&#125; 这下前端就不乐意了，过来找我说要变回去原来的数值，这里要使用到 @JsonProperty, @JsonIgnore, @JsonGetter, @JsonSetter 这几个注解 123456789101112131415161718192021222324252627282930public class Order &#123; private Integer id; private List&lt;Items&gt; items; private Integer value; //... //这里我只写涉及到的变量的 getter 和 setter @JsonIgnore public Integer getValue()&#123; return value; &#125; @JsonProperty public void setValue(Integer value)&#123; this.value = value; &#125; @JsonGetter(&quot;cost&quot;) public Double getValueDouble()&#123; return ((double) (value)) / 100; &#125; @JsonSetter(&quot;cost&quot;) public void setValueDouble()&#123; this.value = Math.toIntExact(Math.round(totalCost * 100)); &#125; //...&#125; 这时候，给前端的 JSON 就会变成这样 1234567&#123; &quot;id&quot; : 1, &quot;items&quot; : [ ..... ], &quot;cost&quot; : 189.78 /* 这里就是正常的数值了 */&#125; 解释至于为什么要这样做呢？ @JsonIgnore 的用途是告诉 Jackson 要忽略一个属性。这个注解打在 getter 上面，setter 将被同时忽略。那么对于前端来说，这个属性就是不可见的了。然而后端在执行计算的时候，则可以继续使用这个属性。 @JsonGetter 和 @JsonSetter 实际上是 @JsonProperty 两个别称，功能是用于改变属性的 getter 和 setter。传参留空的话，则说明它们作为一个与被标注的 getter 同名的属性显示在输出的 JSON 上面。传参填上，则用填上的值覆盖输出 JSON 上指定属性的 getter 和 setter。 至于我为什么需要在被忽略的 setter 上面打上 @JsonProperty ，是因为这样可以让已经使用了 value 字段作为金额数据存储的已经被持久化的 JSON 数据在下次返回给前端的时候也能输出正确的 cost 属性。我这里以订单里面的 items 字段作为例子。 123456789101112131415161718192021222324252627public class Item&#123; private String title; private Integer value; //... //只写用到的 getter 和 setter @JsonIgnore public Integer getValue()&#123; return value; &#125; @JsonProperty public void setValue(Integer value)&#123; this.value = value; &#125; @JsonGetter(&quot;cost&quot;) public Double getValueDouble()&#123; return ((double)value) / 100; &#125; @JsonSetter(&quot;cost&quot;) public void setValueDouble(Double value)&#123; this.value = Math.toIntExact(Math.round(value * 100)); &#125;&#125; 因为之前的数据库里，Order 的 items 字段已经是以这个形式存储到数据库里了： 1234[ &#123;&quot;title&quot; : &quot;item1&quot;, &quot;value&quot; : &quot;10000&quot;&#125;, //金额都放大了 100 倍 &#123;&quot;title&quot; : &quot;item2&quot;, &quot;value&quot; : &quot;29850&quot;&#125;] 保留 value 字段，新建 cost 字段的话，后端的所有涉及到金额的算法就不需要改变也能正常工作。getter 打上 @JsonPropert 的话，Jackson 在反序列化的时候检测到 value 字段就会自己填上 value ，这样旧的数据也能够兼容上了。而新提交的数据将会变成这样： 1234[ &#123;&quot;title&quot; : &quot;item1&quot;, &quot;cost&quot; : &quot;100.00&quot;&#125;, //金额都是正常的 &#123;&quot;title&quot; : &quot;item2&quot;, &quot;cost&quot; : &quot;298.50&quot;&#125;] 反序列化的时候， Jackson 会自动使用 setValueDouble 方法填入数据，那么后端通过 getValue 拿出来的数据也还是放大了 100 倍的，不受影响。 再唠叨几句实际上我还用过 Jackson 的反序列化和序列化类来做这个，但发现这就是兜了弯路了。毕竟为了这点小事创建两个类有点小题大做了吧。。 之前想着直接忽略掉原来的 value 参数，然后在新的 getter 上打上 @JsonProerty(&quot;value&quot;) ，结果 Jackson 认为 setValue 和 setValueDouble 是两个相同的 setter 于是拒绝反序列化了，只好更改了变量名称。","categories":[{"name":"编程技术","slug":"编程技术","permalink":"https://cattenlinger.github.io/categories/%E7%BC%96%E7%A8%8B%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://cattenlinger.github.io/tags/Java/"},{"name":"Jackson","slug":"Jackson","permalink":"https://cattenlinger.github.io/tags/Jackson/"}]},{"title":"Laravel : 使用动作类整理你的代码（翻译）","slug":"Laravel-使用动作类整理你的代码（翻译）","date":"2018-06-05T09:25:23.000Z","updated":"2025-03-24T00:48:50.098Z","comments":true,"path":"2018/06/05/0d016cb96782.html","link":"","permalink":"https://cattenlinger.github.io/2018/06/05/0d016cb96782.html","excerpt":"","text":"友偶阅网文一篇，头中尾英，阅不能，遂中译之。原文链接 ：Keeping your Laravel applications DRY with single action classes “这段代码该放在哪里？”恐怕是在谈论应用结构时最经常提起的问题。“我应该放在 Controller 里吗？还是 Model ？还是哪里？”，虽然 Laravel 是个十分灵活的框架，但要解答这个问题也不总能简单明了。 当你知道你的应用程序只有一个接入点的时候，把逻辑写在 Controller 是完全没问题的。但如今应用一般都会有好几个接入点共用同一个功能。 例如，很多应用都会有一个用户注册的表单，提交到 Controller ，然后根据是否成功注册来返回有用的信息。在移动端应用的场景下，一般都会有个使用 JSON 格式返回的 API 专门用于用户注册。而且利用 Laravel 的 artisan 命令来创建用户也很常见，尤其是在项目前期的开发阶段。 123456789101112131415class UserController &#123; public function create(CreateUserRequest $request)&#123; $user = User::create($request-&gt;all()); return view(&#x27;user.create&#x27;,[&#x27;user&#x27; = &gt; $user]); &#125;&#125;class UserApiController &#123; public function create(CreateUserRequest $request)&#123; $user = User::create($request-&gt;all()); return response()-&gt;json($user); &#125;&#125; 些重复代码的确看上去没什么毛病，但如果就这样让业务逻辑继续扩充下去，例如：你希望给新注册用户发一封提醒邮件，那么你需要在两个 Controller 里同时加上这个逻辑。所以为了代码能够整洁优雅起来，我们需要把它放到其他地方去。 别把服务类神化了一开始，可以先临时创建一个类，把所有针对某个业务逻辑的代码整理起来，例如： 123456789101112131415161718192021class UserService&#123; protected $blogService; public function __construct(BlogService $blogService)&#123; $this-&gt;blogService = $blogService; &#125; public function create(array $data) : User &#123; $user = new User; $user-&gt;email = $data[&#x27;email&#x27;]; $user-&gt;password = $data[&#x27;password&#x27;]; $user-&gt;save(); $blog = $this-&gt;blogService-&gt;create(); $user-&gt;blogs()-attach($blog); return $user; &#125; ...&#125; 这样看上去就好多了；我们可以直接从 Controller 里调用 User 的 create()&#x2F; delete() ，通过任意途径返回结果。然而这方式有个问题：我们处理业务逻辑的时候很少使用一种模式。 例如我们有这个业务逻辑：当用户创建账号的时候，需要创建一篇新的博客。如果我们继续使用刚才的模式，我们需要创建 BlogService 然后使其作为依赖注入到 UserService 中： 1234567891011121314151617class UserSerivce&#123; public function create(array $data) : User &#123; $user = new User; $user-&gt;email = $data[&#x27;email&#x27;]; $user-&gt;password = $data[&#x27;password&#x27;]; $user-&gt;save(); return $user; &#125; public function delete($userId) : bool &#123; $user = User::findOrFail($userId); $user-&gt;delete(); return true; &#125;&#125; 很显然，当我们的应用变得越来越大，会有越来越多的服务类，有些还依赖了 5 个甚至 6 个其他的服务类，代码像被猫玩过的毛线球剪不断理还乱 —— 我们无论如何都要避免这种结局。 引入动作类如果我们不使用里面塞了几个方法的单一服务类，而是把逻辑切分到好几个类里面呢？我在最近的好几个工程里都使用了这种模式，结果十分不错。 首先，我们暂时先把“服务”这个抽象而且模糊的术语丢掉，然后引入“动作”类，并且赋予以下定义： 一个动作类，它的名字应该要能够让人一眼看出它是干什么的，例如：CreateOrder, ConfirmCheckout, DeleteProduct, AddProductToCart,….. 动作类应该只拥有一个公开接口（API）。理想情况下应该用统一的名字，例如 handle(), execute() 这样，方便我们需要在动作上实现一些模式，例如适配器。 动作类不应该关心 Request 和 Response。动作类不处理任何 Request，也不产生任何 Response，因为这是 Controller 的责任。 动作类可以依赖其他的动作。 当处理业务逻辑的时候，遇到不能返回期望内容的情况下，必须抛出异常，让调用者（或者 Laravel 的 ExceptionHandler）去负责渲染或者返回错误信息。 创建 CreateUser 动作现在，让我们用 CreateUser 动作类来重构刚才的例子。 12345678910111213141516171819202122232425class CreateUser &#123; protected $createBlog; public function __constructure(CreateBlog $createBlog)&#123; $this-&gt;createBlog = $createBlog; &#125; public function execute(array $data) : User &#123; $email = $data[&#x27;email&#x27;]; if(User::whereEmail($email)-&gt;first()) &#123; throw new EmailNotUniqueException(&quot;$email shoould be unique.&quot;); &#125; $user = new User; $user-&gt;email = $data[&#x27;email&#x27;]; $user-&gt;password = $data[&#x27;password&#x27;]; $user-&gt;save(); $blog = $this-&gt;createBlog-&gt;execute(); $user-&gt;blogs()-&gt;attach($blog); return $user; &#125;&#125; 你可能觉得奇怪，为什么代码要在 Email 存在的情况下抛出异常，这个不应该是在请求的时候就应该验证一次吗？当然应该让验证器去做这件事，不过，强制动作类遵循业务逻辑是一个好主意。这样做不但能够让业务逻辑更明确（不用过多考虑异常情况），也更容易调试。 下面是我们使用动作类重构后的控制器： 123456789101112131415class UserController&#123; public function create(CreateUserRequest $request, CreateUser $action)&#123; $user = $action-&gt;execute($request-&gt;all()); return view(&#x27;user.created&#x27;,[&#x27;user&#x27; =&gt; $user]); &#125;&#125;class UserApiController&#123; public function create(CreateUserRequest $request, CreateUser $action)&#123; $user = $action-&gt;execute($request-&gt;all()); return response()-&gt;json($user); &#125;&#125; 现在我们再也不用在注册流程更改的时候同时修改两边的代码，干净整洁。 内嵌动作当我们需要往应用里倒入 1000 个用户的时候，我们可以写一个依赖 CreateUser 的动作类： 1234567891011121314151617class ImportUsers&#123; protected $createUser; public function __construct(CreateUser $createUser)&#123; $this-&gt;createUser = $createUser; &#125; public function execute(array $rows) : Collection&#123; return collect($row)-&gt;map(function(array $row)&#123; try&#123; return $this-&gt;createUser-&gt;execute($row); &#125; catch(EmailNotUniqueException $e)&#123; // Deal with duplicate users &#125; &#125;); &#125;&#125; 干净整洁，简单易懂。在这里我们在 Collection::map() 里重用了 CreateUser ，返回一个集合，装着新鲜出炉的用户们。我们可以稍作优化：当有重复邮件的时候，我们可以通过返回 Null 对象，或者往 Logger 里丢 INFO ，随你喜欢。 装饰一下 Actions现在，假设我们要往日志里记录每一个用户的注册。我们可以直接把代码放到动作自身上，但我们也可以使用装饰器模式。 1234567class LogCreateUser extends CreateUser&#123; public function execute(array $data) : User &#123; Log::info(&quot;A new user has registered : &quot;. $data[&#x27;email&#x27;]); return parent::execute($data); &#125;&#125; 然后，使用 Laravel 的 IoC 容器，我们可以把 LogCreateUser 类绑在 Createuser 类上，这样当我们就总能在需要后者的时候把原型注入进去： 123public function register()&#123; $this-&gt;app-&gt;bind(CreateUser::class, LogCreateUser::class);&#125; 这样做甚至更容易地通过环境变量或者配置控制日志的开启和关闭： 12345public function register()&#123; if(config(&quot;user.log_registeration&quot;)) &#123; $this-&gt;app-&gt;bind(CreateUser::class, LogCreateUser::class); &#125;&#125; 总结使用这种模式大概会在开始先产生一大堆的类。当然，为了减少一下文章篇幅读起来比较方便，这里只举了这个简单的用户注册例子。当复杂度增加的时候，这个模式的价值就开始体现出来了 — — 因为你清楚这些边界清楚分工明确的代码在哪。 使用动作类的好处： 使用小物件管理领域逻辑可避免重复代码以及增加可重用性，Keep things SOLID。 易于针对不同的场景做独立测试。 清晰易懂、有意义的命名让理解项目变得更加容易 跨项目一致性：避免代码七零八落地分布在 Controller、Models 等等…… 而且，这些实践都是基于我最近这些年使用 Laravel 的经验以及我写过的项目总结出来的。它们对我来说非常管用，以至于我甚至在中小型项目里使用。 我非常希望能够与你一同交流分享，如果你有不同的实践方式那就最好不过了！","categories":[{"name":"翻译","slug":"翻译","permalink":"https://cattenlinger.github.io/categories/%E7%BF%BB%E8%AF%91/"},{"name":"技术文章","slug":"翻译/技术文章","permalink":"https://cattenlinger.github.io/categories/%E7%BF%BB%E8%AF%91/%E6%8A%80%E6%9C%AF%E6%96%87%E7%AB%A0/"}],"tags":[{"name":"PHP","slug":"PHP","permalink":"https://cattenlinger.github.io/tags/PHP/"},{"name":"Laravel","slug":"Laravel","permalink":"https://cattenlinger.github.io/tags/Laravel/"}]},{"title":"hostapd + dhcpd + nftables 在 CentOS 7 上开 WLAN 热点","slug":"hostapd-dhcpd-nftables-在-CentOS-7-上开-WLAN-热点","date":"2017-03-02T22:12:04.000Z","updated":"2025-03-24T00:48:56.012Z","comments":true,"path":"2017/03/03/546c08002aaa.html","link":"","permalink":"https://cattenlinger.github.io/2017/03/03/546c08002aaa.html","excerpt":"","text":"因为 NetworkManager 的开热点功能太废柴，所以只好另辟蹊径。 首先介绍一下这三款软件 hostapd : 至今为止用得最广泛的无线热点程序，稳定而强大，几乎你能想到的无线路由器都在使用它。 dhcpd : 强大的 DHCP 服务器（动态主机服务），适合用于管理多个大型网络的主机地址自动分配。 nftables : 新兴的一个网络过滤器。因为业界稳定使用 15 年之久的 iptables 的利于新手上手，而且 CentOS 7 后， iptables 不再是一个独立的系统服务，而是包了一层叫 firewalld 的壳，它会托管 iptables 并往里面塞很多杂乱的默认规则，导致比较难下手。所以这里使用 nftables 代替传统路由器使用的 nftables。 开热点需要有能够支持 AP 模式的无线网卡，如果你不确定的话可以这样查看 iw list 如果里面 Supported interface modes: 有 “AP” 那么意味着你的网卡支持。 首先需要安装这三个软件。在安装之前，请确保你的 CentOS 已经使用了 epel 源： yum install epel-release 然后开始安装它们 yum install hostapd dhcpd nftables dhcpd 在 CentOS 里一般自带。 安装完成之后，就是配置了。这三个软件都是作为服务启动，所以可以直接通过 systemctl 管理它们的自启动以及开关。 systemctl start|stop|enable|disable hostapd|dhcpd|nftables 接下来的步骤需要多次提权访问，为了方便请直接 sudo su 后进行操作。 首先我们需要配置 hostapd ，它的默认配置文件在 /etc/hostapd/hostapd.conf 。这里只讲最基本的配置，其他更多的详细高级配置请参考本文最后的连接。 #hostapd 提供一个控制终端 hostapd_cli，这里配置终端接入的细节 ctrl_interface=/var/run/hostapd ctrl_interface_group=whell #一些比较普通的配置。。。。 macaddr_ac1=0 #这里配置使用哪一种认证方式，0 就是开放， 1 使用 WPA 系列，2 为任意，建议选 1 auth_algs=1 ignore_boardcast_ssid=0 #下面配置 WPA 和 WPA2 的选项 wpa=3 wpa_key_mgmt=WPA-PSK wpa_pairwise=TKIP rsn_pairwise=CCMP #这里配置你的 WI-FI 密码 wpa_passphrase=SomePassword #配置驱动，这里一般不需要更改 driver=nl80211 #配置 WI-FI 硬件，这里改成你 WI-FI 硬件的设备名称，可以用 nmcli device show 或者 ifconfig 查找 interface=wlp2s0 #这里配置频率模式 hw_mode=g #频道 channel=7 #SSID，WI-FI 名称 ssid=SSID_NAME #是否用 UIF-8 编码 WI-FI 名称，启用的话就能使用各种字符来命名 WI-FI 了，但在 Windows 上面普遍会出现 WI-FI 名称乱码问题 utf8-ssid=1 保存之后别急着启动，因为默认情况下网卡受 NetworkManager 托管，所以 hostapd 无法管理无线网卡。执行下面命令以让 NetworkManager 不再托管无线网卡。 nmcli device set wlp2s0 managed no 然后才启动 hostapd 服务，没有错误就证明配置好了。 接下来先给启动了的无线网卡配置 IP 地址 ip addr add 192.168.2.1/24 dev wlp2s0 这个地址相当于平时配路由器的路由器地址，可以根据你的需要改成其他的，不过注意下面的所有配置都得跟着改动。 *后面的 /24 是 255.255.255.0 的缩写，如果想改动请自行查询子网掩码的格式 dhcpd 的配置文件默认在 /etc/dhcp/dhcpd.conf，这个文件夹需要 root 权限才能进入，建议执行 sudo su 。 #让 DDNS 自动刷新，适合用在这种经常变动的网络中 ddns-update-style interim; #监听 192.168.2.0 这个子网 subnet 192.168.2.0 netmask 255.255.255.0 &#123; #设置自动派 IP 的范围 range 192.168.2.10 192.168.2.250; #默认的 DNS 服务器 option domain-name-servers 223.6.6.6,223.5.5.5; #告诉客户端路由器地址 option routers 192.168.2.1; #告诉客户端子网掩码 option subnet-mask 255.255.255.0; #告诉客户端广播地址 option broadcast-address 192.168.2.255; #IP 默认租期和最大租期 default-lease-time 86400; max-lease-time 172800; &#125; 保存之后启动 dhcpd 服务，启动没有问题就可以了。 接下来就是 nftables 的配置了。nftables 不需要什么配置文件，只要打命令就行了。 nft add table nat nft add chain nat post &#123; type nat hook postrouting priority 0 \\; &#125; nft add chain nat pre &#123; type nat hook prerouting priority 0 \\; &#125; #使得子网内的流量都通过 enp3s0 出去，这个是指出口的设备，也可以通过上面的命令查出来 nft add rule nat post ip saddr 192.168.2.0/24 oif enp3s0 snat 192.168.2.1 到此你的电脑就能变成无线热点了。 ##参考 Configuring a DHCP Server About hostapd 将DEBIAN配置为软路由 Linux DHCP配置的完美攻略 Software Access Poiont Wireless network configuration nftables - Arch Wiki","categories":[{"name":"Linux 技术应用","slug":"Linux-技术应用","permalink":"https://cattenlinger.github.io/categories/Linux-%E6%8A%80%E6%9C%AF%E5%BA%94%E7%94%A8/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://cattenlinger.github.io/tags/Linux/"}]},{"title":"令牌认证是如何工作的（翻译）","slug":"令牌认证是如何工作的（翻译）","date":"2017-02-21T22:32:16.000Z","updated":"2025-03-24T00:49:10.688Z","comments":true,"path":"2017/02/22/7b0954d33b47.html","link":"","permalink":"https://cattenlinger.github.io/2017/02/22/7b0954d33b47.html","excerpt":"","text":"原文 ： How token-based authentication works 令牌认证机制的工作原理客户端发送一个“硬凭证”（例如用户名和密码）到服务器，服务器返回一段数据作为令牌，之后客户端与服务端之间通讯的时候则会以令牌代替硬凭证。这就是基于令牌的认证机制。 简单来说，基于令牌的认证机制流程如下： 客户端发送凭证（例如用户名和密码）到服务器。 服务器验证凭证是否有效，并生成一个令牌。 服务器把令牌连同用户信息和令牌有效期存储起来。 服务器发送生成好的令牌到客户端。 在接下来的每次请求中，客户端都会发送令牌到服务器 服务器会从请求中取出令牌，并根据令牌作鉴权操作 如果令牌有效，服务器接受请求。 如果令牌无效，服务器拒绝请求。 服务器可能会提供一个接口去刷新过期的令牌 你可以利用 JAX-RS 2.0 干些什么(Jersey, RESTEasy 和 Apache CXF)下面的示例只使用了 JAX-RS 2.0 的API，没有用到其他的框架。所以能够在 Jersey、RESTEasy 和 Apache CXF 等 JAX-RS 2.0 实现中正常工作。 需要特别提醒的是，如果你要用基于令牌的认证机制，你将不依赖任何由 Servlet 容器提供的标准 Java EE Web 应用安全机制。 ###通过用户名和密码认证用户并颁发令牌 创建一个用于验证凭证（用户名和密码）并生成用户令牌的方法： @Path(&quot;/authentication&quot;) public class AuthenticationEndpoint &#123; @POST @Produces(&quot;application/json&quot;) @Consumes(&quot;application/x-www-form-urlencoded&quot;) public Response authenticateUser(@FormParam(&quot;username&quot;) String username, @FormParam(&quot;password&quot;) String password) &#123; try &#123; // Authenticate the user using the credentials provided authenticate(username, password); // Issue a token for the user String token = issueToken(username); // Return the token on the response return Response.ok(token).build(); &#125; catch (Exception e) &#123; return Response.status(Response.Status.UNAUTHORIZED).build(); &#125; &#125; private void authenticate(String username, String password) throws Exception &#123; // Authenticate against a database, LDAP, file or whatever // Throw an Exception if the credentials are invalid &#125; private String issueToken(String username) &#123; // Issue a token (can be a random String persisted to a database or a JWT token) // The issued token must be associated to a user // Return the issued token &#125; &#125; 如果在验证凭证的时候有任何异常抛出，会返回 401 UNAUTHORIZED 状态码。 如果成功验证凭证，将返回 200 OK 状态码并返回处理好的令牌给客户端。客户端必须在每次请求的时候发送令牌。 你希望客户端用如下格式发送凭证的话： username=admin&amp;password=123456 你可以用一个类来包装一下用户名和密码，毕竟直接用表单可能比较麻烦： public class Credentials implements Serializable &#123; private String username; private String password; // Getters and setters omitted &#125; 或者使用 JSON ： @POST @Produces(&quot;application/json&quot;) @Consumes(&quot;application/json&quot;) public Response authenticateUser(Credentials credentials) &#123; String username = credentials.getUsername(); String password = credentials.getPassword(); // Authenticate the user, issue a token and return a response &#125; 然后客户端就能用这种形式发送凭证了： &#123; &quot;username&quot;: &quot;admin&quot;, &quot;password&quot;: &quot;123456&quot; &#125; 从请求中取出令牌并验证客户端需要在发送的 HTTP 请求头中的 Authorization 处写入令牌。 Authorization: Bearer &lt;token-goes-here&gt; 需要注意的是，标准 HTTP 头里的这个名字是不对的，因为它存储的是认证信息（authentication）而不是授权（authorization）。 JAX-RS 提供一个叫 @NameBinding 的元注解来给拦截器和过滤器创建命名绑定注解。 @NameBinding @Retention(RUNTIME) @Target(&#123;TYPE, METHOD&#125;) public @interface Secured &#123; &#125; @Secured 将会用来标记在实现了 ContainerRequestFilter 的类（过滤器）上以处理请求。 ContainerRequestContext 可以帮你把令牌从 HTTP 请求中拿出来。 @Secured @Provider @Priority(Priorities.AUTHENTICATION) public class AuthenticationFilter implements ContainerRequestFilter &#123; @Override public void filter(ContainerRequestContext requestContext) throws IOException &#123; // Get the HTTP Authorization header from the request String authorizationHeader = requestContext.getHeaderString(HttpHeaders.AUTHORIZATION); // Check if the HTTP Authorization header is present and formatted correctly if (authorizationHeader == null || !authorizationHeader.startsWith(&quot;Bearer &quot;)) &#123; throw new NotAuthorizedException(&quot;Authorization header must be provided&quot;); &#125; // Extract the token from the HTTP Authorization header String token = authorizationHeader.substring(&quot;Bearer&quot;.length()).trim(); try &#123; // Validate the token validateToken(token); &#125; catch (Exception e) &#123; requestContext.abortWith( Response.status(Response.Status.UNAUTHORIZED).build()); &#125; &#125; private void validateToken(String token) throws Exception &#123; // Check if it was issued by the server and if it&#39;s not expired // Throw an Exception if the token is invalid &#125; &#125; 如果在验证令牌的时候有任何异常抛出，会返回 401 UNAUTHORIZED 状态码。 如果验证成功，则会调用被请求的方法。 给 RESTful 接口增加安全措施把之前写好的 @Secure 注解打在你的方法或者类上，就能把过滤器绑定上去了。被打上注解的类或者方法都会触发过滤器，也就是说这些接口只有在通过了鉴权之后才能被执行。 如果有些方法或者类不需要鉴权，不打注解就行了。 @Path(&quot;/&quot;) public class MyEndpoint &#123; @GET @Path(&quot;&#123;id&#125;&quot;) @Produces(&quot;application/json&quot;) public Response myUnsecuredMethod(@PathParam(&quot;id&quot;) Long id) &#123; // This method is not annotated with @Secured // The authentication filter won&#39;t be executed before invoking this method ... &#125; @DELETE @Secured @Path(&quot;&#123;id&#125;&quot;) @Produces(&quot;application/json&quot;) public Response mySecuredMethod(@PathParam(&quot;id&quot;) Long id) &#123; // This method is annotated with @Secured // The authentication filter will be executed before invoking this method // The HTTP request must be performed with a valid token ... &#125; &#125; 在上面的例子里，过滤器只会在 mySecuredMethod(Long) 被调用的时候触发（因为打了注解嘛）。 验证当前用户你很有可能会需要知道是哪个用户在请求你的 RESTful 接口，接下来的方法会比较有用： 重载 SecurityContext通过使用 ContainerRequestFilter.filter(ContainerRequestContext) 这个方法，你可以给当前请求设置新的安全上下文（Secure Context）。 重载 SecurityContext.getUserPrincipal() ，返回一个 Principal 实例。 Principal 的名字（name）就是令牌所对应的用户名（usrename）。当你验证令牌的时候会需要它。 requestContext.setSecurityContext(new SecurityContext() &#123; @Override public Principal getUserPrincipal() &#123; return new Principal() &#123; @Override public String getName() &#123; return username; &#125; &#125;; &#125; @Override public boolean isUserInRole(String role) &#123; return true; &#125; @Override public boolean isSecure() &#123; return false; &#125; @Override public String getAuthenticationScheme() &#123; return null; &#125; &#125;); 注入 SecurityContext 的代理到 REST 接口类里。 @Context SecurityContext securityContext; 在方法里做也是可以的。 @GET @Secured @Path(&quot;&#123;id&#125;&quot;) @Produces(&quot;application/json&quot;) public Response myMethod(@PathParam(&quot;id&quot;) Long id, @Context SecurityContext securityContext) &#123; ... &#125; 获取 Principal Principal principal = securityContext.getUserPrincipal(); String username = principal.getName(); 使用 CDI （Context and Dependency Injection）如果因为某些原因你不想重载 SecurityContext 的话，你可以使用 CDI ，它能提供很多诸如事件和提供者（producers）。 创建一个 CDI 限定符用来处理认证事件以及把已认证的用户注入到 bean 里。 @Qualifier @Retention(RUNTIME) @Target(&#123; METHOD, FIELD, PARAMETER &#125;) public @interface AuthenticatedUser &#123; &#125; 在 AuthenticationFilter 里注入一个 Event @Inject @AuthenticatedUser Event&lt;String&gt; userAuthenticatedEvent; 当认证用户的时候，以用户名作为参数去触发事件（注意，令牌必须已经关联到用户，并且能通过令牌查出用户名） userAuthenticatedEvent.fire(username); 一般来说在应用里会有一个 User 类去代表用户。下面的代码处理认证事件，通过用户名去查找一个用户且赋给 authenticatedUser @RequestScoped public class AuthenticatedUserProducer &#123; @Produces @RequestScoped @AuthenticatedUser private User authenticatedUser; public void handleAuthenticationEvent(@Observes @AuthenticatedUser String username) &#123; this.authenticatedUser = findUser(username); &#125; private User findUser(String username) &#123; // Hit the the database or a service to find a user by its username and return it // Return the User instance &#125; &#125; authenticatedUser 保存了一个 User 的实例，便于注入到 bean 里面（例如 JAX-RS 服务、CDI beans、servlet 以及 EJBs） @Inject @AuthenticatedUser User authenticatedUser; 要注意 CDI @Produces 注解和 JAX-RS 的 @Produces 注解是不同的 CDI : javax.enterprise.inject.Produces JAX-RS : java.ws.rs.Produces 支持基于角色的权限认证除了认证，你还可以让你的 RESTful API 支持基于角色的权限认证（RBAC）。 创建一个枚举，并根据你的需求定义一些角色： public enum Role &#123; ROLE_1, ROLE_2, ROLE_3 &#125; 针对 RBAC 改变一下 @Secured 注解： @NameBinding @Retention(RUNTIME) @Target(&#123;TYPE, METHOD&#125;) public @interface Secured &#123; Role[] value() default &#123;&#125;; &#125; 给方法打上注解，这样就能实现 RBAC 了。 注意 @Secured 注解可以在类以及方法上使用。接下来的例子演示一下方法上的注解覆盖掉类上的注解的情况： @Path(&quot;/example&quot;) @Secured(&#123;Role.ROLE_1&#125;) public class MyEndpoint &#123; @GET @Path(&quot;&#123;id&#125;&quot;) @Produces(&quot;application/json&quot;) public Response myMethod(@PathParam(&quot;id&quot;) Long id) &#123; // This method is not annotated with @Secured // But it&#39;s declared within a class annotated with @Secured(&#123;Role.ROLE_1&#125;) // So it only can be executed by the users who have the ROLE_1 role ... &#125; @DELETE @Path(&quot;&#123;id&#125;&quot;) @Produces(&quot;application/json&quot;) @Secured(&#123;Role.ROLE_1, Role.ROLE_2&#125;) public Response myOtherMethod(@PathParam(&quot;id&quot;) Long id) &#123; // This method is annotated with @Secured(&#123;Role.ROLE_1, Role.ROLE_2&#125;) // The method annotation overrides the class annotation // So it only can be executed by the users who have the ROLE_1 or ROLE_2 roles ... &#125; &#125; 使用 AUTHORIZATION 优先级创建一个过滤器，它会在先前定义的过滤器之后执行。 ResourceInfo 可以用来获取到匹配请求 URL 的 类 以及 方法 ，并且把注解提取出来。 @Secured @Provider @Priority(Priorities.AUTHORIZATION) public class AuthorizationFilter implements ContainerRequestFilter &#123; @Context private ResourceInfo resourceInfo; @Override public void filter(ContainerRequestContext requestContext) throws IOException &#123; // Get the resource class which matches with the requested URL // Extract the roles declared by it Class&lt;?&gt; resourceClass = resourceInfo.getResourceClass(); List&lt;Role&gt; classRoles = extractRoles(resourceClass); // Get the resource method which matches with the requested URL // Extract the roles declared by it Method resourceMethod = resourceInfo.getResourceMethod(); List&lt;Role&gt; methodRoles = extractRoles(resourceMethod); try &#123; // Check if the user is allowed to execute the method // The method annotations override the class annotations if (methodRoles.isEmpty()) &#123; checkPermissions(classRoles); &#125; else &#123; checkPermissions(methodRoles); &#125; &#125; catch (Exception e) &#123; requestContext.abortWith( Response.status(Response.Status.FORBIDDEN).build()); &#125; &#125; // Extract the roles from the annotated element private List&lt;Role&gt; extractRoles(AnnotatedElement annotatedElement) &#123; if (annotatedElement == null) &#123; return new ArrayList&lt;Role&gt;(); &#125; else &#123; Secured secured = annotatedElement.getAnnotation(Secured.class); if (secured == null) &#123; return new ArrayList&lt;Role&gt;(); &#125; else &#123; Role[] allowedRoles = secured.value(); return Arrays.asList(allowedRoles); &#125; &#125; &#125; private void checkPermissions(List&lt;Role&gt; allowedRoles) throws Exception &#123; // Check if the user contains one of the allowed roles // Throw an Exception if the user has not permission to execute the method &#125; &#125; 如果用户没有权限去执行这个方法，请求会被跳过，并返回 403 FORBIDDEN。 重新看看上面的部分，即可明白如何获知是哪个用户在发起请求。你可以从 SecurityContext 处获取发起请求的用户（指已经被设置在 ContainerRequestContext 的用户），或者通过 CDI 注入用户信息，这取决于你的情况。 如果没有传递角色给 @Secured 注解，则所有的令牌通过了检查的用户都能够调用这个方法，无论这个用户拥有什么角色。 如何生成令牌令牌可以是不透明的，它不会显示除值本身以外的任何细节（如随机字符串），也可以是自包含的（如JSON Web Token）。 随机字符串可以通过生成一个随机字符串，并把它连同有效期、关联的用户储存到数据库。下面这个使用 Java 生成随机字符串的例子就比较好： Random random = new SecureRandom(); String token = new BigInteger(130, random).toString(32); Json Web Token (JWT)JSON Web Token (JWT) 是 RFC 7519 定义的，用于在双方之间安全地传递信息的标准方法。它不仅只是自包含的令牌，而且它还是一个载体，允许你储存用户标识、有效期以及其他信息（除了密码）。 JWT 是一段用 Base64 编码的 JSON。 这个载体能够被客户端读取，且可以让服务器方便地通过签名校验令牌的有效性。 如果你不需要跟踪令牌，那就不需要存储 JWT 令牌。当然，储存 JWT 令牌可以让你控制令牌的失效与重新颁发。如果既想跟踪 JWT 令牌，又不想存储它们，你可以存储令牌标识（ jti 信息）和一些元数据（令牌颁发给哪个用户，有效期等等）。 有用于颁发以及校验 JWT 令牌的 Java 库（例如 这个 以及 这个 ）。如果需要找 JWT 相关的资源，可以访问 http://jwt.io。 你的应用可以提供用于重新颁发令牌的功能，建议在用户重置密码之后重新颁发令牌。 记得删除旧的令牌，不要让它们一直占用数据库空间。 一些建议 不管你用的是哪一类型的认证方式，切记要使用 HTTPS ，以防中间人攻击。 关于信息安全的更多内容，请查阅 这个 问题。 在 这篇文章 里，你可以找到一些与基于令牌的认证机制相关的内容。 Apache DeltaSpike 提供如 security module 之类的可用于保护 REST 应用的轻量级的 CDI 扩展。 对 OAuth 2.0 协议的 Java 实现感兴趣？你可以看看 Apache Oltu project 。","categories":[{"name":"翻译","slug":"翻译","permalink":"https://cattenlinger.github.io/categories/%E7%BF%BB%E8%AF%91/"},{"name":"技术文章","slug":"翻译/技术文章","permalink":"https://cattenlinger.github.io/categories/%E7%BF%BB%E8%AF%91/%E6%8A%80%E6%9C%AF%E6%96%87%E7%AB%A0/"}],"tags":[{"name":"认证","slug":"认证","permalink":"https://cattenlinger.github.io/tags/%E8%AE%A4%E8%AF%81/"},{"name":"鉴权","slug":"鉴权","permalink":"https://cattenlinger.github.io/tags/%E9%89%B4%E6%9D%83/"}]},{"title":"大概是最简单的 rtmp 推流服务器搭建方法","slug":"大概是最简单的-rtmp-推流服务器搭建方法","date":"2017-02-15T22:53:18.000Z","updated":"2025-03-24T00:49:20.748Z","comments":true,"path":"2017/02/16/fa567a76151d.html","link":"","permalink":"https://cattenlinger.github.io/2017/02/16/fa567a76151d.html","excerpt":"","text":"一开始想到要弄一个简单的 rtmp 服务器是为了给同学上课投射屏幕用。因为我用的是 Linux ，没法用国产的那些课室软件给他们投放屏幕，于是只好出此下策了。 我使用的系统是 CentOS 7 和 Ubuntu 16.04 ，所以就想到最简单的方式搭建：使用现成的 Docker 镜像。因为重新编译安装 nginx 对我来说不太现实，会直接影响到我的开发环境。 先安装好 docker CentOS 7 : 1sudo yum install docker Ubuntu 16.04 : 1sudo apt-get install docker.io 安装好之后执行 systemctl status docker 查看一下 docker 有没有被启动，没有的话执行 sudo systemctl start docker 启动。如果想日后自动启动 docker ，可以执行 sudo systemctl enable docker。 docker 需要使用 root 权限来操作，如果嫌麻烦可以把自己加入 docker 的用户组里，或者直接 su root 。 这里我直接使用 tiangolo/nginx-rtmp 来搭建 rtmp 服务器。 1sudo docker pull tiangolo/nginx-rtmp 等下载完成之后就可以启动这个镜像 1sudo docker run -d -p 1935:1935 --name nginx-rtmp tiangolo/nginx-rtmp 然后就可以直接使用 OBS 推流了。在推流的地址上填写 rtmp://你电脑的 ip 地址/live，密钥随便填写。然后可以开始串流了。 在可以看串流的客户端上（例如 vlc ）打开网络串流，地址就是 rtmp://你电脑的 ip 地址/live/你的密钥。 因为 CentOS 和 Ubuntu 都有防火墙，如果没法推流或者接收推流的话，有可能是因为防火墙的问题。这时最好让防火墙打开 1935 端口的访问，或者直接关掉防火墙（一般是叫做 firewall 的服务或者 ufirewall ）。","categories":[{"name":"Linux 技术应用","slug":"Linux-技术应用","permalink":"https://cattenlinger.github.io/categories/Linux-%E6%8A%80%E6%9C%AF%E5%BA%94%E7%94%A8/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://cattenlinger.github.io/tags/Linux/"},{"name":"Docker","slug":"Docker","permalink":"https://cattenlinger.github.io/tags/Docker/"},{"name":"Nginx","slug":"Nginx","permalink":"https://cattenlinger.github.io/tags/Nginx/"},{"name":"RTMP","slug":"RTMP","permalink":"https://cattenlinger.github.io/tags/RTMP/"},{"name":"Media Streaming","slug":"Media-Streaming","permalink":"https://cattenlinger.github.io/tags/Media-Streaming/"},{"name":"OBS","slug":"OBS","permalink":"https://cattenlinger.github.io/tags/OBS/"}]},{"title":"怎么安装 Remix OS 到本地","slug":"怎么安装-Remix-OS-到本地","date":"2017-01-07T23:00:55.000Z","updated":"2025-03-24T00:49:29.465Z","comments":true,"path":"2017/01/08/0f06ed6e6402.html","link":"","permalink":"https://cattenlinger.github.io/2017/01/08/0f06ed6e6402.html","excerpt":"","text":"首先你需要一个空的能启动的存储设备 格式化为 ext4 解压 Remix OS 的镜像 拷 system.sfs initrd.img ramdisk.img 和 kernel 到盘的根目录 创建一个 data 目录，权限改成 777 装 grub 引导：sudo grub-install –root-directory&#x3D;到你安装目录的绝对路径 &#x2F;dev&#x2F;你的安装设备 在安装目录的 boot&#x2F;grub 创建 grub.cfg 然后写入以下内容 12345678910set default=0set timeout=你自己喜欢等多少秒就写多少秒set gfxmode=1024x768terminal_output gfxterm menuentry &#x27;Remix OS&#x27; --class android-x86&#123; search --file --no-floppy --set=root /kernel linux /kernel root=/dev/ram0 androidboot.hardware=remix_cn_x86_64 androidboot.selinux=permissive quite SRC=/ DATA=/data initrd /initrd.img&#125;","categories":[{"name":"Linux 技术应用","slug":"Linux-技术应用","permalink":"https://cattenlinger.github.io/categories/Linux-%E6%8A%80%E6%9C%AF%E5%BA%94%E7%94%A8/"}],"tags":[{"name":"Remix OS","slug":"Remix-OS","permalink":"https://cattenlinger.github.io/tags/Remix-OS/"},{"name":"Android","slug":"Android","permalink":"https://cattenlinger.github.io/tags/Android/"}]},{"title":"如何关闭 Mac 的保护模式","slug":"如何关闭-Mac-的保护模式","date":"2016-12-14T22:56:16.000Z","updated":"2025-03-24T00:50:38.612Z","comments":true,"path":"2016/12/15/92d4ae37feac.html","link":"","permalink":"https://cattenlinger.github.io/2016/12/15/92d4ae37feac.html","excerpt":"","text":"有时候需要安装一些驱动，但是安装后重启发现驱动没了。这是因为 Mac 系统的保护机制。默认情况下这个保护机制是激活状态的，可以免于系统被恶意修改，即便是使用 root 权限操作也无法对系统关键部分进行写入，重启之后这些更改会自动还原。 关闭这个保护模式很简单，只需要关机重启至 Recovery （Command + R），打开终端，输入以下命令 csrutil disable 重启之后保护模式就关闭了。这样子只会临时关闭，等待修改过后重启了之后保护模式又会再次启动。","categories":[{"name":"macOS 使用经验","slug":"macOS-使用经验","permalink":"https://cattenlinger.github.io/categories/macOS-%E4%BD%BF%E7%94%A8%E7%BB%8F%E9%AA%8C/"}],"tags":[{"name":"Mac OS X","slug":"Mac-OS-X","permalink":"https://cattenlinger.github.io/tags/Mac-OS-X/"}]},{"title":"Windows 7 更改注册表使其支持 UTC 时间","slug":"Windows-7-更改注册表使其支持-UTC-时间","date":"2016-12-14T22:27:50.000Z","updated":"2025-03-24T00:50:47.052Z","comments":true,"path":"2016/12/15/762980ab92a0.html","link":"","permalink":"https://cattenlinger.github.io/2016/12/15/762980ab92a0.html","excerpt":"","text":"默认情况下 Windows 7 是不支持硬件 UTC 时间的，所以导致从 Linux 上切换过来之后时间就不对了。 解决方法是，通过修改注册表使其开启 UTC 时间支持。 打开 regedit.exe (打开开始菜单在搜索框里输入这个名字就会出现，或者到 C:\\Windows 下面找），找到 HKEY_LOCAL_MACHINE -&gt; SYSTEM -&gt; CurrentControlSet -&gt; Control -&gt; TimeZoneInformation ，新建一个 RealTimeIsUniversal 的键， 类型为 DOWRD64 ，重启即可。也可以直接复制下面的文本保存到文本文件，更改后缀名为 .reg 后双击。 Windows Registry Editor Version 5.00 [HKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Control\\TimeZoneInformation] “RealTimeIsUniversal”=dword:00000001","categories":[{"name":"Windows 使用经验","slug":"Windows-使用经验","permalink":"https://cattenlinger.github.io/categories/Windows-%E4%BD%BF%E7%94%A8%E7%BB%8F%E9%AA%8C/"}],"tags":[{"name":"Windows","slug":"Windows","permalink":"https://cattenlinger.github.io/tags/Windows/"}]},{"title":"利用 Bash 脚本编写自动抓取学校图书馆借阅信息的爬虫 Part 2","slug":"利用-Bash-脚本编写自动抓取学校图书馆借阅信息的爬虫-Part-2","date":"2016-11-22T22:45:12.000Z","updated":"2025-03-24T00:51:25.318Z","comments":true,"path":"2016/11/23/d7238b33f0b9.html","link":"","permalink":"https://cattenlinger.github.io/2016/11/23/d7238b33f0b9.html","excerpt":"","text":"接上一篇 《利用 Bash 脚本编写自动抓取学校图书馆借阅信息的爬虫 Part 1》 抓下来的数据是一大堆的 HTML 标签夹杂着无用的玩意，那么就需要把有用的过滤出来。在 Bash 环境下就是需要利用一些命令来过滤掉没用的字符。 我这里用到三个命令来过滤 sed # sed是非交互式的编辑器，它读取文件到自己的缓冲区然后再作修改。 # 默认情况下，所有的输出行都被打印到屏幕上。[1] awk # awk是一个强大的文本分析工具，它把文件逐行的读入，以空格为默认分隔 # 符将每行切片，切开的部分再进行各种分析处理。[2] tr # 可以将 tr 看作为 sed的（极其）简化的变体：它可以用一个字符来替换 # 另一个字符，或者可以完全除去一些字符。您也可以用它来除去重复字符。 # 这就是所有 tr所能够做的。 [3] sed 命令在我的脚本里用得最多，通过输入一组符合 sed 格式的命令来达到过滤文本内容。sed 使用 命令/匹配/选项 的格式来作为一条命令，这里只涉及到我用到的命令。 #在所有“&lt;td”前面换行 #准确点来说是把所有的“&lt;td”换成“\\n&lt;td”，以此达到换行的目的 cat file | sed &#39;s/&lt;td/\\n&lt;td/g&#39; #删掉第 1-107 行 cat file | sed &#39;1,107d&#39; cat file | sed &#39;480,$d&#39; awk 命令我只用来格式化输出一些数据。例如可以不替换直接用html里的一些符号分割字段。 [1] sed命令详解 [2] linux awk命令详解 [3] linux tr命令详解","categories":[{"name":"Linux 技术应用","slug":"Linux-技术应用","permalink":"https://cattenlinger.github.io/categories/Linux-%E6%8A%80%E6%9C%AF%E5%BA%94%E7%94%A8/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://cattenlinger.github.io/tags/Linux/"},{"name":"Bash","slug":"Bash","permalink":"https://cattenlinger.github.io/tags/Bash/"},{"name":"Script","slug":"Script","permalink":"https://cattenlinger.github.io/tags/Script/"}]},{"title":"iOS 商品扫描枪开发笔记","slug":"iOS-商品扫描枪开发笔记","date":"2016-11-22T22:13:58.000Z","updated":"2025-03-24T00:51:18.602Z","comments":true,"path":"2016/11/23/96f97d7714f7.html","link":"","permalink":"https://cattenlinger.github.io/2016/11/23/96f97d7714f7.html","excerpt":"","text":"iOS 课程期末作业项目，我选择做了个商品码扫描枪App。对我这个没有 iOS 开发经验的人来说这的确有点难度。熬了三天几乎从零开始（我一直都是做 JavaEE 开发，对编程语言已经有了不少的基本认识，对编程基础也已经掌握了）写出来了这个 App 。 我对 iOS 开发的基础经验来源于 Android 开发，毕竟基于 Java ，很多概念学习起来比较轻松。诸如视图、控制器等等。移动端 App 开发很注重 MVC 模式，我开发网站也全是基于这个模式。 ##需要涉及的东西 ###机械可阅读码条形码和二维码都属于同一种东西，叫 Machine Readable Codes，翻译过来就是机器可阅读码。基本原理就是把文字编码成机器容易识别的编码，然后打印出来，方便通过摄像头或者其他光学识别器来识别。其本身就是一个信息的容器，跟 BASE64 和其他编码技术只有载体上的区别。 ###设备输入输出 接下来解释一下 iOS 里关于视频捕获的类 AVCaptureSession AVCaptureDevice AVCaptureDeviceInput 输出 AVCaptureSession 是一个用于管理捕获输入输出会话的类。新建一个会话，就像跟系统说“我要准备抓点东西了”。至于要抓什么东西则是需要我们接下来说明的。抓点东西，那么这个行为肯定有两个要点：从哪里输入，以及输出到哪去。 从哪里输入，需要有一个来源， AVCaptureDevice 便是干这个用的。 AVCaptureDevices 是指代一个系统输入设备的类，这些设备可以是话筒、摄像头等等，通过其静态方法 devicesWithMediaType 能够利用设备的类型来获取一个设备列表。在我的 App 里有一个方法专门获取后置摄像头设备 //Get Back-end camera - (AVCaptureDevice *) backendCamera&#123; //通过一个类型来获取设备列表 NSArray *cameras = [AVCaptureDevice devicesWithMediaType:AVMediaTypeVideo]; //遍历这个数组获取符合条件的设备 for (AVCaptureDevice *camera in cameras) &#123; if([camera position] == AVCaptureDevicePositionBack)&#123; //如果匹配则返回 NSLog(@&quot;Camera found:%ld&quot;, (long)camera.position); return camera; &#125; &#125; return NULL; &#125; 有了目标设备就可以拿着这个设备创建一个输入来源了 //这里省略 ScanningHandler 的初始化方法 //获取后置摄像头 AVCaptureDevice *theCamera = [self backendCamera]; //申请一个输入来源 _cameraInput = [[AVCaptureDeviceInput alloc] initWithDevice:theCamera error:nil]; 输入有了，接下来就需要有个输出了。输出到哪也是由一些类来指定。在我这个 App 里，输出有两个 视频预览框 机械码识别器 视频预览的输出是由 AVCaptureVideoPreviewLayer 来管理。输出有两点：输入来源和输出目的地，在这个类里目的地是一个 View //创建一个输出层，从捕获会话里获取输入 _cameraPreviewLayer = [[AVCaptureVideoPreviewLayer alloc] initWithSession:_session]; UIView *view = _viewApplicated; CALayer *viewLayer = [view layer]; [viewLayer setMasksToBounds:YES]; CGRect bounds = [view bounds]; //设定预览层的大小为指定 View 的大小 [_cameraPreviewLayer setFrame:bounds]; //设定预览层的大小显示方式，这个值是让预览画面充满视图，显示的区域的中心是摄像头画面的中心 [_cameraPreviewLayer setVideoGravity:AVLayerVideoGravityResizeAspectFill]; //把这个层塞到目的视图里面。 [viewLayer insertSublayer:_cameraPreviewLayer below:[[viewLayer sublayers] objectAtIndex:0]]; 搞定了预览之后还有给机械识别码的输出 //创建一个输出，从会话获取输入 _captureMetadataOutput = [[AVCaptureMetadataOutput alloc] init]; //这个输出有一个回调，当识别到指定的机械码的时候会把数据返回并调用这个函数 //queue参数是指这个读取器要在哪个线程上执行，这里直接使用主线程。 [_captureMetadataOutput setMetadataObjectsDelegate:self queue:dispatch_get_main_queue()]; //设置捕获区域，如果不设置的话默认识别全部 //虽然上面已经限定了 Camera 的预览区域，但是返回的数据还是摄像头捕获到的所有图像。 //这个范围参数跟普通的 View 的范围参数不一样，它的值是一个占比。 [_captureMetadataOutput setRectOfInterest:CGRectMake(0.375, 0, 0.25, 1)]; //把这个输出放到会话里好让输出有地方出来 [_session addOutput:_captureMetadataOutput]; [self captureBarCode]; ##结构 现在来说一下这个 App 的结构，从可视化开始讲起就是 View 。这个 App 我设计只有一个 View ，里面包含了一个视频的预览窗口（用于让用户能够比较轻松地瞄准目标机器码）、一个列表视图（TableView）以及一个包含了切换器和“编辑列表”按钮的工具栏。 接下来是管理这个 View 的 Controller。里面包含了一些界面的逻辑代码。为了方便，我直接在这里实现了一个 TableView 的控制器，也就是主页面和列表视图共用一个视图控制器。 为了让 ViewController 更加简洁，我写了一个 ScanningHandler 来负责管理摄像头视频数据的获取和分析。对于主视图来说，它需要关心的只是让摄像头的预览数据能够显示在指定区域里，以及如何获得扫描得来的数据。因此，把关于扫描的设置以及管理扫描设置的相关方法整合到一个类里面会方便很多。 按照 MVC 的设计模式，我把数据获取部分按照 Java 的方式，做了一个 CommodityRepository（其实就是DAO） ，负责接收一个商品的编码并返回一个 Commodity（商品） 对象。 因为习惯问题，我这个项目也是做了国际化的，关于国际化如何实现我不累赘，在文章后面的链接里有。 ##遇到的一些问题 在获取到一个 MetadataOutput 之后，它的扫描范围是整个摄像头的范围，需要手动设置这个范围。如果是二维码的话，这个不影响效率，但是是条形码的话，这样做会大大降低扫描的速度。最好的做法是设置一个。但这个范围跟 CameraPreviewLayout 不一样，它的范围尺寸是一个比值，例如要扫描摄像头获取的图像的上半部分，则设置宽度为 1 ，高度为 0.5 。如何让其定位到 CameraPreviewLayout 还是一个难点。 CameraPreviewLayout 的 AVLayerVideoGravityResizeAspectFill 选项，会让摄像头画面居中，然后宽度拉伸到跟 View 一样，所以显示出来的位置是摄像头画面的中间部分。 关闭和打开捕获的时候我做了个小动画，这个动画我是创建了一个毛玻璃效果视图，然后通过动画调整器透明度。 - (IBAction)scannerControlSwitch:(UISwitch *)sender &#123; if ([sender isOn]) &#123; _visualEffectView.alpha = 1; [UIView animateWithDuration:0.2 delay:0 options:UIViewAnimationOptionCurveEaseOut animations:^&#123; _visualEffectView.alpha = 0; &#125; completion:^(BOOL finished) &#123; [_scanningHandler startCapturing]; [_visualEffectView setHidden:YES]; &#125;]; &#125;else&#123; _visualEffectView.alpha = 0; [_visualEffectView setHidden:NO]; [UIView animateWithDuration:0.2 delay:0 options:UIViewAnimationOptionCurveEaseOut animations:^&#123; _visualEffectView.alpha = 1; &#125; completion:^(BOOL finished) &#123; [_scanningHandler stopCapturing]; &#125;]; &#125; &#125; ##参考资料 iOS图片 缩放、剪裁、自适应剪裁、保存到相册 iOS相机获取图片自动旋转90度 iPhone上关于相机拍照的图片的imageOrientation的问题 关于iOS原生条形码扫描，你需要注意的两三事 iOS多语言本地化(国际化)设置 了解 AVFoundation（二）视频捕获 iOS使用AVCaptureSession自定义相机 UISegmentedControl用法详解 iOS中的「回调(callback)」 iOS8中用UIVisualEffectView实现高斯模糊视图(毛玻璃效果) UIToolBar使用技巧 ( 设置UIBarButtonItem 之间的间距，居中对齐 ) iOS开发之顶部状态栏statusBar颜色变化小结 iOS UIKit：animation Transition behavior using transitionFromView and transitionWithView iOS App图标和启动画面尺寸","categories":[{"name":"笔记","slug":"笔记","permalink":"https://cattenlinger.github.io/categories/%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"iOS","slug":"iOS","permalink":"https://cattenlinger.github.io/tags/iOS/"}]},{"title":"利用 Bash 脚本编写自动抓取学校图书馆借阅信息的爬虫 Part 1","slug":"利用-Bash-脚本编写自动抓取学校图书馆借阅信息的爬虫-Part-1","date":"2016-11-14T22:43:40.000Z","updated":"2025-03-24T00:51:31.315Z","comments":true,"path":"2016/11/15/52abf9214120.html","link":"","permalink":"https://cattenlinger.github.io/2016/11/15/52abf9214120.html","excerpt":"","text":"自从弄了个 lcd4linux 之后总想着弄点什么自动化的东西显示出来，因为最近从图书馆借了点书，于是首先想到的是抓图书馆的借阅信息。 我实现的思路大概来说就是，用脚本模仿正常登录查询的步骤来发出并处理请求：先用 Wireshark 对我请求的过程抓包（最方便的方式了吧），然后获取到整个过程中的 HTTP 请求，接着查看每个请求都用了什么方法、发了哪些字段，最后分析出必要的请求并模仿之，逐一发送出去，然后保存获取到的 HTML 页面内容并过滤出有用的内容。 这个操作，流程虽说简单但略微繁琐而且有需要注意的地方。我是用 curl 命令来模仿这些过程，当发送 POST 请求的时候，发送出去的数据是经过了 URL 编码的，里面所有的特殊字符全部都会变成 URL 编码格式的字符，但我忽略了这一点，导致服务器不能正确响应请求而只获取到了错误页面。 除了第一次请求之外，其他的请求都要保存 cookie 来保持会话的一致性。学校的图书馆系统是分开两个并布置在在不同的端口上的，但之间的会话一致性貌似只是通过普通的发送账号密码并 JS 模仿登录框操作来实现（我没详细测试，不知道两个系统之间是否有 session 转移的问题），要注意两个不同的服务器的端口号。 在对第二个系统进行数据的查询的时候，发现了一个问题。浏览器地址栏上面的地址并不是真实的页面地址，而是通过 JS 改写地址栏之后的地址。直接使用 curl 查询的话会得出一个 “Object has remove to here”的页面，里面那个 here 是个超链接，指向之处才是真正的页面的地址。请求了真实页面地址之后，JS 会复写浏览器的地址为原来用户点击的超链接的地址。不知道这用意何在，但如果只是为了隐藏真实页面地址的话我只能说这嫩得一逼啊…… 关于如何用命令提取有用信息，我在下一个部分里再讲。","categories":[{"name":"Linux 技术应用","slug":"Linux-技术应用","permalink":"https://cattenlinger.github.io/categories/Linux-%E6%8A%80%E6%9C%AF%E5%BA%94%E7%94%A8/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://cattenlinger.github.io/tags/Linux/"},{"name":"Bash","slug":"Bash","permalink":"https://cattenlinger.github.io/tags/Bash/"},{"name":"Script","slug":"Script","permalink":"https://cattenlinger.github.io/tags/Script/"}]},{"title":"Bash 通配符小记","slug":"Bash-通配符小记","date":"2016-11-10T22:05:01.000Z","updated":"2025-03-24T00:51:34.148Z","comments":true,"path":"2016/11/11/8953b71b4db1.html","link":"","permalink":"https://cattenlinger.github.io/2016/11/11/8953b71b4db1.html","excerpt":"","text":"本文参考《Linux Shell 编程 从入门到精通》（电子工业出版社出版）一书 3.3 章节 Bash 本身并不支持正则表达式，但是 Bash 可以使用一些通配符实现通配功能： ? 代表一个任意字符 * 代表任意个任意字符 [] 需要匹配的字符集合（例如 a-z, A-Z, 0-9 这样） &#123;&#125; 代表一组表达式的与关系，例如 &#123;[a-h]*.txt,0?.txt&#125; ^ 表达式取反 ? 代表一个任意字符，例如 ls -l 0?.txt 将会显示以 0 开头 .txt 结尾的文件名是两位的文件，例如 01.txt, 0A.txt, 0@.txt 等等。 * 代表任意个任意字符，跟 ? 的区别仅在于 * 不限制匹配的字符数量。 [] 存放字符集合，例如 ls -l o[a-e].txt 则会匹配 o 开头 .txt 结尾的，表达式所在位置的字母是 a 到 e 的文件。 {} 里面填表达式集合，但是它们将以与关系组合，例如 ls -l &#123;[a-h]*.txt,0?.txt&#125; 则里面 [a-h]*.txt 和 0?.txt 两个表达式匹配到的文件都将会被显示出来。","categories":[{"name":"Linux 技术应用","slug":"Linux-技术应用","permalink":"https://cattenlinger.github.io/categories/Linux-%E6%8A%80%E6%9C%AF%E5%BA%94%E7%94%A8/"}],"tags":[{"name":"Bash","slug":"Bash","permalink":"https://cattenlinger.github.io/tags/Bash/"}]},{"title":"关于App开发的杂谈 #1","slug":"关于App开发的杂谈-1","date":"2016-11-06T22:39:42.000Z","updated":"2025-03-24T00:57:47.782Z","comments":true,"path":"2016/11/07/5db99ffce040.html","link":"","permalink":"https://cattenlinger.github.io/2016/11/07/5db99ffce040.html","excerpt":"","text":"尝试过写了些 Hello World，对各大平台的 App 开发有了点毛皮上的认识，我就想来吹吹水，谈谈我的感受了。 学校有开 Android、iOS 的课程，我自己则从小就接触过 C# 的开发，加上自己看了一下视频了解了 Objective-C 的一些基本用法之后自己试着写了个 macOS 的 App，也算是各个平台都碰了一下了。 我的感受就是，App 开发重要在对 App 本身功能的构思以及 MVC 的应用。Android 和 iOS 以及 macOS 的 App ，均以 MVC 的方式构建的。界面跟控制器分离，然后再配合模型层的这种架构，使得一些重复度很高的代码可以高度重用并形成框架，平台的工程师已经做了这些事了。利用这些工程师们写好的框架，其他开发者能够很容易上手一些较为复杂的语言平台的 App 开发（例如 C &#x2F; Objective-C，这种十分原始的语言）。关于界面渲染的 API 和常用的数据结构的算法，工程师们已经整合好了，所需的就是把大部分关注点转移到业务逻辑上去。 还有一个就是，我对“懂一门语言，入门其他语言就很容易”这句话有更深的理解。说实话，到了现在我已经接触过能够使用的语言有 C、C#、Java、Javascript、Objective-C。每一门语言我都能使用其写出一段纯逻辑的代码。即便碰到不懂的语言，花一个下午看看入门视频，把语法和变量类型掌握到手，我就能开始使用这门语言写程序了。原因在于，每一门语言最最基础的就是语法和变量类型。 使用一门语言开发其实就是使用一门语言及基于这门语言发展而来的函数库和框架来开发。用其实现一个企业级 Web 应用或者界面友好的本地 App ，里面需要的代码都是很多的。但如果要分析代码的使用，可以发现占比最多的，并不是应用的业务逻辑代码。不用任何框架来说，一个企业级 Web 应用，占比最多的代码可能是关于数据库访问的管理、 HTTP 请求处理和 HTML 页面的渲染；一个界面友好的本地 App ，占比最多的代码大概就是关于渲染界面、处理用户界面逻辑、文件处理以及网络处理的代码。这些占比最多的代码，即便是写法不同，但是目的都是一样的，都是处理数据库访问、 HTTP 请求、 HTML渲染、界面渲染、界面互动逻辑、文件处理以及网络连接管理。所以之后才有了那么多框架 Hibernate、Servlet、Free Marker、JavaFX、以及一些针对某类型文件的函数库和针对网络连接管理的框架。 因为有了这些框架， App 开发者才可以关注于业务逻辑的处理而无需过多关注其他方面的细节（不敢说不能关注，因为知道其实现原理对开发来说还是很有帮助的）。框架多起来了就需要查询 API 文档了。开发这些 App 都有固定的模式，逻辑已经到手了，接下来就只剩下怎么把代码都串起来。有点像组装一台机器， API 文档就是一本说明了这个平台提供的代码碎片（想像成零件， CPU 啊电源啊内存啊显卡啊……）有什么用处的手册，而开发者则只需要按需把这些代码碎片按照恰当的方式（你的业务逻辑，可以想象成蓝图，例如我要组一台可以全高玩孤岛危机的电脑）拼接成一个应用（想像成实际的电脑主机，但显然电脑主机组装简单多了……）。有了这些框架，就像组装一台主机不需要你自己焊接一块主板甚至自己蚀刻硅片做芯片。 总的来说就是，各个不同平台的 App 开发其实就是用相同的逻辑在不同的语言上使用不同的框架来组装一个应用。","categories":[],"tags":[{"name":"App 开发","slug":"App-开发","permalink":"https://cattenlinger.github.io/tags/App-%E5%BC%80%E5%8F%91/"}]},{"title":"SpringMVC JPA 关联查询问题－根据文章标签查询文章","slug":"JPA-关联查询问题－根据文章标签查询文章","date":"2016-09-19T22:20:44.000Z","updated":"2025-03-24T00:51:52.782Z","comments":true,"path":"2016/09/20/fe622f7eeb75.html","link":"","permalink":"https://cattenlinger.github.io/2016/09/20/fe622f7eeb75.html","excerpt":"","text":"在做协会网站时，有一个API，是可以通过标签查询对应的文章。所以我在文章的 DAO , IArticleDAO 里有个函数 @Query(&quot;select a from ArticleTag a where a.tag in ?1 and a.article.status in ?2&quot;) Page&lt;Article&gt; findArticleByTags(List&lt;Tag&gt; tags, String[] status, Pageable pageable); 但是到我上层 Services 查询回来的结果返回给 Controller 之后，发现返回的 Page 里面居然装的是 ArticleTag 对象。。。我懵了。查了好久发现原来是查询语句写错了，应该 select a.article 才对，于是改成 @Query(&quot;select a.article from ArticleTag a where a.tag in ?1 and a.article.status in ?2&quot;) 但是返回的还是 ArticleTag 。。。 于是我又猜了一下，可能是不能这么查询？试了一下改成以 ArticleTag.article 为查询对象 @Query(&quot;select a from ArticleTag.article a where ArticleTag.tag in ?1 and a.status in ?2&quot;) 于是出现了如下错误直接导致 Services 没法加载 Caused by: org.hibernate.hql.internal.ast.QuerySyntaxException: ArticleTag.article is not mapped [select a from ArticleTag.article a where ArticleTag.tag in ?1 and a.status in ?2] 好吧。。。。上网再查一下 JPA 查询的文章，我发现了这篇 JPA JPQL 查询、排序…..(转)（那个“转”字我看得很不顺眼。。），里面的 关联(join) 部分 提到 在默认的查询中， Entity 中的集合属性默认不会被关联，集合属性默认是延迟加载 ( lazy-load ) 。 然后重新写了之后就变成现在这个了 @Query(&quot;select at.article from ArticleTag at join at.article where at.tag in ?1 and at.article.status in ?2 order by at.article.createDate&quot;) 继续使用 PageRequest 来指定通过文章的某个字段排序也是可以的。删掉 order by ，改在 PageRequest 里使用 article.createDate 即可。因为 JPA 查询实际上会把 PageRequest 里的排序拼接在 JQL 语句里面。实际发出去的 JPA 是跟上面在 Query 注解里的查询语句是一样的。","categories":[{"name":"开发框架","slug":"开发框架","permalink":"https://cattenlinger.github.io/categories/%E5%BC%80%E5%8F%91%E6%A1%86%E6%9E%B6/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"https://cattenlinger.github.io/tags/Spring/"},{"name":"JPA","slug":"JPA","permalink":"https://cattenlinger.github.io/tags/JPA/"}]},{"title":"SpringMVC 一次遇 Bug 经历","slug":"SpringMVC-一次遇-Bug-经历","date":"2016-09-11T22:22:43.000Z","updated":"2025-03-24T00:51:57.808Z","comments":true,"path":"2016/09/12/cdc21b6400c0.html","link":"","permalink":"https://cattenlinger.github.io/2016/09/12/cdc21b6400c0.html","excerpt":"","text":"问题是这样的，我按照正常的配置文件结构配置，然后每次启动起来都提示找不到 Controller ，反反复复看配置文件没发现问题，依赖也正确，甚至连数据库连接池都换了，也没解决 Controller Not Found 的问题。。。 后来过了一天我想了一下，既然是找不到 Controller ，那么就是 Controller 的类没被找到，那么如果没被找到的话，是不是扫描的时候出了问题呢？ 我原来的配置是这样的 &lt;context:component-scan base-package=&quot;cn.lncsa.controller.*&quot;/&gt; 然后我试了一下增加了 Controller 的 filter &lt;context:component-scan base-package=&quot;cn.lncsa.controller.*&quot;&gt; &lt;context:include-filter type=&quot;annotation&quot; expression=&quot;org.springframework.stereotype.Controller&quot;/&gt; &lt;/context:component-scan&gt; 问题并没有被解决。 后来观察，发现 base-package 参数是 “cn.lncsa.controller.*“，然后回头对比了一下按照教程做的能正常运行的 Helloworld ，是 “net.catten.mvc.*“ 而不是”net.catten.mvc.controller.*“，我在想是不是这个通配符的问题，于是便试着把 base-package 改成 “cn.lncsa.controller” &lt;context:component-scan base-package=&quot;cn.lncsa.controller&quot;/&gt; 问题解决。。。。 然后在想为什么呢？ 是这样的，base-package 指的是扫描器从那个包开始扫描， “cn.lncsa.controller.*“ 指的是扫描 controller 包下面的任何包，也就是说 * 通配符是改变了扫描基于的包了，不再是 controller 而是 controller 里面的各个子包。而我的 Controller 类是放在这个包下的，扫的是根包里的子包的类而不是根包里的类，当然就搜索不到 Controller 了。 那么这个错误的配置除了上面这么改还能怎么改呢？ &lt;context:component-scan base-package=&quot;cn.lncsa.*&quot;&gt; &lt;context:include-filter type=&quot;annotation&quot; expression=&quot;org.springframework.stereotype.Controller&quot;/&gt; &lt;/context:component-scan&gt; 这样改就好了。虽然方法不同但是原理都是更改扫描的根包。第一种方法是直接明确地指出扫描的地方。第二种方法是扫描 cn.lncsa 里面的子包，但是增加 include-filter， 使其只扫描 Controller 类。 当然我的习惯是使用第一种。 还有需要注意的是，因为 SpringMVC 一般是和 Spring 共用， 所以会有重复扫描类的问题。我们的 Controller 是交给 SpringMVC 所属的容器管理的，所以应该让主要的 Spring IOC 容器忽略掉这些 Controller。不然会造成重复扫描，生成重复的对象在两个 IOC 容器里。 所以除了配置 spring-mvc 的 applicationContext 以外，也要在主要的 applicationContxt 里配置扫描器。 &lt;context:component-scan base-package=&quot;cn.lncsa&quot;&gt; &lt;context:exclude-filter type=&quot;annotation&quot; expression=&quot;org.springframework.stereotype.Controller&quot;/&gt; &lt;/context:component-scan&gt; 增加 exclude-filter 就能让主要的 IOC 容器忽略掉这些 Controller","categories":[{"name":"开发框架","slug":"开发框架","permalink":"https://cattenlinger.github.io/categories/%E5%BC%80%E5%8F%91%E6%A1%86%E6%9E%B6/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"https://cattenlinger.github.io/tags/Spring/"},{"name":"SpringMVC","slug":"SpringMVC","permalink":"https://cattenlinger.github.io/tags/SpringMVC/"},{"name":"Spring IoC","slug":"Spring-IoC","permalink":"https://cattenlinger.github.io/tags/Spring-IoC/"}]},{"title":"用 Maven 生成典型 Web 应用目录结构","slug":"用-Maven-生成典型-Web-应用目录结构","date":"2016-09-08T23:08:14.000Z","updated":"2025-03-24T00:52:32.002Z","comments":true,"path":"2016/09/09/2d7cc9f10bb5.html","link":"","permalink":"https://cattenlinger.github.io/2016/09/09/2d7cc9f10bb5.html","excerpt":"","text":"使用以下命令 mvn archetype:generate -DgroupId=&#123;your-groupId&#125; -DartifactId=&#123;your-artifactId&#125; -DarchetypeArtifactId=maven-archetype-webapp {your-groupId} 和 {your-artifactId} 用自己喜欢的 groupId 和 artifactId 代替就好，运行一段时间之后会问你一些设置：版本号， groupId ，artifactId，如果不需要修改的话全部直接回车就好。运行结束将会在执行命令的目录下新建一个与 artifactId 同名的文件夹。 简单解析一下命令 mvn是调用maven的命令，archetype:generate是调用了某种插件并应用插件上的某个目标，然后接着的是插件所需要的参数。","categories":[{"name":"开发框架","slug":"开发框架","permalink":"https://cattenlinger.github.io/categories/%E5%BC%80%E5%8F%91%E6%A1%86%E6%9E%B6/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://cattenlinger.github.io/tags/Java/"},{"name":"Maven","slug":"Maven","permalink":"https://cattenlinger.github.io/tags/Maven/"}]},{"title":"慕课网《Javascript 进阶篇》编程挑战通过笔记","slug":"慕课网《Javascript-进阶篇》编程挑战通过笔记","date":"2016-08-24T23:03:18.000Z","updated":"2025-03-24T00:56:41.892Z","comments":true,"path":"2016/08/25/0f6fb47a1245.html","link":"","permalink":"https://cattenlinger.github.io/2016/08/25/0f6fb47a1245.html","excerpt":"","text":"当时我一步步把《Javascript 进阶篇》做完之后，一如既往来到编程挑战章节，当我看到要写一个模拟选项卡切换的小程序之后，我整个人都不好了。好难啊！！感觉之前的白学了！！ orz 之后我看了一下别人的代码。然后滚去看CSS去了。。。 （回来了） 好了当我重新打开这个章节的时候我还是懵逼的，于是只好继续参考别人的代码。。。然后我从CSS样式开始着手。 这个其实上面是一个无序列表元素，里面有几个列表项目包裹着三个文本标签。 &lt;ul&gt; &lt;li&gt;房产&lt;/li&gt; &lt;li&gt;家居&lt;/li&gt; &lt;li&gt;二手房&lt;/li&gt; &lt;/ul&gt; 然后下面是一个类似面板的东西，参考别人代码发现其实是三个面板，只是用CSS样式隐藏掉了 &lt;div class=&quot;hidden&quot;&gt; &lt;ul&gt; &lt;li&gt;内容写在这里&lt;/li&gt; &lt;li&gt;内容写在这里&lt;/li&gt; &lt;li&gt;内容写在这里&lt;/li&gt; ... &lt;/ul&gt; &lt;/div&gt; 当要显示的时候，就改变面板的css样式重新显示出来 样式： .hidden&#123; display:none; &#125; .shown&#123; display:block; &#125; 那么外观呢？ 上面的标签是一个正方形，未激活的时候是灰色边框，激活之后是上面带红色高亮的方框，然后下面面板红色的顶框有跟标签同长度的一段消失掉。 上面的标签好办，我给放置标签的&lt;ul&gt;增加类tabs，然后增加以下css .tabs&gt;li&#123; display:inline-block; /*让 li 元素横着排版*/ margin : 0px 2px; /*设置一个好看的长宽和内边距外边距以及字体样式和位置*/ padding : 3px 2px; width : 70px; height : 25px; font-size : 13x; text-align : center; border : 1px solid #ccc; /*未激活的灰色边框*/ border-bottom : none; /*下边框不要*/ background-color : white; &#125; /*增加一个伪类 active 表示激活状态*/ .tabs&gt;li.active&#123; border-top : 2px solid #955; /*框顶部的红色*/ position : relative; top : 2px; border-bottom : 1px solid #fff; &#125; 这里有个有趣的地方，因为直接让&lt;div&gt;的边框让出跟标签同宽的空白是不可能的，所以想到实际上是标签把下面的&lt;div&gt;的边框给遮住了，怎么实现这个效果呢？我想了很久，想到相对定位让&lt;li&gt;标签下沉对应的位置就好了。所以就有了上面的position和top属性的配合使得标签下沉遮住边框。 搞定了样式开始写 Javascript ，原理无非就是给三个&lt;li&gt;绑定onlick事件，于是直接用window.onload来给标签自动添加事件。 window.onload = function()&#123; var tabs = document.getElementById(&quot;tabs&quot;).getElementByTagName(&quot;li&quot;); for(var i=0;i &lt; tabs.length; i++)&#123; tabs[i].index = i; tabs[i].onclick = function()&#123; //标签切换代码 &#125; &#125; &#125; 为了方便我给放标签的&lt;ul&gt;加了id叫tabs 这里有个要注意的地方：为什么要用document.getElementById(&quot;tabs&quot;).getElementByTagName(&quot;li&quot;); 而不是document.getElementById(&quot;tabs&quot;).childNodes; childNodes有浏览器兼容性问题，如果在IE上面用的话，能取到&lt;ul&gt;里的&lt;li&gt;元素，但是如果在其他浏览器里使用，将不止获取到&lt;li&gt;元素，而是连同里面的TextNode元素一起获取过来，那么这个列表就不是纯粹的只存放&lt;li&gt;的列表了。用getElementByTagName(&quot;li&quot;)能精准拿出所有&lt;li&gt;。 还有一行tabs[i].index = i;，这个是为了之后的代码能够方便地获取标签的id，因为我们没办法直接获取到发出点击事件的标签在标签栏里的顺序，所以直接给这个标签的节点声明一个index会方便很多。 为了方便我给放这个选项卡的容器设置id=&quot;tab-list&quot; 下面是事件的代码 tabs[i].onclick = function()&#123; var panels = document .getElementById(&quot;tab-list&quot;) .getElementsByTagName(&quot;div&quot;); for(var i=0;i&lt;panels.length;i++) panels[i].className = &quot;hide&quot;; for(var i=0;i&lt;tabs.length;i++) tabs[i].className = &quot;&quot;; this.className = &quot;active&quot;; panels[this.index].className = &quot;show&quot;; //给标签设置index就是方便在这里直接获取发出事件的标签的顺序。从而给对应的 panel 设置 show 属性。 &#125;","categories":[{"name":"编程技术","slug":"编程技术","permalink":"https://cattenlinger.github.io/categories/%E7%BC%96%E7%A8%8B%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"JavaScript","slug":"JavaScript","permalink":"https://cattenlinger.github.io/tags/JavaScript/"}]},{"title":"在 Ubuntu 上安装 Enlightenment Desktop","slug":"在-Ubuntu-上安装-Enlightenment-Desktop","date":"2016-08-22T22:46:36.000Z","updated":"2025-03-24T00:52:50.725Z","comments":true,"path":"2016/08/23/cd93c0787761.html","link":"","permalink":"https://cattenlinger.github.io/2016/08/23/cd93c0787761.html","excerpt":"","text":"最近知道有个桌面环境叫 Enlightenment Desktop ，看上去很酷炫，打算安装试用一下。 官方网站是 enlightenment.org ，上面有详细的介绍以及安装方式，这里只介绍如何在 Ubuntu 16.04 上安装。 首先添加其官方软件源，据官方说是因为 Ubuntu 上的源的 Enlightenment 已经很旧了，所以推荐使用新版。 sudo add-apt-repository ppa:niko2040/e19 然后更新并安装桌面的本体 sudo apt-get update sudo apt-get install enlightenment terminology connman 其中 enlightenment 是本体； terminology 是其终端模拟器，很酷炫的说； connman 是网络管理器，建议安装。 然后登出即可切换至 Enlightenment 19 了。","categories":[{"name":"Linux 技术应用","slug":"Linux-技术应用","permalink":"https://cattenlinger.github.io/categories/Linux-%E6%8A%80%E6%9C%AF%E5%BA%94%E7%94%A8/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://cattenlinger.github.io/tags/Linux/"},{"name":"Desktop Environments","slug":"Desktop-Environments","permalink":"https://cattenlinger.github.io/tags/Desktop-Environments/"}]},{"title":"Javascript 入门课程笔记","slug":"Javascript-入门课程笔记","date":"2016-08-17T22:18:27.000Z","updated":"2025-03-24T00:52:58.082Z","comments":true,"path":"2016/08/18/477b1f08fd94.html","link":"","permalink":"https://cattenlinger.github.io/2016/08/18/477b1f08fd94.html","excerpt":"","text":"本篇笔记是学习了 Javascript 入门课程 后的笔记 课程首先讲了Javascript的基本语法： 使用&lt;script&gt;&lt;&#x2F;script&gt;标签对声明Javascript代码片段 使用外部引入方式&lt;script src&#x3D;”filename.js”&gt;&lt;&#x2F;script&gt;引入Javascript函数和代码片段 &#x2F;&#x2F;注释和&#x2F;**&#x2F;注释 if和else关键字控制流程 使用var关键字声明变量 使用function关键字声明函数 在示例代码中也看见有with关键字的使用，声明在with(){}范围内的代码与哪个对象有关，使得一系列代码脚本省略了很多字。 然后讲一些互动有关的函数 用document.write输出字符到此代码所在的地方 用alert函数弹出警告对话框 用confirm函数弹出确认对话框 用prompt函数弹出输入对话框 用window.open函数弹出新窗口 用window.close函数关闭窗口 其中，window.open是有参数列表的: window.open([URL], [窗口名称], [参数字符串])。 URL 代表要打开的连接，可选，如果留空则不打开任何文档。 窗口名称 表示新窗口的名称，可选。有以下注意事项： 该名称由字母、数字和下划线字符组成。 “_top”、”_blank”、”_selft”具有特殊意义的名称。 _blank：在新窗口显示目标网页 _self：在当前窗口显示目标网页 _top：框架网页中在上部窗口中显示目标网页 相同 name 的窗口只能创建一个，要想创建多个窗口则 name 不能相同。 name 不能包含空格 参数字符串 可选，设置窗口参数，各参数用逗号隔开。参数参照以下表格 参数 值 说明 top Number 窗口离屏幕顶部距离 left Number 窗口离屏幕左侧距离 height Number 窗口高度 width Number 窗口宽度 menubar yes | no 是否有菜单栏 toolbar yes | no 是否有工具栏 scrollbar yes | no 是否有滚动条 status yes | no 是否有状态栏 window.close是关闭当前窗口，如果获取了某个窗口对象，则可以调用其close把它关闭。 接着讲操作节点 通过id获取元素：document.getElementById(); 通过节点的innteHTML属性修改节点内容 通过节点的style属性修改样式： style.color修改颜色 style.hight, style.width修改宽和高 其它的属性同理 通过节点的display属性显示或者隐藏元素 display &#x3D; “none” 隐藏元素 display &#x3D; “block” 显示元素 通过节点的className属性改变节点的类名，从而应用对应类的样式","categories":[{"name":"笔记","slug":"笔记","permalink":"https://cattenlinger.github.io/categories/%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"Javascript","slug":"Javascript","permalink":"https://cattenlinger.github.io/tags/Javascript/"}]},{"title":"访问互联网背后的原理","slug":"访问互联网背后的原理","date":"2016-07-23T23:09:16.000Z","updated":"2025-03-24T00:53:06.638Z","comments":true,"path":"2016/07/24/6d29a83b1266.html","link":"","permalink":"https://cattenlinger.github.io/2016/07/24/6d29a83b1266.html","excerpt":"","text":"平常我们只要打开电脑电源，进入操作系统，启动浏览器，输入网址，便能访问互联网。那么在这个过程中到底发生了什么事情呢。 打开浏览器输入网址后，网址通过DNS被解析成IP地址，浏览器发出一个HTTP请求(HTTP Request)（或者是HTTPS，这里先以最普通的HTTP请求为例），HTTP请求被转换成网络数据包，写上发源地IP和目的地IP并发送给网卡，由网卡转换成高低电平，通过网线发送数据到达外面路由器或者交换机，然后错综复杂的互联网上的交换机和路由根据网络数据包的目的地IP转发数据包到目的地，一般称作服务器，然后服务器的系统把数据包从网卡里拿出来发给正在Web容器内运行的网站应用（Web Application，简写 Web App ），网站应用从网络数据包中取出HTTP请求进行分析，并返回适当的网页内容包装成HTTP回应（HTTP Response），然后由系统包装成网络数据包，这时候发源地IP和目的地IP互换，网卡把网络数据包发送给外界互联网，网络数据包被互联网转发到原来发出请求的电脑上，由系统递交给浏览器并由浏览器分析出里面的内容，把内容呈现给用户。 这个过程能够用邮寄来类比。假设有A和B两个人，A希望得到B的一个杯子，于是A通过手写信，然后A把信封在信封里，写上发件人地址和收件人地址拿去邮局寄出，相当于浏览器创建一个HTTP请求，HTTP请求被转换成网络数据包，写上发源地IP和目的地IP并由网卡发送到互联网；信通过邮局的运输网络到达B的信箱，B打开信封并用眼看信纸，然后在自己的仓库里选择A需要的杯子并打包好，在包裹的收件人地址填上A的地址，发件人地址填上B的地址，然后到邮局寄出，相当于服务器得到了HTTP请求之后，分析并生成合适的内容包装成HTTP请求并通过互联网发送给用户。A收到包裹拆开并看见杯子，相当于浏览器分析数据包，从中提取出HTTP回应的内容并呈现给用户。 网站开发，就是通过开发Web App来利用Web容器对HTTP请求作符合需求的处理以及选取适当的内容写入到HTTP回应返回给发出HTTP请求的用户。","categories":[{"name":"笔记","slug":"笔记","permalink":"https://cattenlinger.github.io/categories/%E7%AC%94%E8%AE%B0/"}],"tags":[]},{"title":"对 Java 里方法的可变长参数列表使用的小经验","slug":"对-Java-里方法的可变长参数列表使用的小经验","date":"2016-07-01T22:57:31.000Z","updated":"2025-03-24T00:54:42.358Z","comments":true,"path":"2016/07/02/aa66e4e7c665.html","link":"","permalink":"https://cattenlinger.github.io/2016/07/02/aa66e4e7c665.html","excerpt":"","text":"Java好像自从1.6就已经可以使用void method(String... s)的方法声明参数列表，这个声明方式挺好玩的，我分享一下我的使用经验。 这个声明有一个特点，就是可变长的参数声明必须在传参列表的最后面。也就是说，void method(Object o, String... s)可以，但是void method(String... s, Object o)是不符合语法的。String... s是半个语法糖，可变长参数列表只能放在传参的最后面。那么这样子用起来某些场合就有那么点小限制了，但是这并不太妨碍，只要这样就行了。 void method(String[] s, Object o)&#123; //Codes... &#125; void method(Object o, String... s)&#123; method(s,o); &#125; 上面举例的代码可能太抽象，我用我的实际应用场景来继续说明一下。为了方便说明，我先给一些刚入门的同学介绍一下SpringData。这里的介绍摘自官网首页，并附上我的翻译。 Spring Data’s mission is to provide a familiar and consistent, Spring-based programming model for data access while still retaining the special traits of the underlying data store. It makes it easy to use data access technologies, relational and non-relational databases, map-reduce frameworks, and cloud-based data services. Spring Data 的任务是提供一个符合标准和习惯的、保留了一些底层数据访问特性的、基于 Spring 的访问数据的框架，让使用关系型数据库、非关系型数据库、MapReduce 框架（MapReduce 是 Google 提出的一个软件架构，用于大规模数据集（大于1TB）的并行运算）以及云端数据服务等数据访问技术变得更加方便。 那么接下来我有这么一串代码在DAO接口里： @Query(&quot;select a from Article a where a.status in ?1&quot;) Page&lt;Article&gt; findAll(String[] status, PageRequest pageRequest); PS：这是一个符合Spring Data 规范的 PagingAndSortingRepository 接口子接口方法声明规范的一个方法。在这个接口里面声明的方法，能够通过 ?1 的方式传入到上面的 @Query 注解里的 JQL（JIRA Query Language）语句里面。 这个方法用途是从存放 Article 对象的表中查询出符合 status 数组里条件的数据并返回成分页查询对象。根据规范，我的分页请求必须在参数列表里，但是为了方便以后编程，我想使用可变长参数列表，于是就撞上了语法限制了。但是想一下，DAO 上一层就是 Services 层，Services 层代理了 DAO 的访问。于是结合之前讲的原理，我在 Services 层里的一个代理方法里这样写 public Page&lt;Article&gt; getAllArticle(PageRequest pageRequest, String... status) &#123; return articleDAO.findAll(status, pageRequest); &#125; 这样就能愉快地使用可变长参数列表啦。 getAllArticle(new PageRequest(),&quot;shown&quot;,&quot;hidden&quot;,&quot;banned&quot;); 之前考虑到如果只传一个参数的话会怎么。答案其实显而易见，就是传进来一个只有一个元素的数组。因为它是把可变长参数包装成了数组，原因是 String... a; 其实是 Java 里面的一种声明数组的方式。","categories":[{"name":"编程技术","slug":"编程技术","permalink":"https://cattenlinger.github.io/categories/%E7%BC%96%E7%A8%8B%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://cattenlinger.github.io/tags/Java/"},{"name":"Programing Language","slug":"Programing-Language","permalink":"https://cattenlinger.github.io/tags/Programing-Language/"}]},{"title":"使用 Docker 搭建 Don't Starve Together Dedicated Server","slug":"使用-Docker-搭建-Don-t-Starve-Together-Dedicated-Server","date":"2016-05-12T22:36:21.000Z","updated":"2025-03-24T00:54:48.365Z","comments":true,"path":"2016/05/13/522c8a934a61.html","link":"","permalink":"https://cattenlinger.github.io/2016/05/13/522c8a934a61.html","excerpt":"","text":"了解过docker之后我决定练一下手（本来是因为有些人想玩DST所以才决定的），于是就拿饥荒联机服务器(以下简称dst服务器)来做练手作 Google到了Docker Hub里面有现成的DST docker镜像，感谢jamesits。介绍地址:Docker Hub ： DST Dedicated Server。 安装docker的步骤网上很多，我就不介绍了。安装完docker之后还得安装docker-compose。我的DST服务器数据放在/srv/dst/，以下例子都用这个路径。 镜像作者使用Docker Compose，所以只要在打算让dst服务器保存数据的目录下新建文件并粘贴以下代码 overworld-server: image: jamesits/don-t-starve-together-dedicated-server:latest restart: always ports: - 10999:10999/udp - 8766:8766/udp - 27016:27016/udp volumes: - ./server_config:/data/DoNotStarveTogether 保存成名为docker-compose.yml的文件，在/srv/dst/下以root权限启动docker-compose up，即可自动下载并启动饥荒服务器。但是这样子服务器并不会真正启动起来，还需要写一下配置才能够跑起来。 Ctrl+C停掉服务器，会发现自动生成好的配置文件目录/srv/dst/server_config/。进入/srv/dst/server_config/Cluster_1/，新建一个cluster.ini文件，并在里面写配置： [NETWORK] cluster_name = 服务器的名称 cluster_description = 服务器描述 cluster_intention = 服务器的类型 [cooperative | social | competitive | madness] cluster_password = 密码，可选 server_port = 10999 服务器的端口，建议不要修改 max_players = 20 最大玩家数量，1-64 pvp = false 是否允许pvp，玩家对打 game_mode = survival 游戏模式 [endless | survival | wilderness] tick_rate = 30 服务器的帧率，越高越fantasy不过对服务器和带宽要求高 connection_timeout = 3000 server_save_slot = 1 服务器存档读取，一般不用改 pause_when_empty = true 这个虽然是对应“当服务器没人时停止服务器”但是并没有生效 dedicated_lan_server = true 是否允许局域网联机 写好配置之后，要获取服务端的令牌。进入DST客户端之后，点Play登陆，然后点右下角的Account，页面里找到生成Token的地方（右侧的名字可以随便写），然后把生成的Token写进/srv/dst/server_config/Cluster_1/cluster_token.txt里保存。 如果不需要mod的话，到这里就可以回到/srv/dst里docker-compose up了，在后面加-d可以让其在后台运行。 如果要加mod，那么需要编辑/srv/dst/server_config/里面的dedicated_server_mods_setup.lua文件。在里面一行添加一个mod。 ServerModSetup(&quot;mod1-id&quot;) ServerModSetup(&quot;mod2-id&quot;) ServerModSetup(&quot;mod3-id&quot;) Mod ID可以在创意工坊里面查到。进入mod页面后拷贝一下链接。找个地方粘贴一下 http://steamcommunity.com/sharedfiles/filedetails/?id=681368916 id后面跟着的就是了。 写好之后保存。现在还没能启用，如果启动服务器的话，只会下载列表里的Mod而不会启动。要启动的话有两种方式，一种是强制启动，但是这种方式一般只在开发mod的时候使用，不推荐。另外一种是常规的启动方式，能给mod写配置（如何写配置请参考下面给出的链接）。 进入/srv/dst/server_config/Cluster_1/Master/，新建一个modoverrides.lua，在里面写 return&#123; [&quot;workshop-id1&quot;] = &#123; enabled = true &#125;, [&quot;workshop-id2&quot;] = &#123; enabled = true &#125;, [&quot;workshop-id3&quot;] = &#123; enabled = true &#125; &#125; id替换成要启动的mod的id，保存后建议给文件添加可执行权限 chmod +x modoverrides.lua 现在启动服务器后，就如你所愿啦。 黑名单，白名单以及管理员名单列表放在 更详尽的服务器设置和Mod设置请参考 Guides&#x2F;Don’t Starve Together Dedicated Servers 和 Dedicated Server w&#x2F;Mods [Problem]","categories":[{"name":"Self-Hosting","slug":"Self-Hosting","permalink":"https://cattenlinger.github.io/categories/Self-Hosting/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://cattenlinger.github.io/tags/Linux/"},{"name":"Docker","slug":"Docker","permalink":"https://cattenlinger.github.io/tags/Docker/"}]},{"title":"Hibernate 使用 Annotation 实现外键关联关系","slug":"Hibernate-使用-Annotation-实现外键关联关系","date":"2016-04-26T22:07:58.000Z","updated":"2025-03-24T00:54:57.802Z","comments":true,"path":"2016/04/27/c4be259c16d2.html","link":"","permalink":"https://cattenlinger.github.io/2016/04/27/c4be259c16d2.html","excerpt":"","text":"因为在使用Hibernate的Annotation时遇到坑，坑了一晚上时间，所以写一篇文章记一下经验 如果并没有对Hibernate入门，还请在课室或者在技研中心，接入学校的教学网络，进入服务器smb:&#x2F;&#x2F;10.15.231.233&#x2F;Video （在技研的网络里叫OPENSUSE-SERVER）。在 数据库-&gt;ORM-&gt;Hibernate 目录内查看视频教程了解 我的项目使用的是Hibernate 4.3.11.Final，是一个Maven工程。所用到的辅助工具有fastjson，用来把类直接输出成json查看，还有junit4，测试用。 依赖列表(pom.xml)节选 &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.hibernate&lt;/groupId&gt; &lt;artifactId&gt;hibernate-core&lt;/artifactId&gt; &lt;version&gt;4.3.11.Final&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-simple&lt;/artifactId&gt; &lt;version&gt;1.7.18&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;5.1.38&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;4.8.2&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;fastjson&lt;/artifactId&gt; &lt;version&gt;1.2.8&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; 我的工程是一个有关于评分的系统。在里面有两个类，一个是评分模板MarkingTemplate，一个是评分项目MarkingItem。 MarkingTemplate在数据库中的字段如下 字段名 数据类型 备注 id INT 数据编号（自动增长） title nvarchar(50) 模板标题 commit nvarchar(50) 模板备注 实体类字段如下： private int id; private String title; private String commit; private int value; private MarkingTemplate markingTemplate; MarkingItem在数据库里的字段如下 字段名 数据类型 备注 id INT 数据编号（自增长） title nvarchar(50) 评分项目标题 commit nvarchar(50) 评分项目备注 value INT 项目分值（只有整数） belong_to_template INT 所属模板的编号（外键链接至contest_templates） 实体类字段如下： private int id; private String title; private String commit; private List&lt;MarkingItem&gt; markingItems; 很明显，我数据库里只有MarkingItem到MarkingTemplate的关联，没有明显的反过来的关联。看视频教程的话，都是用的实体类配置文件实现这些关系，但是我想尝试使用Annotation（注解）来实现这个关系，因为本身项目简单，而且注解很简洁很方便。 MarkingTemplate类源码和注解 @Entity @Table(name = &quot;marking_templates&quot;) public class MarkingTemplate &#123; private int id; private String title; private String commit; private List&lt;MarkingItem&gt; markingItems; @Id @GeneratedValue public int getId() &#123; return id; &#125; public void setId(int id) &#123; this.id = id; &#125; public String getTitle() &#123; return title; &#125; public void setTitle(String title) &#123; this.title = title; &#125; public String getCommit() &#123; return commit; &#125; public void setCommit(String commit) &#123; this.commit = commit; &#125; @OneToMany(mappedBy = &quot;markingTemplate&quot;) public List&lt;MarkingItem&gt; getMarkingItems() &#123; return markingItems; &#125; public void setMarkingItems(List&lt;MarkingItem&gt; markingItems) &#123; this.markingItems = markingItems; &#125; &#125; MarkingItem源码和注解 @Entity @Table(name = &quot;marking_items&quot;) public class MarkingItem &#123; private int id; private String title; private String commit; private int value; private MarkingTemplate markingTemplate; @Id @GeneratedValue public int getId() &#123; return id; &#125; public void setId(int id) &#123; this.id = id; &#125; public String getTitle() &#123; return title; &#125; public void setTitle(String title) &#123; this.title = title; &#125; public String getCommit() &#123; return commit; &#125; public void setCommit(String commit) &#123; this.commit = commit; &#125; public int getValue() &#123; return value; &#125; public void setValue(int value) &#123; this.value = value; &#125; @ManyToOne(targetEntity = MarkingTemplate.class) @JoinColumn(name = &quot;belong_to_template&quot;) public MarkingTemplate getMarkingTemplate() &#123; return markingTemplate; &#125; public void setMarkingTemplate(MarkingTemplate markingTemplate) &#123; this.markingTemplate = markingTemplate; &#125; &#125; 如果要实现双向的关联，那么需要在两边的类关联的字段所对应的属性声明上添加注解。 先解释一下MarkingItem的getMarkingTemplate() @ManyToOne(targetEntity = MarkingTemplate.class) @JoinColumn(name = &quot;belong_to_template&quot;) public MarkingTemplate getMarkingTemplate() &#123; return markingTemplate; &#125; 从数据库里提取belong_to_template字段的数值然后再利用其查询即可得出MarkingTemplate的数值。@ManyToOne表示了一个多对一的关系。模板内项目对模板是多对一关系。targetEntity标明这个字段是关联到哪个类，通过这个，Hibernate可以很方便地把这个查出来的号码把MarkingItems所属的MarkingTemplate实体化出来。@JoinColumn表明插入列的字段名称，这个可以省去，我添加这个的原因是因为类中的属性名和数据库内的字段名不相符。 再解释一下MarkingTemplate的getMarkingItems() @OneToMany(mappedBy = &quot;markingTemplate&quot;) public List&lt;MarkingItem&gt; getMarkingItems() &#123; return markingItems; &#125; @OneToMany注解声明了一个一对多关系。从数据库字段表可以看出，模板对模板内项目是一对多关系。一个模板拥有多个模板内项目，这些项目在类里被存放在一个List里。而在数据库里，是每个项目都有一个字段标明它们属于哪个模板。mappedBy参数表明这个被在Many一方的类的那个属性给映射了。 当查出实体数据之后，Hibernate默认是对关联属性的数据进行延迟加载，就是等到调用get方法的时候再去生成SQL语句查询这个类。 测试类里我利用fastjson直接把数据可视化了。 获取MarkingTemplate @Test public void TestGetMarkingTemplate()&#123; System.out.println(JSON.toJSONString(session.get(MarkingTemplate.class,1))); &#125; 输出结果 &#123; &quot;commit&quot;: &quot;通用模板&quot;, &quot;id&quot;: 1, &quot;markingItems&quot;: [ &#123; &quot;commit&quot;: &quot;结合竞赛主题，作品选题具有实用性、合理性、创新性&quot;, &quot;id&quot;: 6, &quot;markingTemplate&quot;: &#123; &quot;$ref&quot;: &quot;$&quot; &#125;, &quot;title&quot;: &quot;选题&quot;, &quot;value&quot;: 10 &#125;, &#123; &quot;commit&quot;: &quot;界面友好，完成速度快，操作简洁明了&quot;, &quot;id&quot;: 7, &quot;markingTemplate&quot;: &#123; &quot;$ref&quot;: &quot;$&quot; &#125;, &quot;title&quot;: &quot;界面&quot;, &quot;value&quot;: 20 &#125;, &#123; &quot;commit&quot;: &quot;采用的软件开发方法与技术是否先进及与项目相宜&quot;, &quot;id&quot;: 8, &quot;markingTemplate&quot;: &#123; &quot;$ref&quot;: &quot;$&quot; &#125;, &quot;title&quot;: &quot;技术&quot;, &quot;value&quot;: 10 &#125;, &#123; &quot;commit&quot;: &quot;功能强大，具有实用性&quot;, &quot;id&quot;: 9, &quot;markingTemplate&quot;: &#123; &quot;$ref&quot;: &quot;$&quot; &#125;, &quot;title&quot;: &quot;功能&quot;, &quot;value&quot;: 40 &#125;, &#123; &quot;commit&quot;: &quot;作品的市场潜力与价值&quot;, &quot;id&quot;: 10, &quot;markingTemplate&quot;: &#123; &quot;$ref&quot;: &quot;$&quot; &#125;, &quot;title&quot;: &quot;市场&quot;, &quot;value&quot;: 10 &#125;, &#123; &quot;commit&quot;: &quot;对问题的实际理解程度&quot;, &quot;id&quot;: 11, &quot;markingTemplate&quot;: &#123; &quot;$ref&quot;: &quot;$&quot; &#125;, &quot;title&quot;: &quot;答辩&quot;, &quot;value&quot;: 10 &#125; ], &quot;title&quot;: &quot;模板1&quot; &#125; 因为fastjson在生成json string的时候调用了里面的get方法，所以这里没体现hibernate的延迟加载。 获取MarkingItem @Test public void TestGetMarkingItems()&#123; List markingItems = session.createQuery(&quot;from MarkingItem&quot;).setFirstResult(0).setMaxResults(9).list(); for(Object o: markingItems)&#123; System.out.println(JSON.toJSONString(o)); &#125; &#125; 输出结果 &#123;&quot;commit&quot;:&quot;结合竞赛主题，作品选题具有实用性、合理性、创新性&quot;,&quot;id&quot;:6,&quot;markingTemplate&quot;:&#123;&quot;commit&quot;:&quot;通用模板&quot;,&quot;id&quot;:1,&quot;markingItems&quot;:[&#123;&quot;$ref&quot;:&quot;$&quot;&#125;,&#123;&quot;commit&quot;:&quot;界面友好，完成速度快，操作简洁明了&quot;,&quot;id&quot;:7,&quot;markingTemplate&quot;:&#123;&quot;$ref&quot;:&quot;$.markingTemplate&quot;&#125;,&quot;title&quot;:&quot;界面&quot;,&quot;value&quot;:20&#125;,&#123;&quot;commit&quot;:&quot;采用的软件开发方法与技术是否先进及与项目相宜&quot;,&quot;id&quot;:8,&quot;markingTemplate&quot;:&#123;&quot;$ref&quot;:&quot;$.markingTemplate&quot;&#125;,&quot;title&quot;:&quot;技术&quot;,&quot;value&quot;:10&#125;,&#123;&quot;commit&quot;:&quot;功能强大，具有实用性&quot;,&quot;id&quot;:9,&quot;markingTemplate&quot;:&#123;&quot;$ref&quot;:&quot;$.markingTemplate&quot;&#125;,&quot;title&quot;:&quot;功能&quot;,&quot;value&quot;:40&#125;,&#123;&quot;commit&quot;:&quot;作品的市场潜力与价值&quot;,&quot;id&quot;:10,&quot;markingTemplate&quot;:&#123;&quot;$ref&quot;:&quot;$.markingTemplate&quot;&#125;,&quot;title&quot;:&quot;市场&quot;,&quot;value&quot;:10&#125;,&#123;&quot;commit&quot;:&quot;对问题的实际理解程度&quot;,&quot;id&quot;:11,&quot;markingTemplate&quot;:&#123;&quot;$ref&quot;:&quot;$.markingTemplate&quot;&#125;,&quot;title&quot;:&quot;答辩&quot;,&quot;value&quot;:10&#125;],&quot;title&quot;:&quot;模板1&quot;&#125;,&quot;title&quot;:&quot;选题&quot;,&quot;value&quot;:10&#125; &#123;&quot;commit&quot;:&quot;界面友好，完成速度快，操作简洁明了&quot;,&quot;id&quot;:7,&quot;markingTemplate&quot;:&#123;&quot;commit&quot;:&quot;通用模板&quot;,&quot;id&quot;:1,&quot;markingItems&quot;:[&#123;&quot;commit&quot;:&quot;结合竞赛主题，作品选题具有实用性、合理性、创新性&quot;,&quot;id&quot;:6,&quot;markingTemplate&quot;:&#123;&quot;$ref&quot;:&quot;$.markingTemplate&quot;&#125;,&quot;title&quot;:&quot;选题&quot;,&quot;value&quot;:10&#125;,&#123;&quot;$ref&quot;:&quot;$&quot;&#125;,&#123;&quot;commit&quot;:&quot;采用的软件开发方法与技术是否先进及与项目相宜&quot;,&quot;id&quot;:8,&quot;markingTemplate&quot;:&#123;&quot;$ref&quot;:&quot;$.markingTemplate&quot;&#125;,&quot;title&quot;:&quot;技术&quot;,&quot;value&quot;:10&#125;,&#123;&quot;commit&quot;:&quot;功能强大，具有实用性&quot;,&quot;id&quot;:9,&quot;markingTemplate&quot;:&#123;&quot;$ref&quot;:&quot;$.markingTemplate&quot;&#125;,&quot;title&quot;:&quot;功能&quot;,&quot;value&quot;:40&#125;,&#123;&quot;commit&quot;:&quot;作品的市场潜力与价值&quot;,&quot;id&quot;:10,&quot;markingTemplate&quot;:&#123;&quot;$ref&quot;:&quot;$.markingTemplate&quot;&#125;,&quot;title&quot;:&quot;市场&quot;,&quot;value&quot;:10&#125;,&#123;&quot;commit&quot;:&quot;对问题的实际理解程度&quot;,&quot;id&quot;:11,&quot;markingTemplate&quot;:&#123;&quot;$ref&quot;:&quot;$.markingTemplate&quot;&#125;,&quot;title&quot;:&quot;答辩&quot;,&quot;value&quot;:10&#125;],&quot;title&quot;:&quot;模板1&quot;&#125;,&quot;title&quot;:&quot;界面&quot;,&quot;value&quot;:20&#125; &#123;&quot;commit&quot;:&quot;采用的软件开发方法与技术是否先进及与项目相宜&quot;,&quot;id&quot;:8,&quot;markingTemplate&quot;:&#123;&quot;commit&quot;:&quot;通用模板&quot;,&quot;id&quot;:1,&quot;markingItems&quot;:[&#123;&quot;commit&quot;:&quot;结合竞赛主题，作品选题具有实用性、合理性、创新性&quot;,&quot;id&quot;:6,&quot;markingTemplate&quot;:&#123;&quot;$ref&quot;:&quot;$.markingTemplate&quot;&#125;,&quot;title&quot;:&quot;选题&quot;,&quot;value&quot;:10&#125;,&#123;&quot;commit&quot;:&quot;界面友好，完成速度快，操作简洁明了&quot;,&quot;id&quot;:7,&quot;markingTemplate&quot;:&#123;&quot;$ref&quot;:&quot;$.markingTemplate&quot;&#125;,&quot;title&quot;:&quot;界面&quot;,&quot;value&quot;:20&#125;,&#123;&quot;$ref&quot;:&quot;$&quot;&#125;,&#123;&quot;commit&quot;:&quot;功能强大，具有实用性&quot;,&quot;id&quot;:9,&quot;markingTemplate&quot;:&#123;&quot;$ref&quot;:&quot;$.markingTemplate&quot;&#125;,&quot;title&quot;:&quot;功能&quot;,&quot;value&quot;:40&#125;,&#123;&quot;commit&quot;:&quot;作品的市场潜力与价值&quot;,&quot;id&quot;:10,&quot;markingTemplate&quot;:&#123;&quot;$ref&quot;:&quot;$.markingTemplate&quot;&#125;,&quot;title&quot;:&quot;市场&quot;,&quot;value&quot;:10&#125;,&#123;&quot;commit&quot;:&quot;对问题的实际理解程度&quot;,&quot;id&quot;:11,&quot;markingTemplate&quot;:&#123;&quot;$ref&quot;:&quot;$.markingTemplate&quot;&#125;,&quot;title&quot;:&quot;答辩&quot;,&quot;value&quot;:10&#125;],&quot;title&quot;:&quot;模板1&quot;&#125;,&quot;title&quot;:&quot;技术&quot;,&quot;value&quot;:10&#125; &#123;&quot;commit&quot;:&quot;功能强大，具有实用性&quot;,&quot;id&quot;:9,&quot;markingTemplate&quot;:&#123;&quot;commit&quot;:&quot;通用模板&quot;,&quot;id&quot;:1,&quot;markingItems&quot;:[&#123;&quot;commit&quot;:&quot;结合竞赛主题，作品选题具有实用性、合理性、创新性&quot;,&quot;id&quot;:6,&quot;markingTemplate&quot;:&#123;&quot;$ref&quot;:&quot;$.markingTemplate&quot;&#125;,&quot;title&quot;:&quot;选题&quot;,&quot;value&quot;:10&#125;,&#123;&quot;commit&quot;:&quot;界面友好，完成速度快，操作简洁明了&quot;,&quot;id&quot;:7,&quot;markingTemplate&quot;:&#123;&quot;$ref&quot;:&quot;$.markingTemplate&quot;&#125;,&quot;title&quot;:&quot;界面&quot;,&quot;value&quot;:20&#125;,&#123;&quot;commit&quot;:&quot;采用的软件开发方法与技术是否先进及与项目相宜&quot;,&quot;id&quot;:8,&quot;markingTemplate&quot;:&#123;&quot;$ref&quot;:&quot;$.markingTemplate&quot;&#125;,&quot;title&quot;:&quot;技术&quot;,&quot;value&quot;:10&#125;,&#123;&quot;$ref&quot;:&quot;$&quot;&#125;,&#123;&quot;commit&quot;:&quot;作品的市场潜力与价值&quot;,&quot;id&quot;:10,&quot;markingTemplate&quot;:&#123;&quot;$ref&quot;:&quot;$.markingTemplate&quot;&#125;,&quot;title&quot;:&quot;市场&quot;,&quot;value&quot;:10&#125;,&#123;&quot;commit&quot;:&quot;对问题的实际理解程度&quot;,&quot;id&quot;:11,&quot;markingTemplate&quot;:&#123;&quot;$ref&quot;:&quot;$.markingTemplate&quot;&#125;,&quot;title&quot;:&quot;答辩&quot;,&quot;value&quot;:10&#125;],&quot;title&quot;:&quot;模板1&quot;&#125;,&quot;title&quot;:&quot;功能&quot;,&quot;value&quot;:40&#125; &#123;&quot;commit&quot;:&quot;作品的市场潜力与价值&quot;,&quot;id&quot;:10,&quot;markingTemplate&quot;:&#123;&quot;commit&quot;:&quot;通用模板&quot;,&quot;id&quot;:1,&quot;markingItems&quot;:[&#123;&quot;commit&quot;:&quot;结合竞赛主题，作品选题具有实用性、合理性、创新性&quot;,&quot;id&quot;:6,&quot;markingTemplate&quot;:&#123;&quot;$ref&quot;:&quot;$.markingTemplate&quot;&#125;,&quot;title&quot;:&quot;选题&quot;,&quot;value&quot;:10&#125;,&#123;&quot;commit&quot;:&quot;界面友好，完成速度快，操作简洁明了&quot;,&quot;id&quot;:7,&quot;markingTemplate&quot;:&#123;&quot;$ref&quot;:&quot;$.markingTemplate&quot;&#125;,&quot;title&quot;:&quot;界面&quot;,&quot;value&quot;:20&#125;,&#123;&quot;commit&quot;:&quot;采用的软件开发方法与技术是否先进及与项目相宜&quot;,&quot;id&quot;:8,&quot;markingTemplate&quot;:&#123;&quot;$ref&quot;:&quot;$.markingTemplate&quot;&#125;,&quot;title&quot;:&quot;技术&quot;,&quot;value&quot;:10&#125;,&#123;&quot;commit&quot;:&quot;功能强大，具有实用性&quot;,&quot;id&quot;:9,&quot;markingTemplate&quot;:&#123;&quot;$ref&quot;:&quot;$.markingTemplate&quot;&#125;,&quot;title&quot;:&quot;功能&quot;,&quot;value&quot;:40&#125;,&#123;&quot;$ref&quot;:&quot;$&quot;&#125;,&#123;&quot;commit&quot;:&quot;对问题的实际理解程度&quot;,&quot;id&quot;:11,&quot;markingTemplate&quot;:&#123;&quot;$ref&quot;:&quot;$.markingTemplate&quot;&#125;,&quot;title&quot;:&quot;答辩&quot;,&quot;value&quot;:10&#125;],&quot;title&quot;:&quot;模板1&quot;&#125;,&quot;title&quot;:&quot;市场&quot;,&quot;value&quot;:10&#125; &#123;&quot;commit&quot;:&quot;对问题的实际理解程度&quot;,&quot;id&quot;:11,&quot;markingTemplate&quot;:&#123;&quot;commit&quot;:&quot;通用模板&quot;,&quot;id&quot;:1,&quot;markingItems&quot;:[&#123;&quot;commit&quot;:&quot;结合竞赛主题，作品选题具有实用性、合理性、创新性&quot;,&quot;id&quot;:6,&quot;markingTemplate&quot;:&#123;&quot;$ref&quot;:&quot;$.markingTemplate&quot;&#125;,&quot;title&quot;:&quot;选题&quot;,&quot;value&quot;:10&#125;,&#123;&quot;commit&quot;:&quot;界面友好，完成速度快，操作简洁明了&quot;,&quot;id&quot;:7,&quot;markingTemplate&quot;:&#123;&quot;$ref&quot;:&quot;$.markingTemplate&quot;&#125;,&quot;title&quot;:&quot;界面&quot;,&quot;value&quot;:20&#125;,&#123;&quot;commit&quot;:&quot;采用的软件开发方法与技术是否先进及与项目相宜&quot;,&quot;id&quot;:8,&quot;markingTemplate&quot;:&#123;&quot;$ref&quot;:&quot;$.markingTemplate&quot;&#125;,&quot;title&quot;:&quot;技术&quot;,&quot;value&quot;:10&#125;,&#123;&quot;commit&quot;:&quot;功能强大，具有实用性&quot;,&quot;id&quot;:9,&quot;markingTemplate&quot;:&#123;&quot;$ref&quot;:&quot;$.markingTemplate&quot;&#125;,&quot;title&quot;:&quot;功能&quot;,&quot;value&quot;:40&#125;,&#123;&quot;commit&quot;:&quot;作品的市场潜力与价值&quot;,&quot;id&quot;:10,&quot;markingTemplate&quot;:&#123;&quot;$ref&quot;:&quot;$.markingTemplate&quot;&#125;,&quot;title&quot;:&quot;市场&quot;,&quot;value&quot;:10&#125;,&#123;&quot;$ref&quot;:&quot;$&quot;&#125;],&quot;title&quot;:&quot;模板1&quot;&#125;,&quot;title&quot;:&quot;答辩&quot;,&quot;value&quot;:10&#125; 嗯。。。这里把模板也加载出来了。","categories":[{"name":"开发框架","slug":"开发框架","permalink":"https://cattenlinger.github.io/categories/%E5%BC%80%E5%8F%91%E6%A1%86%E6%9E%B6/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://cattenlinger.github.io/tags/Java/"},{"name":"Hibernate","slug":"Hibernate","permalink":"https://cattenlinger.github.io/tags/Hibernate/"}]},{"title":"记一次尝试用 Java 获取系统运行信息","slug":"记一次尝试用-Java-获取系统运行信息","date":"2016-03-21T22:25:39.000Z","updated":"2025-03-24T00:55:13.388Z","comments":true,"path":"2016/03/22/097a5b624dd8.html","link":"","permalink":"https://cattenlinger.github.io/2016/03/22/097a5b624dd8.html","excerpt":"","text":"为了能在Linux上面用java获取系统的状态数值，我自己设计了一个SystemStatus工具。用于获取系统的CPU占用内存状态之类的。考虑到一般只用Linux服务器当J2EE容器服务器，所以这个工具只适配Linux系统。 ##I.偶遇Process类上网找不到什么合适的工具，只发现了别人的代码。原理是利用ProcessBuilder.start()和Runtime.exec()其中一个启动top之类的命令行工具，获取一个Process对象后对输出的字符进行处理，从而得出系统的状态参数。后来自己动手实验和询问朋友发现，不同的top版本，参数列表不同，这影响到程序的通用性（我在Mac OS X上开发，然而服务器是openSUSE）。最后我选择自己参照这个原理设计一个。 首先写一个不断Print出top的信息的线程，研究它输出的字符串。 12345678910111213141516171819202122232425Thread thread = new Thread()&#123; public void run()&#123; Process process = null; try &#123; process = new ProcessBuilder(&quot;top&quot;,&quot;-l&quot;,&quot;0&quot;,&quot;-n&quot;,&quot;0&quot;).start(); BufferedReader bufferedReader = new BufferedReader(new InputStreamReader(process.getInputStream())); while (true)&#123; String _line; do&#123; _line = bufferedReader.readLine(); System.out.println(_line); &#125;while (!&quot;&quot;.equals(_line)); sleep(1000); &#125; &#125; catch (IOException | InterruptedException e) &#123; e.printStackTrace(); &#125;finally &#123; if(process != null)&#123; process.destroy(); &#125; &#125; &#125; &#125;; thread.setDaemon(true); thread.start(); 在Mac OS X上输出是这个样子的 123456789101112Processes: 306 total, 2 running, 4 stuck, 300 sleeping, 1538 threads 2016/03/19 01:48:27Load Avg: 2.54, 2.02, 1.85 CPU usage: 7.52% user, 7.52% sys, 84.95% idle SharedLibs: 143M resident, 21M data, 12M linkedit.MemRegions: 72549 total, 2138M resident, 70M private, 801M shared.PhysMem: 8153M used (2315M wired), 37M unused.VM: 873G vsize, 527M framework vsize, 6078855(0) swapins, 6516083(0) swapouts.Networks: packets: 6311608/2054M in, 4686357/778M out.Disks: 1729987/56G read, 1830126/68G written. 除了时间之外，每行开头都有描述＋分号的头，然后是数据＋单位＋描述，而且后面带两空行。 但是我首先想到的问题不是怎么处理它们，而是资源消耗。其实这个问题我早就开始考虑了。 首先是创建线程的成本。这个成本很大，占用10%以上的CPU，但只是在一开始Create的时候产生，之后CPU的占用几乎是top的基本占用，这是基本成本，可以不用削减，因此也不可以用“查询一次调用一次命令”的方法。 然后是线程循环读取BufferedReader时候的成本。我在查找资料的时候，从 关于java中BufferedReader的read()及readLine()方法的使用心得 中了解到，BufferedReader.readLine()是一个阻塞函数，因此并不需要自己写代码判断是否是空行然后挂起线程。 误以为readLine()是读取到没有数据时就返回null(因为其它read方法当读到没有数据时返回-1)，而实际上readLine()是一个阻塞函数，当没有数据读取时，就一直会阻塞在那，而不是返回null；因为readLine()阻塞后，System.out.println(message)这句根本就不会执行到，所以在接收端就不会有东西输出。 还有就是BufferedReader缓冲区满问题，我并没有这方面的开发经验，不知道BufferedReader的缓冲区会不会满，会的话，满了之后发生什么事。依旧上网查资料。从java io系列23之 BufferedReader详解的源码分析里得出，BufferedReader是不会爆的……然后我就继续向上查找，InputStreamReader呢？但是发现，已经到了尽头了（JVM托管的东西，就先不要操心用下去，出了问题再处理，这样能省点时间嗯……）所以可以放心继续用下去。 于是开始设计获取的整个过程 首先有一个模型类，去盛放这些数据 然后有一个对应的工厂，去产生数据 但是问题来了，输出结果依赖top的版本。为了以后的兼容性，我是先有个服务线程，SystemStatusSession，把输出结果通过render整理到HashMap后再用依赖配置的工厂类序列化数据到模型类。然后不同的top版本命令格式也不同，所以有一个命令参数传进去才能让top有正确的输出。但前期为了降低难度，先不用render和依赖配置的工厂类去实现数据的序列化。暂时有以下的类 [Interface]TopCommand 生成top的命令用，参数类，用的时候再写实现类 [Class]SystemStatusSession 这个类负责使用render整理top的输出到HashMap，一个top线程对应一个状态会话。 [Class]SystemStatus 盛放数据用的模型类 [Class]SystemStatusFactory 工厂类，依赖配置序列化HashMap的数据到模型类 ##II.但是…… 当我尝试使用Linux上的top开发这个工具的时候，遇到了个很严重的问题……Linux的top并不能像OS X上的那样指定输出几行，然后就GG了，而且top这个工具，最新版的顶层直接变成了进度条样式而且无法更改。 其实只要像我之前说的那样，用render／factory模式，是可以通过配置文件适配各个版本的top的。但是，这样会产生大量的配置文件。而且工厂运行起来复杂：首先判断top版本，获取配置文件，然后各种循环各种判断，把top的输出字符串转换成类。就是为了获取个状态，付出这么大的代价，最后又影响了这个状态，怎么越来越有量子物理的感觉了…… ##III.抛弃Top，使用Python脚本 最后又一头扎进Google的怀里继续找…… 查看了很多的方法之后，我退回去想：既然是通过Process去执行一些东西得到返回值，那么……我想起了我在学Python，网页上的系统状态显示的视线也是用的脚本语言，那就干脆用Python写一个好了。询问朋友，得知Python的psutil，用这个玩意获取这些系统信息，完全就是一句话的事情。当我使用了一下psutil之后简直就是想揍自己……不过在搞技术的道路上谁会一帆风顺呢～ psutil的文档在这里：psutil 4.1.0 : Python Package Index 根据文档，我写了个小Demo 12345678910111213141516171819202122232425262728#!/usr/bin/pythonimport psutilimport timeimport osimport systry: while 1: print &quot;cpu_percent:&quot;,psutil.cpu_percent(interval=1) print &quot;logical_cpu_count:&quot;,psutil.cpu_count() print &quot;real_cpu_count:&quot;,psutil.cpu_count(logical=False) v_memstatus=psutil.virtual_memory() print &quot;memory_virtual_total:&quot;,v_memstatus.total print &quot;memory_virtual_abailable:&quot;,v_memstatus.available print &quot;memory_virtual_percent:&quot;,v_memstatus.percent print &quot;memory_virtual_used:&quot;,v_memstatus.used print &quot;memory_virtual_free:&quot;,v_memstatus.free print &quot;memory_virtual_active:&quot;,v_memstatus.active print &quot;memory_virtual_inactive:&quot;,v_memstatus.inactive #print &quot;memory_virtual_buffers =&quot;,v_memstatus.buffers s_memstatus=psutil.swap_memory() print &quot;memory_swap_total:&quot;,s_memstatus.total print &quot;memory_swap_used:&quot;,s_memstatus.used print &quot;memory_swap_free:&quot;,s_memstatus.free print &quot;memory_swap_percent:&quot;,s_memstatus.percent sys.stdout.flush();except (KeyboardInterrupt, SystemExit): pass 代码大致上没啥问题，最重点的一句是sys.stdout.flush();，我就是卡在这里一段时间。从关于Java调用外部程序即时输出的一些收获中得知，原来是Python的程序要主动调用flush()才能把输出从缓冲区输出。 里面那句“经过测试，我们发现一个问题，如果外部程序在输出信息时，没有用flush也会出现问题”点醒了我。我才发现原来是python和C程序中使用print或者printf输出也是有缓冲机制的。所以process的getInputStream()并不能立即获得输出结果（因为此时结果还保留在C或python进程输出的缓冲区中），所以需要在python中的print后面加入sys.stdout.flush()才行。如此，问题解决。 psutil的安装需要python-devel（或者叫python-dev），gcc也是必须的，我的服务器没有，所以才意识到这个问题。 因为输出格式完全可以自定义，所以可以省去render，直接把这些整理到hashmap里，最后session的线程代码如下 12345678910111213141516171819202122232425262728private class QueryServerThread extends Thread&#123; HashMap&lt;String,String&gt; map = infoMap; boolean isRun = true; public void run()&#123; try &#123; BufferedReader bufferedReader = new BufferedReader(new InputStreamReader(topProcess.getInputStream())); String _line; while (isRun)&#123; do&#123; _line = bufferedReader.readLine(); if(_line == null) break; _line = _line.trim().replace(&quot;\\&quot;&quot;,&quot;&quot;); String[] strings = _line.split(&quot;:&quot;); map.put(strings[0],strings[1]); &#125;while (true); sleep(700); &#125; &#125; catch (IOException | InterruptedException e) &#123; e.printStackTrace(); &#125; finally &#123; if(topProcess != null)&#123; topProcess.destroy(); &#125; &#125; &#125; &#125; 写一个main来测试一下 12345678910111213141516171819public static void main(String[] args) &#123; Thread thread = new Thread()&#123; public void run()&#123; try &#123; SystemStatusSession systemStatusSession = new SystemStatusSession(&quot;ex-lib/iostatu.py&quot;); HashMap&lt;String,String&gt; hashMap = systemStatusSession.getInfoMap(); while (true)&#123; for(String s : hashMap.keySet())&#123; System.out.printf(&quot;Key:%s | Value:%s\\n&quot;,s,hashMap.get(s)); &#125; sleep(1000); &#125; &#125;catch (Exception e)&#123; e.printStackTrace(); &#125; &#125; &#125;; thread.start();&#125; 输出结果 12345678910Key:cpu_percent | Value: 12.2Key:memory_virtual_inactive | Value: 2061193216Key:memory_virtual_percent | Value: 75.5Key:logical_cpu_count | Value: 4Key:memory_swap_total | Value: 2147483648Key:memory_virtual_abailable | Value: 2108739584Key:memory_virtual_free | Value: 47546368Key:memory_virtual_used | Value: 6812692480Key:memory_virtual_total | Value: 8589934592Key:real_cpu_count | Value: 2 这样的话，就可以很方便得用工厂来创建SystemStatus类了。虽说不算灵活，但是只要更改这个python脚本就能获得各种系统参数。 ##IV.抛弃Java，全用Python实现","categories":[{"name":"编程技术","slug":"编程技术","permalink":"https://cattenlinger.github.io/categories/%E7%BC%96%E7%A8%8B%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://cattenlinger.github.io/tags/Java/"},{"name":"Linux","slug":"Linux","permalink":"https://cattenlinger.github.io/tags/Linux/"}]},{"title":"主要的 NAT 类型","slug":"主要的-NAT-类型","date":"2015-11-18T22:30:24.000Z","updated":"2024-09-30T12:28:22.398Z","comments":true,"path":"2015/11/19/69502e432e3e.html","link":"","permalink":"https://cattenlinger.github.io/2015/11/19/69502e432e3e.html","excerpt":"","text":"##I. Full-cone NAT, also known as one-to-one NAT（无限制型NAT） 一旦一个内网地址 iAddr:iPort 被映射到一个外部地址 eAddr:ePort， 来自 iAddr:iPort 的任何数据包将通过 eAddr:ePort 发送。 任何外部主机 都能够通过外部地址 eAddr:ePort 发送数据包到内网地址 iAddr:iPort 。 ##II. Address-restricted-cone NAT（地址限制型NAT） 一旦一个内网地址 iAddr:iPort 被映射到一个外部地址 eAddr:ePort，来自内网地址 iAddr:iPort 的任何数据包将通过 eAddr:ePort 发送。 若外部主机接收到内网地址 iAddr:iPort 通过 eAddr:ePort 发送的数据包，那么通过该主机的 任何端口 发送到 eAddr:ePort 的数据包都可被正确转发到 iAddr:iPort 。也就是说主机有关端口无关。 ##III. Port-restricted cone NAT（端口限制型NAT） 类似于address restricted cone NAT，但是端口号有限制。 一旦一个内网地址 iAddr:iPort 被映射到一个外部地址 eAddr:ePort，来自 iAddr:iPort 的任何数据包将通过 eAddr:ePort 发送。 若外部主机接收到内网地址 iAddr:iPort 通过 eAddr:ePort 发送的数据包，那么通过 该主机的相同端口 发送到 eAddr:ePort 的数据包才能够被正确的转发到 iAddr:iPort 。 ##IV. Symmetric NAT（对等NAT） 来自相同内部ip和port发送到相同目的地ip和port的请求 被映射到唯一的外部ip和port地址 eAdde:ePort ；如果相同的内部主机采用相同的ip和port地址发送到不同的目的地，那么重新分配映射地址。 只有先前收到内部地址发出的包的外部主机才能发送返回包到内部主机。","categories":[{"name":"笔记","slug":"笔记","permalink":"https://cattenlinger.github.io/categories/%E7%AC%94%E8%AE%B0/"}],"tags":[]}],"categories":[{"name":"Self-Hosting","slug":"Self-Hosting","permalink":"https://cattenlinger.github.io/categories/Self-Hosting/"},{"name":"编程技术","slug":"编程技术","permalink":"https://cattenlinger.github.io/categories/%E7%BC%96%E7%A8%8B%E6%8A%80%E6%9C%AF/"},{"name":"Linux 技术应用","slug":"Linux-技术应用","permalink":"https://cattenlinger.github.io/categories/Linux-%E6%8A%80%E6%9C%AF%E5%BA%94%E7%94%A8/"},{"name":"开发框架","slug":"开发框架","permalink":"https://cattenlinger.github.io/categories/%E5%BC%80%E5%8F%91%E6%A1%86%E6%9E%B6/"},{"name":"翻译","slug":"翻译","permalink":"https://cattenlinger.github.io/categories/%E7%BF%BB%E8%AF%91/"},{"name":"技术文章","slug":"翻译/技术文章","permalink":"https://cattenlinger.github.io/categories/%E7%BF%BB%E8%AF%91/%E6%8A%80%E6%9C%AF%E6%96%87%E7%AB%A0/"},{"name":"macOS 使用经验","slug":"macOS-使用经验","permalink":"https://cattenlinger.github.io/categories/macOS-%E4%BD%BF%E7%94%A8%E7%BB%8F%E9%AA%8C/"},{"name":"Windows 使用经验","slug":"Windows-使用经验","permalink":"https://cattenlinger.github.io/categories/Windows-%E4%BD%BF%E7%94%A8%E7%BB%8F%E9%AA%8C/"},{"name":"笔记","slug":"笔记","permalink":"https://cattenlinger.github.io/categories/%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://cattenlinger.github.io/tags/Linux/"},{"name":"Docker","slug":"Docker","permalink":"https://cattenlinger.github.io/tags/Docker/"},{"name":"DNS","slug":"DNS","permalink":"https://cattenlinger.github.io/tags/DNS/"},{"name":"域名","slug":"域名","permalink":"https://cattenlinger.github.io/tags/%E5%9F%9F%E5%90%8D/"},{"name":"Java","slug":"Java","permalink":"https://cattenlinger.github.io/tags/Java/"},{"name":"依值类型","slug":"依值类型","permalink":"https://cattenlinger.github.io/tags/%E4%BE%9D%E5%80%BC%E7%B1%BB%E5%9E%8B/"},{"name":"泛型","slug":"泛型","permalink":"https://cattenlinger.github.io/tags/%E6%B3%9B%E5%9E%8B/"},{"name":"Bash","slug":"Bash","permalink":"https://cattenlinger.github.io/tags/Bash/"},{"name":"Shell","slug":"Shell","permalink":"https://cattenlinger.github.io/tags/Shell/"},{"name":"xmllint","slug":"xmllint","permalink":"https://cattenlinger.github.io/tags/xmllint/"},{"name":"XPath","slug":"XPath","permalink":"https://cattenlinger.github.io/tags/XPath/"},{"name":"XML","slug":"XML","permalink":"https://cattenlinger.github.io/tags/XML/"},{"name":"Virtual","slug":"Virtual","permalink":"https://cattenlinger.github.io/tags/Virtual/"},{"name":"Machine","slug":"Machine","permalink":"https://cattenlinger.github.io/tags/Machine/"},{"name":"PCIe","slug":"PCIe","permalink":"https://cattenlinger.github.io/tags/PCIe/"},{"name":"Passthrought","slug":"Passthrought","permalink":"https://cattenlinger.github.io/tags/Passthrought/"},{"name":"Ubuntu","slug":"Ubuntu","permalink":"https://cattenlinger.github.io/tags/Ubuntu/"},{"name":"QEMU","slug":"QEMU","permalink":"https://cattenlinger.github.io/tags/QEMU/"},{"name":"vfio-pci","slug":"vfio-pci","permalink":"https://cattenlinger.github.io/tags/vfio-pci/"},{"name":"vfio","slug":"vfio","permalink":"https://cattenlinger.github.io/tags/vfio/"},{"name":"TypeScript","slug":"TypeScript","permalink":"https://cattenlinger.github.io/tags/TypeScript/"},{"name":"NodeJS","slug":"NodeJS","permalink":"https://cattenlinger.github.io/tags/NodeJS/"},{"name":"Javascript","slug":"Javascript","permalink":"https://cattenlinger.github.io/tags/Javascript/"},{"name":"Kotlin","slug":"Kotlin","permalink":"https://cattenlinger.github.io/tags/Kotlin/"},{"name":"JS","slug":"JS","permalink":"https://cattenlinger.github.io/tags/JS/"},{"name":"Kt","slug":"Kt","permalink":"https://cattenlinger.github.io/tags/Kt/"},{"name":"Webpack","slug":"Webpack","permalink":"https://cattenlinger.github.io/tags/Webpack/"},{"name":"Promise","slug":"Promise","permalink":"https://cattenlinger.github.io/tags/Promise/"},{"name":"Coroutine","slug":"Coroutine","permalink":"https://cattenlinger.github.io/tags/Coroutine/"},{"name":"Spring","slug":"Spring","permalink":"https://cattenlinger.github.io/tags/Spring/"},{"name":"Web","slug":"Web","permalink":"https://cattenlinger.github.io/tags/Web/"},{"name":"SpringMVC","slug":"SpringMVC","permalink":"https://cattenlinger.github.io/tags/SpringMVC/"},{"name":"Jwt","slug":"Jwt","permalink":"https://cattenlinger.github.io/tags/Jwt/"},{"name":"Spring IoC","slug":"Spring-IoC","permalink":"https://cattenlinger.github.io/tags/Spring-IoC/"},{"name":"项目开发","slug":"项目开发","permalink":"https://cattenlinger.github.io/tags/%E9%A1%B9%E7%9B%AE%E5%BC%80%E5%8F%91/"},{"name":"Spring MVC","slug":"Spring-MVC","permalink":"https://cattenlinger.github.io/tags/Spring-MVC/"},{"name":"Servlet","slug":"Servlet","permalink":"https://cattenlinger.github.io/tags/Servlet/"},{"name":"iptables","slug":"iptables","permalink":"https://cattenlinger.github.io/tags/iptables/"},{"name":"Network","slug":"Network","permalink":"https://cattenlinger.github.io/tags/Network/"},{"name":"Maven","slug":"Maven","permalink":"https://cattenlinger.github.io/tags/Maven/"},{"name":"Web App","slug":"Web-App","permalink":"https://cattenlinger.github.io/tags/Web-App/"},{"name":"RabbitMQ","slug":"RabbitMQ","permalink":"https://cattenlinger.github.io/tags/RabbitMQ/"},{"name":"第三方平台","slug":"第三方平台","permalink":"https://cattenlinger.github.io/tags/%E7%AC%AC%E4%B8%89%E6%96%B9%E5%B9%B3%E5%8F%B0/"},{"name":"微信","slug":"微信","permalink":"https://cattenlinger.github.io/tags/%E5%BE%AE%E4%BF%A1/"},{"name":"支付","slug":"支付","permalink":"https://cattenlinger.github.io/tags/%E6%94%AF%E4%BB%98/"},{"name":"vsftpd","slug":"vsftpd","permalink":"https://cattenlinger.github.io/tags/vsftpd/"},{"name":"WebFlux","slug":"WebFlux","permalink":"https://cattenlinger.github.io/tags/WebFlux/"},{"name":"MySql","slug":"MySql","permalink":"https://cattenlinger.github.io/tags/MySql/"},{"name":"Jackson","slug":"Jackson","permalink":"https://cattenlinger.github.io/tags/Jackson/"},{"name":"PHP","slug":"PHP","permalink":"https://cattenlinger.github.io/tags/PHP/"},{"name":"Laravel","slug":"Laravel","permalink":"https://cattenlinger.github.io/tags/Laravel/"},{"name":"认证","slug":"认证","permalink":"https://cattenlinger.github.io/tags/%E8%AE%A4%E8%AF%81/"},{"name":"鉴权","slug":"鉴权","permalink":"https://cattenlinger.github.io/tags/%E9%89%B4%E6%9D%83/"},{"name":"Nginx","slug":"Nginx","permalink":"https://cattenlinger.github.io/tags/Nginx/"},{"name":"RTMP","slug":"RTMP","permalink":"https://cattenlinger.github.io/tags/RTMP/"},{"name":"Media Streaming","slug":"Media-Streaming","permalink":"https://cattenlinger.github.io/tags/Media-Streaming/"},{"name":"OBS","slug":"OBS","permalink":"https://cattenlinger.github.io/tags/OBS/"},{"name":"Remix OS","slug":"Remix-OS","permalink":"https://cattenlinger.github.io/tags/Remix-OS/"},{"name":"Android","slug":"Android","permalink":"https://cattenlinger.github.io/tags/Android/"},{"name":"Mac OS X","slug":"Mac-OS-X","permalink":"https://cattenlinger.github.io/tags/Mac-OS-X/"},{"name":"Windows","slug":"Windows","permalink":"https://cattenlinger.github.io/tags/Windows/"},{"name":"Script","slug":"Script","permalink":"https://cattenlinger.github.io/tags/Script/"},{"name":"iOS","slug":"iOS","permalink":"https://cattenlinger.github.io/tags/iOS/"},{"name":"App 开发","slug":"App-开发","permalink":"https://cattenlinger.github.io/tags/App-%E5%BC%80%E5%8F%91/"},{"name":"JPA","slug":"JPA","permalink":"https://cattenlinger.github.io/tags/JPA/"},{"name":"JavaScript","slug":"JavaScript","permalink":"https://cattenlinger.github.io/tags/JavaScript/"},{"name":"Desktop Environments","slug":"Desktop-Environments","permalink":"https://cattenlinger.github.io/tags/Desktop-Environments/"},{"name":"Programing Language","slug":"Programing-Language","permalink":"https://cattenlinger.github.io/tags/Programing-Language/"},{"name":"Hibernate","slug":"Hibernate","permalink":"https://cattenlinger.github.io/tags/Hibernate/"}]}